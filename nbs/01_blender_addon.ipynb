{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff66780-4538-49e7-a1e2-4b1030fad4ec",
   "metadata": {},
   "source": [
    "## Blender add-on\n",
    "\n",
    "> Blender add-on for loading and visualizing volumetric data into blender and projecting image intensities onto a mesh surface\n",
    "\n",
    "**Note** This module is _not_ for use in a standard python environment, but must be run as an add-on within Blender. For documentation of the add-on user interface, see tutorial 3. This page documents the add-on code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825e730-c1de-4826-b230-f1a2517a547f",
   "metadata": {},
   "source": [
    "### Add-on design\n",
    "\n",
    "The add-on code comprises three parts:\n",
    "\n",
    "1. Functions for carrying out key tissue cartography operations. These are based on the `blender_tissue_cartography` python library, edited to reflect the constraints of python scripting in blender (e.g. the `igl` library is not available).\n",
    "\n",
    "2. A class (inherting from `bpy.types.Operator`) defining each add-on button, with an `execute` function defining what happens when you click it.\n",
    "\n",
    "3. The `TissueCartographyPanel(Panel)` class and the `register` function defining all user input fields and how user input fields and buttons from part 2 are laid out in the Tissue Cartography Panel.\n",
    "\n",
    "All functions and classes are documented below.\n",
    "\n",
    "To allow the user to load multiple 3D datasets and meshes into the same blender file, image data is associated with mesh objects. Which data any operation is applied to is determined by the currently selected mesh.\n",
    "\n",
    "The `bpy` library allows the add-on to interact with blender. It is only available within blender's python scripting interface, which is why you cannot run the add-on in a normal python interpreter. See this tutorial for an introduction into scripting Blender: https://docs.blender.org/manual/en/latest/advanced/scripting/addon_tutorial.html\n",
    "\n",
    "If you want to edit/extend the add-on, be aware of the following **hacks** used:\n",
    "\n",
    "1. _Associating data with meshes_: In the add-on, tissue cartography data is associated with blender meshes. For example, loaded volumetric image data (represented as a `numpy` array) is associated with a `BoundingBox` rectangular cuboid showing the volume covered by the image data (see tutorial 3). Unfortunately, blender does not allow adding arbitrary attributes to meshes. The functions `set_numpy_attribute`/`get_numpy_attribute` circumvent this by representing array data as binary buffer + shape. To associate functions with a mesh (e.g. interpolators), a global dictionary is used.\n",
    "\n",
    "2. _UV layout_: To obtain the part of the UV square covered by an unwrapped mesh, a `.png` of the layout is exported to disk and re-read. \n",
    "\n",
    "The add-on makes use of the following libraries which are included with the add-ons using wheels: `numpy, tifffile, scipy, skimage`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f4400-ca7c-418c-86ea-7dff39632154",
   "metadata": {},
   "source": [
    "### Add-on code\n",
    "\n",
    "The code below is shown for completeness of the documentation webpage. Please download the add-on code from GitHub [here](https://github.com/nikolas-claussen/blender-tissue-cartography/blob/main/blender_addon/blender_addon.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7593c93b-e3d2-4bd7-9ec1-feff5b950615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| notest\n",
    "\n",
    "bl_info = {\n",
    "    \"name\": \"Tissue Cartography\",\n",
    "    \"blender\": (4, 3, 0),\n",
    "    \"category\": \"Scene\",\n",
    "}\n",
    "\n",
    "import bpy\n",
    "from bpy.props import StringProperty, FloatProperty, FloatVectorProperty, IntProperty, IntVectorProperty, BoolProperty, EnumProperty\n",
    "from bpy.types import Operator, Panel\n",
    "import mathutils\n",
    "import bmesh\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import difflib\n",
    "import itertools\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import tifffile\n",
    "from scipy import interpolate, ndimage, spatial, stats, linalg\n",
    "from skimage import measure\n",
    "\n",
    "\n",
    "### Installing dependencies\n",
    "\n",
    "def install_dependencies():\n",
    "    try:\n",
    "        import scipy\n",
    "        import skimage\n",
    "    except ImportError:\n",
    "        python_executable = sys.executable\n",
    "        subprocess.check_call([python_executable, \"-m\", \"pip\", \"install\", \"scipy\", \"scikit-image\", \"tifffile\"])\n",
    "\n",
    "\n",
    "### I/O and image handling\n",
    "\n",
    "\n",
    "def load_png(image_path):\n",
    "    \"\"\"Load .png into numpy array.\"\"\"\n",
    "    image = bpy.data.images.load(image_path)\n",
    "    width, height = image.size\n",
    "    pixels = np.array(image.pixels[:], dtype=np.float32)\n",
    "    return pixels.reshape((height, width, -1))\n",
    "\n",
    "\n",
    "def normalize_quantiles(image, quantiles=(0.01, 0.99), channel_axis=None, clip=False,\n",
    "                        data_type=None):\n",
    "    \"\"\"\n",
    "    Normalize a multi-dimensional image by setting given quantiles to 0 and 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Multi-dimensional image.\n",
    "    quantiles : tuple\n",
    "        Image quantile to set to 0 and 1.\n",
    "    channel_axis : int or None\n",
    "        If None, the image is assumed to have only a single channel.\n",
    "        If int, indicates the position of the channel axis. \n",
    "        Each channel is normalized separately.\n",
    "    clip : bool\n",
    "        Whether to clip image to 0-1. Automatically enabled if converting to int dtype.\n",
    "    data_type : None, np.unit8 or np.uint16\n",
    "        If not None, image is converted to give data type.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image_normalized : np.array\n",
    "        Normalized image, the same shape as input\n",
    "    \"\"\"\n",
    "    if channel_axis is None:\n",
    "        image_normalized = image - np.nanquantile(image, quantiles[0])\n",
    "        image_normalized /= np.nanquantile(image_normalized, quantiles[1])\n",
    "        image_normalized = np.nan_to_num(image_normalized)\n",
    "    else:\n",
    "        image_normalized = np.moveaxis(image, channel_axis, 0)\n",
    "        image_normalized = np.stack([ch - np.nanquantile(ch, quantiles[0]) for ch in image_normalized])\n",
    "        image_normalized = np.stack([ch / np.nanquantile(ch, quantiles[1]) for ch in image_normalized])\n",
    "        image_normalized = np.moveaxis(np.nan_to_num(image_normalized), 0, channel_axis)\n",
    "    if clip or (data_type is not None):\n",
    "        image_normalized = np.clip(image_normalized, 0, 1)\n",
    "    if data_type is np.uint8:\n",
    "        image_normalized = np.round((2**8-1)*image_normalized).astype(np.uint8)\n",
    "    if data_type is np.uint16:\n",
    "        image_normalized = np.round((2**16-1)*image_normalized).astype(np.uint16)\n",
    "    return image_normalized\n",
    "\n",
    "\n",
    "\n",
    "def axis_order_to_transpose(axis_order_string):\n",
    "    \"\"\"Convert string describing axis order into tuple for use in np.transpose.\"\"\"\n",
    "    assert ''.join(sorted(axis_order_string)) in ['xyz', 'cxyz'], \"Must be xyz, cxyz, or permutation thereof\"\n",
    "    if 'c' in axis_order_string:\n",
    "        transpose = [axis_order_string.index(k) for k in 'cxyz']\n",
    "    else:\n",
    "        transpose = [axis_order_string.index(k) for k in 'xyz']\n",
    "    return transpose\n",
    "\n",
    "\n",
    "### Tissue cartography - projecting 3d images to UV textures\n",
    "\n",
    "\n",
    "def get_uv_layout(obj, uv_layout_path, image_resolution):\n",
    "    \"\"\"Get UV layout mask for obj object as a np.array. As a side effect, saves layout to disk and deselects everything except obj.\"\"\"\n",
    "    if os.path.exists(uv_layout_path):\n",
    "        os.remove(uv_layout_path)\n",
    "\n",
    "    bpy.ops.object.select_all(action='DESELECT')  # Deselect all objects\n",
    "    obj.select_set(True)  # Select the specific object\n",
    "    bpy.context.view_layer.objects.active = obj\n",
    "    bpy.ops.object.mode_set(mode='EDIT')\n",
    "    \n",
    "    # Set all faces to selected for the UV layout\n",
    "    mesh = bmesh.from_edit_mesh(obj.data)\n",
    "    for face in mesh.faces:\n",
    "        face.select = True\n",
    "    bmesh.update_edit_mesh(obj.data)\n",
    "    \n",
    "    bpy.ops.uv.export_layout(filepath=uv_layout_path, size=(image_resolution, image_resolution), opacity=1, export_all=False, check_existing=False)\n",
    "    bpy.ops.object.mode_set(mode='OBJECT')\n",
    "    UV_layout = load_png(uv_layout_path)\n",
    "    \n",
    "    return (UV_layout.sum(axis=-1) > 0)[::-1]\n",
    "\n",
    "\n",
    "def get_uv_normal_world_per_loop(mesh_obj, filter_unique=False):\n",
    "    \"\"\"\n",
    "    Get UV, normals, and world and normal for each loop (half-edge) as np.array.\n",
    "    \n",
    "    If filter_unique, remove \"duplicate\" loops (for which UV, normals and position\n",
    "    are identical).\n",
    "    \"\"\"\n",
    "    if not mesh_obj:\n",
    "        raise TypeError(\"No object selected\")\n",
    "    if mesh_obj.type != 'MESH':\n",
    "        raise TypeError(\"Selected object is not a mesh\")\n",
    "    world_matrix = mesh_obj.matrix_world\n",
    "    uv_layer = mesh_obj.data.uv_layers.active\n",
    "    if not uv_layer:\n",
    "        raise RuntimeError(\"Mesh does not have an active UV map\")\n",
    "    loop_uvs = np.zeros((len(mesh_obj.data.loops), 2), dtype=np.float32)\n",
    "    loop_normals = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    loop_world_positions = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    for loop in mesh_obj.data.loops:\n",
    "        loop_uvs[loop.index] = uv_layer.data[loop.index].uv\n",
    "        loop_normals[loop.index] = world_matrix.to_3x3() @ mesh_obj.data.vertices[loop.vertex_index].normal\n",
    "        loop_world_positions[loop.index] = world_matrix @ mesh_obj.data.vertices[loop.vertex_index].co\n",
    "    if filter_unique:\n",
    "        unqiue_loops = np.unique(np.hstack([loop_uvs, loop_normals, loop_world_positions]), axis=0)\n",
    "        loop_uvs, loop_normals, loop_world_positions = (unqiue_loops[:,:2], unqiue_loops[:,2:5], unqiue_loops[:,5:])\n",
    "    loop_normals = np.round((loop_normals.T/np.linalg.norm(loop_normals, axis=1)).T, decimals=4)\n",
    "    return loop_uvs, loop_normals, loop_world_positions\n",
    "\n",
    "\n",
    "def bake_per_loop_values_to_uv(loop_uvs, loop_values, image_resolution):\n",
    "    \"\"\"\n",
    "    Bake (interpolate) values (normals or world position) defined per loop into the UV square.\n",
    "    \n",
    "    UV coordinates outside [0,1] are ignored.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    loop_uvs : np.array of shape (n_loops, 2)\n",
    "        UV coordinates of loop.\n",
    "    loop_values : np.array of shape (n_loops, ...)\n",
    "        Input field. Can be an array with any number of axes (e.g. scalar or vector field).\n",
    "    image_resolution : int, default 256\n",
    "        Size of UV grid. Determines resolution of result.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    interpolated : np.array of shape (uv_grid_steps, uv_grid_steps, ...)\n",
    "        Field across [0,1]**2 UV grid, with a uniform step size. UV positions that don't\n",
    "        correspond to any value are set to np.nan.\n",
    "            \n",
    "    \"\"\"\n",
    "    U, V = np.meshgrid(*(2*(np.linspace(0,1, image_resolution),)))\n",
    "    interpolated = interpolate.griddata(loop_uvs, loop_values, (U, V), method='linear')[::-1]\n",
    "    return interpolated\n",
    "\n",
    "\n",
    "def bake_volumetric_data_to_uv(image, baked_world_positions, resolution, baked_normals, normal_offsets=(0,), affine_matrix=None):\n",
    "    \"\"\" \n",
    "    Interpolate volumetric image data onto UV coordinate grid.\n",
    "    \n",
    "    Uses baked 3d world positions corresponding to each UV grid point (see bake_per_loop_values_to_UV).\n",
    "    3d coordinates (in microns) are converted into image coordinates via the resolution scaling factor.\n",
    "    The resolution of the bake (number of pixels) is determined by the shape of baked_world_positions.\n",
    "    \n",
    "    normal_offsets moves the 3d positions whose volumetric voxel values will be baked inwards or outwards\n",
    "    along the surface normal. Providing a list of offsets results in a multi-layer pullback\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : 4d np.array\n",
    "        Image, axis 0  is assumed to be the channel axis\n",
    "    baked_world_positions : np.array of shape (image_resolution, image_resolution, uv_grid_steps, 3)\n",
    "        3d world positions baked to UV grid, with uniform step size. UV positions that don't correspond to \n",
    "        any value are set to np.nan.\n",
    "    resolution : np.array of shape (3,)\n",
    "        Resolution in pixels/microns for each of the three spatial axes.\n",
    "    baked_normals : np.array of shape (image_resolution, image_resolution, uv_grid_steps, 3)\n",
    "        3d world normals baked to UV grid, with uniform step size. UV positions that don't correspond to \n",
    "        any value are set to np.nan.\n",
    "    normal_offsets : np.array of shape (n_layers,), default (0,)\n",
    "        Offsets along normal direction, in same units as interpolated_3d_positions (i.e. microns).\n",
    "        0 corresponds to no shift.\n",
    "    affine_matrix : np.array of shape (4, 4) or None\n",
    "        If not None, transform coordinates by affine trafor before calling interpolator\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    aked_data : np.array of shape (n_channels, n_layers, image_resolution, image_resolution)\n",
    "        Multi-layer 3d volumetric data baked onto UV.\n",
    "    \"\"\"\n",
    "    x, y, z = [np.arange(ni) for ni in image.shape[1:]]\n",
    "    baked_data = []\n",
    "    for o in normal_offsets:\n",
    "        position = (baked_world_positions+o*baked_normals)\n",
    "        if affine_matrix is not None:\n",
    "            position = position @ affine_matrix[:3, :3].T + affine_matrix[:3,3]\n",
    "        position =  position/resolution\n",
    "        baked_layer_data = np.stack([interpolate.interpn((x, y, z), channel, position,\n",
    "                                     method=\"linear\", bounds_error=False) for channel in image])\n",
    "        baked_data.append(baked_layer_data)\n",
    "    baked_data = np.stack(baked_data, axis=1)\n",
    "    return baked_data\n",
    "\n",
    "\n",
    "### Bounding box and orthoslices for visualizing the 3d data\n",
    "\n",
    "\n",
    "def create_box(length, width, height, name=\"RectangularBox\", hide=True):\n",
    "    \"\"\"\n",
    "    Creates a rectangular box using Blender's default cube.\n",
    "    One corner is positioned at the origin, and the box lies in the positive x/y/z quadrant.\n",
    "\n",
    "    Args:\n",
    "        length (float): Length of the box along the X-axis.\n",
    "        width (float): Width of the box along the Y-axis.\n",
    "        height (float): Height of the box along the Z-axis.\n",
    "    \"\"\"\n",
    "    # Store the current active object\n",
    "    current_active = bpy.context.active_object\n",
    "\n",
    "    bpy.ops.mesh.primitive_cube_add(size=2, location=(0, 0, 0))\n",
    "    obj = bpy.context.active_object\n",
    "    obj.name = name\n",
    "    obj.scale = (length / 2, width / 2, height / 2)\n",
    "    obj.location = (length / 2, width / 2, height / 2)\n",
    "    bpy.ops.object.transform_apply(location=True, scale=True)\n",
    "    obj.hide_set(hide)\n",
    "    # re-select the currently active object\n",
    "    if current_active:\n",
    "        bpy.context.view_layer.objects.active = current_active\n",
    "    return obj\n",
    "\n",
    "\n",
    "def create_slice_plane(length, width, height, axis='z', position=0.0):\n",
    "    \"\"\"\n",
    "    Creates a 2D plane as a slice of a rectangular box along a specified axis.\n",
    "    The plane lies within the bounds of the box.\n",
    "\n",
    "    Args:\n",
    "        length (float): Length of the box along the X-axis.\n",
    "        width (float): Width of the box along the Y-axis.\n",
    "        height (float): Height of the box along the Z-axis.\n",
    "        axis (str): Axis along which to slice ('x', 'y', or 'z').\n",
    "        position (float): Position along the chosen axis for the slice plane.\n",
    "                          Should be within the range of the box dimensions.\n",
    "    \"\"\"\n",
    "    current_active = bpy.context.active_object\n",
    "    # Validate axis and position\n",
    "    if axis not in {'x', 'y', 'z'}:\n",
    "        raise ValueError(\"Axis must be 'x', 'y', or 'z'.\")\n",
    "    \n",
    "    axis_limits = {'x': length, 'y': width, 'z': height}\n",
    "    if not (0.0 <= position <= axis_limits[axis]):\n",
    "        raise ValueError(f\"Position must be within [0, {axis_limits[axis]}] for axis {axis}.\")\n",
    "\n",
    "    # Create the plane's dimensions based on the slicing axis\n",
    "    if axis == 'x':\n",
    "        plane_size = (height, width) #(width, height)\n",
    "        location =  (position, width / 2, height / 2)\n",
    "        rotation = (0, 1.5708, 0)  # Rotate to align with the YZ-plane\n",
    "    elif axis == 'y':\n",
    "        plane_size = (length, height)\n",
    "        location = (length / 2, position, height / 2)\n",
    "        rotation = (1.5708, 0, 0)  # Rotate to align with the XZ-plane\n",
    "    else:  # 'z'\n",
    "        plane_size = (length, width)\n",
    "        location = (length / 2, width / 2, position)\n",
    "        rotation = (0, 0, 0)  # No rotation needed for the XY-plane\n",
    "\n",
    "    # Add a plane\n",
    "    bpy.ops.mesh.primitive_plane_add(size=2, location=(0, 0, 0))\n",
    "    plane = bpy.context.active_object\n",
    "    plane.name = f\"SlicePlane_{axis.upper()}_{position:.2f}\"\n",
    "\n",
    "    # Scale and position the plane\n",
    "    plane.scale = (plane_size[0] / 2, plane_size[1] / 2, 1)\n",
    "    plane.location = location\n",
    "    plane.rotation_euler = rotation\n",
    "\n",
    "    # Apply transformations (scale, location, rotation)\n",
    "    bpy.ops.object.transform_apply(location=True, scale=True, rotation=True)\n",
    "\n",
    "    # Restore the previously active object\n",
    "    if current_active:\n",
    "        bpy.context.view_layer.objects.active = current_active\n",
    "\n",
    "    return plane\n",
    "\n",
    "\n",
    "def get_slice_image(image_3d, resolution, axis='z', position=0.0):\n",
    "    \"\"\"Get slice of 3d image along axis for ortho-slice visualization.\n",
    "    image_3d must be a 4d array (channels, x, y, z). Position in microns.\"\"\"\n",
    "    if axis == 'x':\n",
    "        ind = int(np.round(position / resolution[0]))\n",
    "        slice_img = image_3d[:,ind,:,::-1]\n",
    "    elif axis == 'y':\n",
    "        ind = int(np.round(position / resolution[1]))\n",
    "        slice_img = image_3d[:,:,ind,:].transpose((0,2,1))\n",
    "    elif axis == 'z': \n",
    "        ind = int(np.round(position / resolution[0]))\n",
    "        slice_img = image_3d[:,:,:,ind].transpose((0,2,1))\n",
    "    return slice_img\n",
    "\n",
    "\n",
    "def create_material_from_array(slice_plane, array, material_name=\"SliceMaterial\"):\n",
    "    \"\"\"\n",
    "    Creates a material for a ortho-slice plane using a 2D numpy array as a texture.\n",
    "\n",
    "    Args:\n",
    "        slice_plane (bpy.types.Object): The plane object to which the material will be applied.\n",
    "        array (numpy.ndarray): 2D array representing grayscale values (0-1), or 3D array representing RGBA values (0-1).\n",
    "        material_name (str): Name of the new material.\n",
    "    \"\"\"\n",
    "    # Validate input array\n",
    "    if not len(array.shape) in [2,3]:\n",
    "        raise ValueError(\"Input array must be 2D.\")\n",
    "    \n",
    "    # Normalize array to range [0, 1] and convert to a flat list\n",
    "    image_height, image_width = array.shape[:2]\n",
    "    pixel_data = np.zeros((image_height, image_width, 4), dtype=np.float32)  # RGBA\n",
    "    if len(array.shape) == 2:\n",
    "        pixel_data[..., 0] =  pixel_data[..., 1] = pixel_data[..., 2] = array\n",
    "        pixel_data[..., 3] = 1.0  # Alpha\n",
    "    else:\n",
    "        pixel_data[...] = array\n",
    "    pixel_data = pixel_data.flatten()\n",
    "\n",
    "    # Create a new image in Blender\n",
    "    image = bpy.data.images.new(name=\"SliceTexture\", width=image_width, height=image_height)\n",
    "    image.pixels = pixel_data.tolist()\n",
    "\n",
    "    # Create a new material\n",
    "    material = bpy.data.materials.new(name=material_name)\n",
    "    material.use_nodes = True\n",
    "    nodes = material.node_tree.nodes\n",
    "    links = material.node_tree.links\n",
    "\n",
    "    # Clear default nodesx\n",
    "    for node in nodes:\n",
    "        nodes.remove(node)\n",
    "\n",
    "    # Add required nodes\n",
    "    texture_node = nodes.new(type=\"ShaderNodeTexImage\")\n",
    "    texture_node.image = image\n",
    "    bsdf_node = nodes.new(type=\"ShaderNodeBsdfPrincipled\")\n",
    "    output_node = nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "\n",
    "    # Arrange nodes\n",
    "    texture_node.location = (-400, 0)\n",
    "    bsdf_node.location = (0, 0)\n",
    "    output_node.location = (400, 0)\n",
    "\n",
    "    # Connect nodes\n",
    "    links.new(texture_node.outputs[\"Color\"], bsdf_node.inputs[\"Base Color\"])\n",
    "    links.new(bsdf_node.outputs[\"BSDF\"], output_node.inputs[\"Surface\"])\n",
    "\n",
    "    # Assign the material to the plane\n",
    "    slice_plane.active_material = material\n",
    "    return None\n",
    "\n",
    "\n",
    "### Pullback shading\n",
    "\n",
    "\n",
    "def create_material_from_multilayer_array(mesh, array, material_name=\"ProjectedMaterial\"):\n",
    "    \"\"\"\n",
    "    Creates a material for a mesh using multi-channel, multi-layer projection.\n",
    "\n",
    "    Args:\n",
    "        obj (bpy.types.Object): The mesh object to which the material will be applied.\n",
    "        array (numpy.ndarray): 4D array of shape (channels, layers, U, V)\n",
    "        material_name (str): Name of the new material.\n",
    "    \"\"\"\n",
    "    # Validate and normalize input array\n",
    "    if not len(array.shape) == 4:\n",
    "        raise ValueError(\"Input array must have 4 axes.\")\n",
    "    array_normalized = normalize_quantiles(array, quantiles=(0.01, 0.99), channel_axis=0,\n",
    "                                           clip=True, data_type=None)\n",
    "    # Create a new image in Blender for each layer and channel\n",
    "    image_height, image_width = array.shape[-2:]\n",
    "    n_channels, n_layers = array.shape[:2]\n",
    "    images = {}\n",
    "    for ic, chanel in enumerate(array_normalized):\n",
    "        for il, layer in enumerate(chanel):\n",
    "            pixel_data = np.zeros((image_height, image_width, 4), dtype=np.float32)\n",
    "            pixel_data[..., 0] =  pixel_data[..., 1] = pixel_data[..., 2] = layer[::-1]\n",
    "            pixel_data[..., 3] = 1.0  # Alpha\n",
    "            pixel_data = pixel_data.flatten()\n",
    "            images[(ic, il)] = bpy.data.images.new(name=f\"Channel_{ic}_Layer_{il}\",\n",
    "                                                   width=image_width, height=image_height)\n",
    "            images[(ic, il)].pixels = pixel_data.tolist()\n",
    "    # Create a new material\n",
    "    material = bpy.data.materials.new(name=material_name)\n",
    "    material.use_nodes = True\n",
    "    nodes = material.node_tree.nodes\n",
    "    links = material.node_tree.links\n",
    "    # Clear default nodesx\n",
    "    for node in nodes:\n",
    "        nodes.remove(node)\n",
    "    # Add required nodes\n",
    "    texture_nodes = {}\n",
    "    for (ic, il), image in images.items():\n",
    "        texture_nodes[(ic, il)] = nodes.new(type=\"ShaderNodeTexImage\")\n",
    "        texture_nodes[(ic, il)].image = image\n",
    "        texture_nodes[(ic, il)].location = (-400, ic*400 + il*300)\n",
    "    \n",
    "    bsdf_node = nodes.new(type=\"ShaderNodeBsdfPrincipled\")\n",
    "    output_node = nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "\n",
    "    # Arrange nodes\n",
    "    bsdf_node.location = (0, 0)\n",
    "    output_node.location = (400, 0)\n",
    "\n",
    "    # Connect nodes\n",
    "    links.new(texture_nodes[(0,0)].outputs[\"Color\"], bsdf_node.inputs[\"Base Color\"])\n",
    "    links.new(bsdf_node.outputs[\"BSDF\"], output_node.inputs[\"Surface\"])\n",
    "\n",
    "    # Assign the material to the mesh\n",
    "    mesh.active_material = material\n",
    "    return None\n",
    "\n",
    "\n",
    "### Vertex shading\n",
    "\n",
    "\n",
    "def compute_edge_lengths(obj):\n",
    "    \"\"\"\n",
    "    Computes the lengths of all edges in a mesh object as a numpy array.\n",
    "\n",
    "    Args:\n",
    "        obj (bpy.types.Object): The mesh object to compute edge lengths for.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 1D array containing the lengths of all edges in the mesh.\n",
    "    \"\"\"\n",
    "    # Ensure the object is a mesh\n",
    "    if obj.type != 'MESH':\n",
    "        raise ValueError(\"The selected object is not a mesh.\")\n",
    "    # Ensure the mesh is in edit mode for accurate vertex data\n",
    "    bpy.context.view_layer.objects.active = obj\n",
    "    if obj.mode != 'OBJECT':\n",
    "        bpy.ops.object.mode_set(mode='OBJECT')\n",
    "    edge_lengths = []\n",
    "    for edge in obj.data.edges:\n",
    "        v1 = obj.data.vertices[edge.vertices[0]].co\n",
    "        v2 = obj.data.vertices[edge.vertices[1]].co\n",
    "        edge_lengths.append((v1 - v2).length)\n",
    "    return np.array(edge_lengths)\n",
    "\n",
    "\n",
    "def get_image_to_vertex_interpolator(obj, image_3d, resolution_array, quantiles=(0.01, 0.99)):\n",
    "    \"\"\"\n",
    "    Get interpolator that maps vertex position -> image intensity.\n",
    "    \n",
    "    Returns a list of interpolators, one for each channel.\n",
    "    To avoid aliasing, the 3d image is smoothed with\n",
    "    sigma=median edge length /2. The image data is also normalized to\n",
    "    range from 0-1 using the provided quantiles.\n",
    "    \"\"\"\n",
    "    anti_aliasing_scale = np.median(compute_edge_lengths(obj))/2\n",
    "    image_3d_smoothed = np.stack([ndimage.gaussian_filter(ch, anti_aliasing_scale/resolution_array)\n",
    "                                  for ch in image_3d])\n",
    "    image_3d_smoothed = normalize_quantiles(image_3d_smoothed,\n",
    "                                            quantiles=quantiles, clip=True, data_type=None)\n",
    "    x, y, z = [np.arange(ni)*resolution_array[i]\n",
    "               for i, ni in enumerate(image_3d.shape[1:])]\n",
    "    \n",
    "    return [interpolate.RegularGridInterpolator((x,y,z), ch, method='linear', bounds_error=False)\n",
    "            for ch in image_3d_smoothed]\n",
    "\n",
    "\n",
    "def assign_vertex_colors(obj, colors):\n",
    "    \"\"\"\n",
    "    Assigns an RGB color to each vertex in the given object.\n",
    "    Args:\n",
    "        obj: The mesh object.\n",
    "        colors: A list or dict of (R, G, B) tuples for each vertex.\n",
    "    \"\"\"\n",
    "    if obj.type != 'MESH':\n",
    "        print(\"Object is not a mesh!\")\n",
    "        return\n",
    "    if not obj.data.vertex_colors:\n",
    "        obj.data.vertex_colors.new()\n",
    "    color_layer = obj.data.vertex_colors.active\n",
    "    # Assign colors to each loop (face corner)\n",
    "    for loop in obj.data.loops:    \n",
    "        color_layer.data[loop.index].color = (*colors[loop.vertex_index], 1.0)  # RGBA\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_vertex_color_material(object, material_name=\"VertexColorMaterial\"):\n",
    "    \"\"\"\n",
    "    Creates a material for an object that uses vertex colors.\n",
    "    The R, G, and B channels are processed through separate \"Map Range\" nodes\n",
    "    to edit their brightness, and then combined into a Principled BSDF.\n",
    "\n",
    "    Args:\n",
    "        object (bpy.types.Object): The object to which the material will be applied.\n",
    "        material_name (str): Name of the new material.\n",
    "    \"\"\"\n",
    "    # Ensure the object has a vertex color layer\n",
    "    if not object.data.vertex_colors:\n",
    "        raise ValueError(\"The object has no vertex color layers.\")\n",
    "\n",
    "    # Create a new material\n",
    "    material = bpy.data.materials.new(name=material_name)\n",
    "    material.use_nodes = True\n",
    "    nodes = material.node_tree.nodes\n",
    "    links = material.node_tree.links\n",
    "\n",
    "    # Clear default nodes\n",
    "    for node in nodes:\n",
    "        nodes.remove(node)\n",
    "\n",
    "    # Add nodes\n",
    "    vertex_color_node = nodes.new(type=\"ShaderNodeVertexColor\")\n",
    "    vertex_color_node.layer_name = object.data.vertex_colors[0].name\n",
    "    vertex_color_node.location = (-1000, 0)\n",
    "\n",
    "    separate_color_node = nodes.new(type=\"ShaderNodeSeparateRGB\")\n",
    "    separate_color_node.location = (-800, 0)\n",
    "\n",
    "    map_range_r = nodes.new(type=\"ShaderNodeMapRange\")\n",
    "    map_range_r.label = \"Map Range R\"\n",
    "    map_range_r.location = (-600, 300)\n",
    "\n",
    "    map_range_g = nodes.new(type=\"ShaderNodeMapRange\")\n",
    "    map_range_g.label = \"Map Range G\"\n",
    "    map_range_g.location = (-600, 0)\n",
    "\n",
    "    map_range_b = nodes.new(type=\"ShaderNodeMapRange\")\n",
    "    map_range_b.label = \"Map Range B\"\n",
    "    map_range_b.location = (-600, -300)\n",
    "\n",
    "    combine_rgb = nodes.new(type=\"ShaderNodeCombineRGB\")\n",
    "    combine_rgb.location = (-200, 0)\n",
    "\n",
    "    bsdf_node = nodes.new(type=\"ShaderNodeBsdfPrincipled\")\n",
    "    bsdf_node.location = (000, 0)\n",
    "\n",
    "    output_node = nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "    output_node.location = (400, 0)\n",
    "\n",
    "    # Connect nodes\n",
    "    links.new(vertex_color_node.outputs[\"Color\"], separate_color_node.inputs[\"Image\"])\n",
    "    links.new(separate_color_node.outputs[\"R\"], map_range_r.inputs[\"Value\"])\n",
    "    links.new(separate_color_node.outputs[\"G\"], map_range_g.inputs[\"Value\"])\n",
    "    links.new(separate_color_node.outputs[\"B\"], map_range_b.inputs[\"Value\"])\n",
    "\n",
    "    links.new(map_range_r.outputs[\"Result\"], combine_rgb.inputs[\"R\"])\n",
    "    links.new(map_range_g.outputs[\"Result\"], combine_rgb.inputs[\"G\"])\n",
    "    links.new(map_range_b.outputs[\"Result\"], combine_rgb.inputs[\"B\"])\n",
    "\n",
    "    links.new(combine_rgb.outputs[\"Image\"], bsdf_node.inputs[\"Base Color\"])\n",
    "    links.new(bsdf_node.outputs[\"BSDF\"], output_node.inputs[\"Surface\"])\n",
    "\n",
    "    # Set default map range values for each channel\n",
    "    for map_range_node in [map_range_r, map_range_g, map_range_b]:\n",
    "        map_range_node.inputs[\"From Min\"].default_value = 0.0\n",
    "        map_range_node.inputs[\"From Max\"].default_value = 1.0\n",
    "        map_range_node.inputs[\"To Min\"].default_value = 0.0\n",
    "        map_range_node.inputs[\"To Max\"].default_value = 1.0\n",
    "\n",
    "    # Assign the material to the object\n",
    "    object.active_material = material\n",
    "    return None\n",
    "\n",
    "\n",
    "### Marching cubes\n",
    "\n",
    "\n",
    "def create_mesh_from_numpy(name, verts, faces):\n",
    "    \"\"\"\n",
    "    Creates a Blender mesh object from NumPy arrays of vertices and faces.\n",
    "    \n",
    "    :param name: Name of the new mesh object.\n",
    "    :param verts: NumPy array of shape (n, 3) containing vertex coordinates.\n",
    "    :param faces: NumPy array of shape (m, 3 or 4) containing face indices.\n",
    "    :return: The created mesh object.\n",
    "    \"\"\"\n",
    "    mesh = bpy.data.meshes.new(name)\n",
    "    obj = bpy.data.objects.new(name, mesh)\n",
    "    # Link the object to the scene\n",
    "    bpy.context.collection.objects.link(obj)\n",
    "    mesh.from_pydata(verts.tolist(), [], faces.tolist())\n",
    "    mesh.update()\n",
    "    return obj\n",
    "\n",
    "\n",
    "### Iterative closest point alignment\n",
    "\n",
    "\n",
    "def package_affine_transformation(matrix, vector):\n",
    "    \"\"\"Package matrix transformation & translation into (d+1,d+1) matrix representation of affine transformation.\"\"\"\n",
    "    matrix_rep = np.hstack([matrix, vector[:, np.newaxis]])\n",
    "    matrix_rep = np.pad(matrix_rep, ((0,1),(0,0)), constant_values=0)\n",
    "    matrix_rep[-1,-1] = 1\n",
    "    return matrix_rep\n",
    "\n",
    "\n",
    "def get_inertia(pts):\n",
    "    \"\"\"Get inertia tensor of 3d point cloud.\"\"\"\n",
    "    pts_nomean = pts - np.mean(pts, axis=0)\n",
    "    x, y, z = pts_nomean.T\n",
    "    Ixx = np.mean(x**2)\n",
    "    Ixy = np.mean(x*y)\n",
    "    Ixz = np.mean(x*z)\n",
    "    Iyy = np.mean(y**2)\n",
    "    Iyz = np.mean(y*z)\n",
    "    Izz = np.mean(z*z)\n",
    "    return np.array([[Ixx, Ixy, Ixz], [Ixy,Iyy, Iyz], [Ixz, Iyz, Izz]])\n",
    "\n",
    "\n",
    "def align_by_centroid_and_intertia(source, target, scale=True, shear=True, improper=False, n_samples=10000):\n",
    "    \"\"\"\n",
    "    Align source point cloud to target point cloud using affine transformation.\n",
    "    \n",
    "    Align by matching centroids and axes of inertia tensor. Since the inertia tensor is invariant\n",
    "    under reflections along its principal axes, all 2^3 reflections are tried and the one leading\n",
    "    to the best agreement with the target is chosen.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    source : np.array of shape (n_source, 3)\n",
    "        Point cloud to be aligned.\n",
    "    target : np.array of shape (n_target, 3)\n",
    "        Point cloud to align to.\n",
    "    scale : bool, default True\n",
    "        Whether to allow scale transformation (True) or rotations only (False)\n",
    "    shear : bool, default False\n",
    "        Whether to allow shear transformation (True) or rotations/scale only (False)\n",
    "    improper : bool, default False\n",
    "        Whether to allow transfomations with determinant -1\n",
    "    n_samples : int, optional\n",
    "        Number of samples of source to use when estimating distances.\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array, np.array\n",
    "        affine_matrix_rep : np.array of shape (4, 4)\n",
    "            Affine transformation source -> target\n",
    "        aligned : np.array of shape (n_source, 3)\n",
    "            Aligned coordinates\n",
    "    \"\"\"\n",
    "    target_centroid = np.mean(target, axis=0)\n",
    "    target_inertia = get_inertia(target)\n",
    "    target_eig = np.linalg.eigh(target_inertia)\n",
    "\n",
    "    source_centroid = np.mean(source, axis=0)\n",
    "    source_inertia = get_inertia(source)\n",
    "    source_eig = np.linalg.eigh(source_inertia)\n",
    "\n",
    "    flips = [np.diag([i,j,k]) for i, j, k in itertools.product(*(3*[[-1,1]]))]\n",
    "    trafo_matrix_candidates = []\n",
    "    tree = spatial.cKDTree(target)\n",
    "    samples = source[np.random.randint(low=0, high=source.shape[0], size=min([n_samples, source.shape[0]])),:]\n",
    "    distances = []\n",
    "    for flip in flips:\n",
    "        if shear:\n",
    "            trafo_matrix = (source_eig.eigenvectors\n",
    "                            @ np.diag(np.sqrt(target_eig.eigenvalues/source_eig.eigenvalues))\n",
    "                            @ flip @ target_eig.eigenvectors.T)\n",
    "        elif scale and not shear:\n",
    "            scale_fact = np.sqrt(stats.gmean(target_eig.eigenvalues)/stats.gmean(source_eig.eigenvalues))\n",
    "            trafo_matrix = scale_fact*source_eig.eigenvectors@flip@target_eig.eigenvectors.T\n",
    "        elif not scale and not shear:\n",
    "            trafo_matrix = source_eig.eigenvectors@flip@target_eig.eigenvectors.T\n",
    "        if not improper and np.linalg.det(trafo_matrix) < 0:\n",
    "            continue\n",
    "        trafo_matrix = trafo_matrix.T\n",
    "        trafo_matrix_candidates.append(trafo_matrix)\n",
    "        trafo_translate = target_centroid - trafo_matrix@source_centroid\n",
    "        aligned = samples@trafo_matrix.T + trafo_translate\n",
    "        distances.append(np.mean(tree.query(aligned)[0]))\n",
    "    trafo_matrix = trafo_matrix_candidates[np.argmin(distances)]\n",
    "    print('inferred rotation/scale', trafo_matrix)\n",
    "    trafo_translate = target_centroid - trafo_matrix@source_centroid\n",
    "    aligned = source@trafo_matrix.T + trafo_translate\n",
    "    affine_matrix_rep = package_affine_transformation(trafo_matrix, trafo_translate)\n",
    "    \n",
    "    print('inferred translation', trafo_translate)\n",
    "    return affine_matrix_rep, aligned\n",
    "\n",
    "\n",
    "def procrustes(source, target, scale=True):\n",
    "    \"\"\"\n",
    "    Procrustes analysis, a similarity test for two data sets.\n",
    "\n",
    "    Copied from scipy.spatial.procrustes, modified to return the transform\n",
    "    as an affine matrix, and return the transformed source data in the original,\n",
    "    non-normalized coordinates.\n",
    "\n",
    "    Each input matrix is a set of points or vectors (the rows of the matrix).\n",
    "    The dimension of the space is the number of columns of each matrix. Given\n",
    "    two identically sized matrices, procrustes standardizes both such that:\n",
    "\n",
    "    - tr(AA^T) = 1.\n",
    "    - Both sets of points are centered around the origin.\n",
    "\n",
    "    Procrustes then applies the optimal transform to the source matrix\n",
    "    (including scaling/dilation, rotations, and reflections) to minimize the\n",
    "    sum of the squares of the pointwise differences between the two input datasets.\n",
    "\n",
    "    This function is not designed to handle datasets with different numbers of\n",
    "    datapoints (rows).  If two data sets have different dimensionality\n",
    "    (different number of columns), simply add columns of zeros to the smaller\n",
    "    of the two.\n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source : array_like\n",
    "        Matrix, n rows represent points in k (columns) space. The data from\n",
    "        source will be transformed to fit the pattern in target.\n",
    "    target : array_like\n",
    "        Maxtrix, n rows represent points in k (columns) space. \n",
    "        target is the reference data. \n",
    "    scale : bool, default True\n",
    "        Whether to allow scaling transformations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trafo_affine : array_like\n",
    "        (4,4) array representing the affine transformation from source to target.\n",
    "    aligned : array_like\n",
    "        The orientation of source that best fits target.\n",
    "    disparity : float\n",
    "        np.linalg.norm(aligned-target, axis=1).mean()\n",
    "    \"\"\"\n",
    "    mtx1 = np.array(target, dtype=np.float64, copy=True)\n",
    "    mtx2 = np.array(source, dtype=np.float64, copy=True)\n",
    "\n",
    "    if mtx1.ndim != 2 or mtx2.ndim != 2:\n",
    "        raise ValueError(\"Input matrices must be two-dimensional\")\n",
    "    if mtx1.shape != mtx2.shape:\n",
    "        raise ValueError(\"Input matrices must be of same shape\")\n",
    "    if mtx1.size == 0:\n",
    "        raise ValueError(\"Input matrices must be >0 rows and >0 cols\")\n",
    "\n",
    "    # translate all the data to the origin\n",
    "    centroid1, centroid2 = (np.mean(mtx1, 0), np.mean(mtx2, 0))\n",
    "    mtx1 -= centroid1\n",
    "    mtx2 -= centroid2\n",
    "\n",
    "    # change scaling of data (in rows) such that trace(mtx*mtx') = 1\n",
    "    norm1 = np.linalg.norm(mtx1)\n",
    "    norm2 = np.linalg.norm(mtx2)\n",
    "    if norm1 == 0 or norm2 == 0:\n",
    "        raise ValueError(\"Input matrices must contain >1 unique points\")\n",
    "    mtx1 /= norm1\n",
    "    mtx2 /= norm2\n",
    "    # transform mtx2 to minimize disparity\n",
    "    R, s = linalg.orthogonal_procrustes(mtx1, mtx2)\n",
    "    mtx2 = np.dot(mtx2, R.T) * s\n",
    "\n",
    "    # retranslate and scale\n",
    "    aligned = norm1 * mtx2 + centroid1\n",
    "\n",
    "    # measure the dissimilarity between the two datasets\n",
    "    disparity = np.mean(np.linalg.norm(aligned-target, axis=1))\n",
    "\n",
    "    # assemble the linear transformation\n",
    "    if scale:\n",
    "        trafo_matrix = (norm1/norm2)*s*R\n",
    "    else:\n",
    "        trafo_matrix = (norm1/norm2)*R\n",
    "    trafo_translate = centroid1 - trafo_matrix@centroid2\n",
    "    trafo_affine = package_affine_transformation(trafo_matrix, trafo_translate)\n",
    "    return trafo_affine, aligned, disparity\n",
    "\n",
    "\n",
    "def icp(source, target, initial=None, threshold=1e-4, max_iterations=20, scale=True, n_samples=1000):\n",
    "    \"\"\"\n",
    "    Apply the iterative closest point algorithm to align point cloud a with\n",
    "    point cloud b. Will only produce reasonable results if the\n",
    "    initial transformation is roughly correct. Initial transformation can be\n",
    "    found by applying Procrustes' analysis to a suitable set of landmark\n",
    "    points (often picked manually), or by inertia+centroid based alignment,\n",
    "    implemented in align_by_centroid_and_intertia.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    source : (n,3) float\n",
    "      Source points in space.\n",
    "    target : (m,3) float or Trimesh\n",
    "      Target points in space or mesh.\n",
    "    initial : (4,4) float\n",
    "      Initial transformation.\n",
    "    threshold : float\n",
    "      Stop when change in cost is less than threshold\n",
    "    max_iterations : int\n",
    "      Maximum number of iterations\n",
    "    scale : bool, optional\n",
    "      Whether to allow dilations. If False, orthogonal procrustes is used\n",
    "    n_samples : int or None\n",
    "        If not None, n_samples sample points are randomly chosen from source array for distance computation\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    matrix : (4,4) float\n",
    "      The transformation matrix sending a to b\n",
    "    transformed : (n,3) float\n",
    "      The image of a under the transformation\n",
    "    cost : float\n",
    "      The cost of the transformation\n",
    "    \"\"\"\n",
    "    # initialize transform matrix\n",
    "    total_matrix = np.eye(4) if initial is None else initial\n",
    "    tree = spatial.cKDTree(target)\n",
    "    # subsample and apply initial transformation\n",
    "    samples = (source[np.random.randint(low=0, high=source.shape[0],\n",
    "                                        size=min([n_samples, source.shape[0]])),:]\n",
    "               if n_samples is not None else source[:])\n",
    "    samples = samples@total_matrix[:3,:3].T + total_matrix[:3,-1]\n",
    "    # start with infinite cost\n",
    "    old_cost = np.inf\n",
    "    # avoid looping forever by capping iterations\n",
    "    for i in range(max_iterations):\n",
    "        print('iteration', i, 'cost', old_cost) \n",
    "        # Find closest point in target to each point in sample and align\n",
    "        closest = target[tree.query(samples, 1)[1]]\n",
    "        matrix, samples, cost = procrustes(samples, closest, scale=scale)\n",
    "        # update a with our new transformed points\n",
    "        total_matrix = np.dot(matrix, total_matrix)\n",
    "        if old_cost - cost < threshold:\n",
    "            break\n",
    "        else:\n",
    "            old_cost = cost\n",
    "    aligned = source@total_matrix[:3,:3].T + total_matrix[:3,-1]\n",
    "    return total_matrix, aligned, cost\n",
    "\n",
    "\n",
    "def combined_alignment(source, target, pre_align=True, shear=False, iterations=100):\n",
    "    \"\"\"Align source to target by combination of moment-of-intertia based aligment + ICP\"\"\"\n",
    "    if pre_align:\n",
    "        trafo_initial, _ = align_by_centroid_and_intertia(source, target,\n",
    "                                                          scale=True, shear=shear, improper=False)\n",
    "    else:\n",
    "        trafo_initial = None\n",
    "    trafo_icp, _, _ = icp(source, target, initial=trafo_initial,\n",
    "                          threshold=1e-4, max_iterations=iterations,\n",
    "                          scale=True, n_samples=5000)\n",
    "    return trafo_icp\n",
    "\n",
    "\n",
    "### Shrink-wrapping\n",
    "\n",
    "\n",
    "def shrinkwrap_and_smooth(source_obj, target_obj, corrective_smooth_iter=0):\n",
    "    \"\"\"\n",
    "    Applies a shrinkwrap modifier with target_obj to source_obj, \n",
    "    optionally adds a corrective smooth modifier, and applies all modifiers.\n",
    "\n",
    "    Parameters:\n",
    "    - source_obj: The source mesh object to be modified.\n",
    "    - target_obj: The target mesh object for the shrinkwrap modifier.\n",
    "    - corrective_smooth_iter: (Optional) Number of iterations for the corrective smooth modifier. \n",
    "      If 0, no corrective smooth is applied.\n",
    "\n",
    "    Returns:\n",
    "    - bpy.types.Object: The new modified mesh object.\n",
    "    \"\"\"\n",
    "    # Ensure the objects are valid\n",
    "    if source_obj.type != 'MESH' or target_obj.type != 'MESH':\n",
    "        raise ValueError(\"Both source_obj and target_obj must be mesh objects.\")\n",
    "\n",
    "    # Store the currently active object\n",
    "    original_active_obj = bpy.context.view_layer.objects.active\n",
    "\n",
    "    # Add the first shrinkwrap modifier\n",
    "    shrinkwrap_1 = source_obj.modifiers.new(name=\"Shrinkwrap\", type='SHRINKWRAP')\n",
    "    shrinkwrap_1.target = target_obj\n",
    "    shrinkwrap_1.wrap_method = 'TARGET_PROJECT'\n",
    "\n",
    "    # Add a corrective smooth modifier if requested\n",
    "    for i in range(0, corrective_smooth_iter):\n",
    "        corrective_smooth = source_obj.modifiers.new(name=f\"Corrective Smooth {i}\", type='CORRECTIVE_SMOOTH')\n",
    "        corrective_smooth.iterations = 5\n",
    "        corrective_smooth.scale = 0\n",
    "        # Add a second shrinkwrap modifier after the corrective smooth\n",
    "        shrinkwrap_2 = source_obj.modifiers.new(name=f\"Shrinkwrap {i}\", type='SHRINKWRAP')\n",
    "        shrinkwrap_2.target = target_obj\n",
    "        shrinkwrap_2.wrap_method = 'TARGET_PROJECT'\n",
    "\n",
    "    # Apply all modifiers\n",
    "    bpy.context.view_layer.objects.active = source_obj\n",
    "    for modifier in source_obj.modifiers:\n",
    "        bpy.ops.object.modifier_apply(modifier=modifier.name)\n",
    "    # Restore the original active object\n",
    "    bpy.context.view_layer.objects.active = original_active_obj\n",
    "    return source_obj\n",
    "\n",
    "\n",
    "### Handling of mesh-associated array-data\n",
    "\n",
    "\n",
    "def set_numpy_attribute(mesh, name, array):\n",
    "    \"\"\"Sets mesh[name] = array.\n",
    "    \n",
    "    Since Blender does not support adding arbitrary objects as attributes to meshes,\n",
    "    the array is flattened, converted to a binary buffer, and saved as a tuple together with its shape.\n",
    "    All arrays are converted to np.float32.\n",
    "    \"\"\"\n",
    "    bytes, shape = (array.astype(np.float32).flatten().tobytes(), array.shape)\n",
    "    mesh[name] = (bytes, shape)\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_numpy_attribute(mesh, name):\n",
    "    \"\"\"Get array = mesh[name].\n",
    "    \n",
    "    Since Blender does not support adding arbitrary objects as attributes to meshes,\n",
    "    the array is flattened, converted to a binary buffer, and saved as a tuple together with its shape.\n",
    "    All arrays are converted to np.float32.\n",
    "    \"\"\"\n",
    "    assert name in mesh, \"Attribute not found\"\n",
    "    return np.frombuffer(mesh[name][0], dtype=np.float32).reshape(mesh[name][1])\n",
    "\n",
    "\n",
    "def separate_selected_into_mesh_and_box(self, context):\n",
    "    \"\"\"\n",
    "    Separate selected objects into mesh and box, representing 3D image data.\n",
    "    \n",
    "    If not exactly one mesh and one box (with attribute \"3D_data\") are selected,\n",
    "    an error is raised.\n",
    "    \"\"\"\n",
    "    n_data_selected = len([x for x in context.selected_objects if \"3D_data\" in x])\n",
    "    n_mesh_selected = len([x for x in context.selected_objects if not \"3D_data\" in x])\n",
    "    if not ((n_data_selected==1) and (n_mesh_selected==1)):\n",
    "        self.report({'ERROR'}, \"Select exactly one mesh and one 3D image (BoundingBox)!\")\n",
    "        return None, None\n",
    "    box = [x for x in context.selected_objects if \"3D_data\" in x][0]\n",
    "    obj = [x for x in context.selected_objects if not \"3D_data\" in x][0]\n",
    "    if not obj or obj.type != 'MESH':\n",
    "        self.report({'ERROR'}, \"No mesh object selected!\")\n",
    "        return None, None\n",
    "    return box, obj\n",
    "\n",
    "\n",
    "### Operators defining the user interface of the add-on\n",
    "\n",
    "\n",
    "class LoadTIFFOperator(Operator):\n",
    "    \"\"\"Load .tif file and resolution. Also creates a bounding box object.\"\"\"\n",
    "    bl_idname = \"scene.load_tiff\"\n",
    "    bl_label = \"Load TIFF File\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        file_path = bpy.path.abspath(context.scene.tissue_cartography_file)\n",
    "        resolution = np.array(context.scene.tissue_cartography_resolution)\n",
    "        self.report({'INFO'}, f\"Resolution loaded: {resolution}\")\n",
    "\n",
    "        # Load TIFF file as a NumPy array\n",
    "        if not (file_path.lower().endswith(\".tiff\") or file_path.lower().endswith(\".tif\")):\n",
    "            self.report({'ERROR'}, \"Selected file is not a TIFF\")\n",
    "            return {'CANCELLED'}\n",
    "        try:\n",
    "            data = tifffile.imread(file_path)\n",
    "            if not len(data.shape) in [3,4]:\n",
    "                self.report({'ERROR'}, \"Selected TIFF must have 3 or 4 axes.\")\n",
    "                return {'CANCELLED'}\n",
    "            # sort out axis order\n",
    "            axis_order_string = context.scene.tissue_cartography_axis_order\n",
    "            if not ''.join(sorted(axis_order_string)) in ['', 'xyz', 'cxyz']:\n",
    "                self.report({'ERROR'}, \"Must be empty, xyz, cxyz, or permutation thereof\")\n",
    "                return {'CANCELLED'}\n",
    "            if not len(axis_order_string) in [0, len(data.shape)]:\n",
    "                self.report({'ERROR'}, \"Number of axes in axis order does not match tiff data.\")\n",
    "                return {'CANCELLED'}\n",
    "            \n",
    "            if axis_order_string == '' and len(data.shape) == 4:\n",
    "                # ensure channel axis (assumed shortest axis) is 1st if no axis order provided.\n",
    "                channel_axis = np.argmin(data.shape)\n",
    "                data = np.moveaxis(data, channel_axis, 0)\n",
    "            if axis_order_string != '':\n",
    "                data = data.transpose(axis_order_to_transpose(axis_order_string))\n",
    "            if len(data.shape) == 3: # add singleton channel axis to single channel-data \n",
    "                data = data[np.newaxis]\n",
    "            # display image shape in add-on\n",
    "            context.scene.tissue_cartography_image_shape = str(data.shape[1:])\n",
    "            context.scene.tissue_cartography_image_channels = data.shape[0]\n",
    "            self.report({'INFO'}, f\"TIFF file loaded with shape {data.shape}\")\n",
    "            # create a bounding box mesh to represent the data\n",
    "            box = create_box(*(np.array(data.shape[1:])*resolution),\n",
    "                             name=f\"{Path(file_path).stem}_BoundingBox\",\n",
    "                             hide=False)\n",
    "            box.display_type = 'WIRE'\n",
    "            # attach the data to the box\n",
    "            set_numpy_attribute(box, \"resolution\", resolution)\n",
    "            set_numpy_attribute(box, \"3D_data\", data)\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.report({'ERROR'}, f\"Failed to load TIFF file: {e}\")\n",
    "            return {'CANCELLED'}\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class LoadSegmentationTIFFOperator(Operator):\n",
    "    \"\"\"\n",
    "    Load segmentation .tif file and resolution, and create a mesh from binary segmentation.\n",
    "    \n",
    "    Selecting a folder instead of a file batch processes all files in folder.\n",
    "    \"\"\"\n",
    "    bl_idname = \"scene.load_segmentation\"\n",
    "    bl_label = \"Load Segmentation TIFF File\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        # Load resolution as a NumPy array\n",
    "        resolution_array = np.array(context.scene.tissue_cartography_segmentation_resolution)\n",
    "        input_path = Path(bpy.path.abspath(context.scene.tissue_cartography_segmentation_file))\n",
    "        if input_path.is_dir():\n",
    "            files_to_process = [f for f in input_path.iterdir() if f.is_file() and f.suffix in [\".tif\", \".tiff\"]]\n",
    "        elif input_path.is_file():\n",
    "            files_to_process = [input_path]\n",
    "        else:\n",
    "            self.report({'ERROR'}, \"Select a valid file or directory\")\n",
    "            return {'CANCELLED'}\n",
    "        for file_path in files_to_process:\n",
    "            if not file_path.suffix in [\".tif\", \".tiff\"]:\n",
    "                self.report({'ERROR'}, \"Selected file is not a TIFF\")\n",
    "                return {'CANCELLED'}\n",
    "            try:\n",
    "                data = tifffile.imread(file_path)\n",
    "                # sort out axis order\n",
    "                if not len(data.shape) in [3,4]:\n",
    "                    self.report({'ERROR'}, \"Selected TIFF must have 3 or 4 axes.\")\n",
    "                    return {'CANCELLED'}\n",
    "                axis_order_string = context.scene.tissue_cartography_segmentation_axis_order\n",
    "                if not ''.join(sorted(axis_order_string)) in ['', 'xyz', 'cxyz']:\n",
    "                    self.report({'ERROR'}, \"Must be empty, xyz, cxyz, or permutation thereof\")\n",
    "                    return {'CANCELLED'}\n",
    "                if not len(axis_order_string) in [0, len(data.shape)]:\n",
    "                    self.report({'ERROR'}, \"Number of axes in axis order does not match tiff data.\")\n",
    "                    return {'CANCELLED'}\n",
    "                if axis_order_string == '' and len(data.shape) == 4:\n",
    "                    # ensure channel axis (assumed shortest axis) is 1st if no axis order provided.\n",
    "                    channel_axis = np.argmin(data.shape)\n",
    "                    data = np.moveaxis(data, channel_axis, 0)\n",
    "                if axis_order_string != '':\n",
    "                    data = data.transpose(axis_order_to_transpose(axis_order_string))\n",
    "                if len(data.shape) == 3: # add singleton channel axis to single channel-data \n",
    "                    data = data[np.newaxis]\n",
    "                self.report({'INFO'}, f\"TIFF file loaded with shape {data.shape}\")\n",
    "                context.scene.tissue_cartography_segmentation_shape = str(data.shape[1:])\n",
    "                context.scene.tissue_cartography_segmentation_channels = data.shape[0]\n",
    "                # iterate over channels. each channel is one label\n",
    "                for ic, channel in enumerate(data):\n",
    "                    # smooth and normalize the segmentation\n",
    "                    channel = (channel-channel.min())/(channel.max()-channel.min())\n",
    "                    sigma = context.scene.tissue_cartography_segmentation_sigma\n",
    "                    channel = ndimage.gaussian_filter(channel, sigma=sigma/resolution_array)\n",
    "                    # compute mesh using marching cubes, and convert to mesh\n",
    "                    verts, faces, _, _ = measure.marching_cubes(channel, level=0.5, spacing=(1.0,1.0,1.0))\n",
    "                    verts = verts * resolution_array\n",
    "                    create_mesh_from_numpy(f\"{Path(file_path).stem}_c{ic}\", verts, faces)\n",
    "                \n",
    "            except Exception as e:\n",
    "                self.report({'ERROR'}, f\"Failed to load segmentation: {e}\")\n",
    "                return {'CANCELLED'}\n",
    "        return {'FINISHED'}\n",
    "    \n",
    "\n",
    "class CreateProjectionOperator(Operator):\n",
    "    \"\"\"\n",
    "    Create a cartographic projection.\n",
    "    \n",
    "    Select one mesh and one 3d-image ([...]_BoundingBox) to project 3d image data\n",
    "    onto mesh surface.\n",
    "    \"\"\"\n",
    "    bl_idname = \"scene.create_projection\"\n",
    "    bl_label = \"Create Projection\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        # Validate selected object and UV map\n",
    "        box, obj = separate_selected_into_mesh_and_box(self, context)\n",
    "        if box is None or obj is None:\n",
    "            return {'CANCELLED'}\n",
    "        # Ensure the object has a UV map\n",
    "        if not obj.data.uv_layers:\n",
    "            self.report({'ERROR'}, \"The selected mesh does not have a UV map!\")\n",
    "            return {'CANCELLED'}\n",
    "        # Parse offsets into a NumPy array\n",
    "        offsets_str = context.scene.tissue_cartography_offsets\n",
    "        try:\n",
    "            offsets_array = np.array([float(x) for x in offsets_str.split(\",\") if x.strip()])\n",
    "            if offsets_array.size == 0:\n",
    "                offsets_array = np.array([0])\n",
    "            self.report({'INFO'}, f\"Offsets loaded: {offsets_array}\")\n",
    "        except ValueError as e:\n",
    "            self.report({'ERROR'}, f\"Invalid offsets input: {e}\")\n",
    "            return {'CANCELLED'}\n",
    "        # set offsets as property\n",
    "        set_numpy_attribute(obj, \"projection_offsets\", offsets_array)\n",
    "        \n",
    "        # Parse projection resolution\n",
    "        projection_resolution = context.scene.tissue_cartography_projection_resolution\n",
    "        self.report({'INFO'}, f\"Using projection resolution: {projection_resolution}\")\n",
    "\n",
    "        # texture bake normals and world positions\n",
    "        loop_uvs, loop_normals, loop_world_positions = get_uv_normal_world_per_loop(obj, filter_unique=True)\n",
    "        \n",
    "        baked_normals = bake_per_loop_values_to_uv(loop_uvs, loop_normals, \n",
    "                                                   image_resolution=projection_resolution)\n",
    "        baked_normals = (baked_normals.T/np.linalg.norm(baked_normals.T, axis=0)).T\n",
    "        baked_world_positions = bake_per_loop_values_to_uv(loop_uvs, loop_world_positions,\n",
    "                                                           image_resolution=projection_resolution)\n",
    "        # obtain UV layout and use it to get a mask\n",
    "        uv_layout_path = str(Path(bpy.path.abspath(\"//\")).joinpath(f'{obj.name}_UV_layout.png'))\n",
    "        mask = get_uv_layout(obj, uv_layout_path, projection_resolution)\n",
    "        baked_normals[~mask] = np.nan\n",
    "        baked_world_positions[~mask] = np.nan\n",
    "        \n",
    "        # create a pullback\n",
    "        box_world_inv = np.linalg.inv(np.array(box.matrix_world))\n",
    "        baked_data = bake_volumetric_data_to_uv(get_numpy_attribute(box, \"3D_data\"),\n",
    "                                                baked_world_positions, \n",
    "                                                get_numpy_attribute(box, \"resolution\"),\n",
    "                                                baked_normals, normal_offsets=offsets_array,\n",
    "                                                affine_matrix=box_world_inv)\n",
    "        # set results as attributes of the mesh\n",
    "        set_numpy_attribute(obj, \"baked_data\", baked_data)\n",
    "        set_numpy_attribute(obj, \"baked_normals\", baked_normals)\n",
    "        set_numpy_attribute(obj, \"baked_world_positions\", baked_world_positions)\n",
    "        # create texture\n",
    "        create_material_from_multilayer_array(obj, baked_data, material_name=f\"ProjectedMaterial_{obj.name}\")\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class SaveProjectionOperator(Operator):\n",
    "    \"\"\"Save cartographic projection to disk\"\"\"\n",
    "    bl_idname = \"scene.save_projection\"\n",
    "    bl_label = \"Save Projection\"\n",
    "    \n",
    "    filepath: bpy.props.StringProperty(subtype=\"FILE_PATH\")\n",
    "    \n",
    "    def invoke(self, context, event):\n",
    "        # Open file browser to choose the save location\n",
    "        context.window_manager.fileselect_add(self)\n",
    "        return {'RUNNING_MODAL'}\n",
    "    \n",
    "    def execute(self, context):\n",
    "        obj = context.active_object\n",
    "        if not obj or \"baked_data\" not in obj:\n",
    "            self.report({'ERROR'}, \"No baked data found on the active object!\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        # Get the baked data\n",
    "        baked_data = get_numpy_attribute(obj, \"baked_data\")\n",
    "        baked_normals = get_numpy_attribute(obj, \"baked_normals\")\n",
    "        baked_world_positions = get_numpy_attribute(obj, \"baked_world_positions\")\n",
    "        # Save the data to the chosen filepath\n",
    "        try:\n",
    "            tifffile.imwrite(self.filepath + \"_BakedNormals.tif\", baked_normals)\n",
    "            tifffile.imwrite(self.filepath + \"_BakedPositions.tif\", baked_world_positions)\n",
    "            tifffile.imwrite(self.filepath + \"_BakedData.tif\", baked_data.astype(np.float32),\n",
    "                             metadata={'axes': 'ZCYX'}, imagej=True)\n",
    "            self.report({'INFO'}, f\"Cartographic projection saved to {self.filepath}\")\n",
    "        except Exception as e:\n",
    "            self.report({'ERROR'}, f\"Failed to save data: {str(e)}\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class BatchProjectionOperator(Operator):\n",
    "    \"\"\"\n",
    "    Batch-process cartographic projections.\n",
    "    \n",
    "    Select all meshes to process (in blender) and one 3d-image ([...]_BoundingBox)\n",
    "    for resolution and relative position information. Further 3d .tiff files are read from\n",
    "    Batch Process Input directory. Mesh names should match .tiff file names.\n",
    "    \n",
    "    \"\"\"\n",
    "    bl_idname = \"scene.batch_projection\"\n",
    "    bl_label = \"Create Projections (Batch Mode)\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        try:\n",
    "            box = [x for x in context.selected_objects if \"3D_data\" in x][0]\n",
    "        except IndexError:\n",
    "            self.report({'ERROR'}, \"Select one 3D image (BoundingBox) for resolution and position information!\")\n",
    "            return\n",
    "        # get list of files\n",
    "        batch_path = Path(bpy.path.abspath(context.scene.tissue_cartography_batch_directory))\n",
    "        batch_out_path = Path(bpy.path.abspath(context.scene.tissue_cartography_batch_output_directory))\n",
    "        batch_files = {f.stem: f for f in list(batch_path.iterdir()) if ((f.suffix in [\".tif\", \".tiff\"]) and not \"Baked\" in f.stem)}\n",
    "        # match files to selected meshes\n",
    "        meshes_to_process = [obj for obj in context.selected_objects if obj != box]\n",
    "        mesh_names = [obj.name for obj in meshes_to_process]\n",
    "        matched = {obj.name: difflib.get_close_matches(obj.name, batch_files.keys(), n=1, cutoff=0.1)\n",
    "                   for obj in context.selected_objects if obj != box}\n",
    "        # parse axis order\n",
    "        axis_order = list(context.scene.tissue_cartography_axis_order)\n",
    "        if not sorted(axis_order) == [0,1,2,3]:\n",
    "            self.report({'ERROR'}, \"Axis order must be a permutation of [0,1,2,3] (e.g. [3,0,1,2])\")\n",
    "            return {'CANCELLED'}\n",
    "        # parse offsets into a NumPy array\n",
    "        offsets_str = context.scene.tissue_cartography_offsets\n",
    "        try:\n",
    "            offsets_array = np.array([float(x) for x in offsets_str.split(\",\") if x.strip()])\n",
    "            if offsets_array.size == 0:\n",
    "                offsets_array = np.array([0])\n",
    "            self.report({'INFO'}, f\"Offsets loaded: {offsets_array}\")\n",
    "        except ValueError as e:\n",
    "            self.report({'ERROR'}, f\"Invalid offsets input: {e}\")\n",
    "            return {'CANCELLED'}\n",
    "        # Parse projection resolution\n",
    "        projection_resolution = context.scene.tissue_cartography_projection_resolution\n",
    "        self.report({'INFO'}, f\"Using projection resolution: {projection_resolution}\")\n",
    "        # find box for position and resolution info\n",
    "        \n",
    "        for iobj, obj in enumerate(meshes_to_process):\n",
    "            self.report({'INFO'}, f\"Processing {iobj}/{len(meshes_to_process)}\")\n",
    "            if not obj.data.uv_layers:\n",
    "                self.report({'ERROR'}, f\"Mesh {obj.name} does not have a UV map!\")\n",
    "                return {'CANCELLED'}\n",
    "            # set offsets as property\n",
    "            set_numpy_attribute(obj, \"projection_offsets\", offsets_array)\n",
    "            # find the matching file\n",
    "            if len(matched[obj.name]) == 0:\n",
    "                self.report({'ERROR'}, \"No matching file found for {obj.name}!\")\n",
    "                return {'CANCELLED'}\n",
    "            file_path = batch_files[matched[obj.name][0]]\n",
    "            # load the 3D data\n",
    "            try:\n",
    "                data = tifffile.imread(file_path)\n",
    "                if not len(data.shape) in [3,4]:\n",
    "                    self.report({'INFO'}, f\"Selected TIFF for {obj.name} must have 3 or 4 axes.\")\n",
    "                    return {'CANCELLED'}\n",
    "                if len(data.shape) == 3: # add singleton channel axis to single channel-data \n",
    "                    data = data[np.newaxis]\n",
    "                # ensure channel axis (assumed shortest axis) is 1st\n",
    "                channel_axis = np.argmin(data.shape)\n",
    "                data = np.moveaxis(data, channel_axis, 0)\n",
    "                data = data.transpose(axis_order)\n",
    "            except:\n",
    "                self.report({'ERROR'}, f\"Failed loading TIFF for {obj.name}\")\n",
    "                return {'CANCELLED'}\n",
    "            # texture bake normals and world positions\n",
    "            loop_uvs, loop_normals, loop_world_positions = get_uv_normal_world_per_loop(obj, filter_unique=True)\n",
    "            \n",
    "            baked_normals = bake_per_loop_values_to_uv(loop_uvs, loop_normals, \n",
    "                                                       image_resolution=projection_resolution)\n",
    "            baked_normals = (baked_normals.T/np.linalg.norm(baked_normals.T, axis=0)).T\n",
    "            baked_world_positions = bake_per_loop_values_to_uv(loop_uvs, loop_world_positions,\n",
    "                                                               image_resolution=projection_resolution)\n",
    "            # obtain UV layout and use it to get a mask\n",
    "            uv_layout_path = str(Path(batch_out_path).joinpath(f'{obj.name}_UV_layout.png'))\n",
    "            mask = get_uv_layout(obj, uv_layout_path, projection_resolution)\n",
    "            baked_normals[~mask] = np.nan\n",
    "            baked_world_positions[~mask] = np.nan\n",
    "            # create a pullback\n",
    "            box_world_inv = np.linalg.inv(np.array(box.matrix_world))\n",
    "            baked_data = bake_volumetric_data_to_uv(data,\n",
    "                                                    baked_world_positions, \n",
    "                                                    get_numpy_attribute(box, \"resolution\"),\n",
    "                                                    baked_normals, normal_offsets=offsets_array,\n",
    "                                                    affine_matrix=box_world_inv)\n",
    "            # Save the data to the chosen filepath\n",
    "            try:\n",
    "                tifffile.imwrite(batch_out_path.joinpath(f\"{obj.name}_BakedNormals.tif\"), baked_normals)\n",
    "                tifffile.imwrite(batch_out_path.joinpath(f\"{obj.name}_BakedPositions.tif\"), baked_world_positions)\n",
    "                tifffile.imwrite(batch_out_path.joinpath(f\"{obj.name}_BakedData.tif\"), baked_data.astype(np.float32),\n",
    "                                 metadata={'axes': 'ZCYX'}, imagej=True)\n",
    "                self.report({'INFO'}, f\"Cartographic projection saved for {obj.name}\")\n",
    "            except Exception as e:\n",
    "                self.report({'ERROR'}, f\"Failed to save data for {obj.name}: {str(e)}\")\n",
    "                return {'CANCELLED'}\n",
    "            if bpy.context.scene.tissue_cartography_batch_create_materials:\n",
    "                # set results as attributes of the mesh\n",
    "                set_numpy_attribute(obj, \"baked_data\", baked_data)\n",
    "                set_numpy_attribute(obj, \"baked_normals\", baked_normals)\n",
    "                set_numpy_attribute(obj, \"baked_world_positions\", baked_world_positions)\n",
    "                # create texture\n",
    "                create_material_from_multilayer_array(obj, baked_data, material_name=f\"ProjectedMaterial_{obj.name}\")\n",
    "        return {'FINISHED'}\n",
    "    \n",
    "\n",
    "class SlicePlaneOperator(Operator):\n",
    "    \"\"\"Create a slice plane along the selected axis with texture from 3D data\"\"\"\n",
    "    bl_idname = \"scene.create_slice_plane\"\n",
    "    bl_label = \"Create Slice Plane\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        # Get the 3D data array from the selected box\n",
    "        box = context.active_object\n",
    "        if not box or not \"3D_data\" in box:\n",
    "            self.report({'ERROR'}, \"Select exactly a 3D image (BoundingBox)!\")\n",
    "            return {'CANCELLED'}\n",
    "        data = get_numpy_attribute(box, \"3D_data\")\n",
    "        \n",
    "        resolution = get_numpy_attribute(box, \"resolution\")\n",
    "        if not isinstance(data, np.ndarray) or data.ndim != 4:\n",
    "            self.report({'ERROR'}, \"Invalid 3D data array.\")\n",
    "            return {'CANCELLED'}\n",
    "        if context.scene.tissue_cartography_slice_channel >= data.shape[0]:\n",
    "            self.report({'ERROR'}, f\"Channel {context.scene.tissue_cartography_slice_channel} is out of bounds for the data array.\")\n",
    "            return {'CANCELLED'}\n",
    "\n",
    "        length, width, height = (np.array(data.shape[1:]) * resolution)\n",
    "        slice_plane = create_slice_plane(length, width, height, axis=context.scene.tissue_cartography_slice_axis,\n",
    "                                         position=context.scene.tissue_cartography_slice_position)\n",
    "        slice_plane.name = f\"{slice_plane.name}_{box.name}\"\n",
    "        # set matrix world\n",
    "        slice_plane.matrix_world = box.matrix_world\n",
    "                                         \n",
    "        slice_img = get_slice_image(data, resolution, axis=context.scene.tissue_cartography_slice_axis,\n",
    "                                    position=context.scene.tissue_cartography_slice_position)\n",
    "        slice_img = normalize_quantiles(slice_img, quantiles=(0.01, 0.99),\n",
    "                                        channel_axis=0, clip=True, data_type=None)     \n",
    "        create_material_from_array(slice_plane, slice_img[context.scene.tissue_cartography_slice_channel], material_name=f\"SliceMaterial_{box.name}_{context.scene.tissue_cartography_slice_axis}_{context.scene.tissue_cartography_slice_position}\")  \n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class VertexShaderInitializeOperator(Operator):\n",
    "    \"\"\"Initialize vertex shader for a selected mesh. Colors mesh vertices according to \n",
    "    3D image intensity from selected BoundingBox.\"\"\"\n",
    "    bl_idname = \"scene.initialize_vertex_shader\"\n",
    "    bl_label = \"Initialize Vertex Shader\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        # create global dict to hold interpolator objects\n",
    "        if not hasattr(bpy.types.Scene, \"tissue_cartography_interpolators\"):\n",
    "            bpy.types.Scene.tissue_cartography_interpolators = dict()\n",
    "        # get the selected mesh and bounding box\n",
    "        box, obj = separate_selected_into_mesh_and_box(self, context)\n",
    "        if box is None or obj is None:\n",
    "            return {'CANCELLED'}\n",
    "        # Get the 3D data array from the box object\n",
    "        data = get_numpy_attribute(box, \"3D_data\")\n",
    "        resolution = get_numpy_attribute(box, \"resolution\")\n",
    "     \n",
    "        if not isinstance(data, np.ndarray) or data.ndim != 4:\n",
    "            self.report({'ERROR'}, \"Invalid 3D data array.\")\n",
    "            return {'CANCELLED'}\n",
    "        if not obj or obj.type != 'MESH':\n",
    "            self.report({'ERROR'}, \"No mesh object selected!\")\n",
    "            return {'CANCELLED'}\n",
    "        if context.scene.tissue_cartography_vertex_shader_channel >= data.shape[0]:\n",
    "            self.report({'ERROR'}, f\"Channel {context.scene.tissue_cartography_vertex_shader_channel} is out of bounds for the data array.\")\n",
    "            return {'CANCELLED'}\n",
    "        # need to compute coordinates relative to matrix_world of box I think\n",
    "        set_numpy_attribute(obj, \"box_world_inv_vertex_shader\",\n",
    "                            np.array(box.matrix_world.inverted()))\n",
    "        bpy.types.Scene.tissue_cartography_interpolators[obj.name] = get_image_to_vertex_interpolator(obj, data, resolution)\n",
    "        box_inv = mathutils.Matrix(get_numpy_attribute(obj, \n",
    "                                   \"box_world_inv_vertex_shader\"))\n",
    "        positions = np.array([box_inv@obj.matrix_world@(v.co + context.scene.tissue_cartography_vertex_shader_offset*v.normal)\n",
    "                              for v in obj.data.vertices])\n",
    "        intensities = bpy.types.Scene.tissue_cartography_interpolators[obj.name][context.scene.tissue_cartography_vertex_shader_channel](positions)\n",
    "        colors = np.stack(3*[intensities,], axis=1)\n",
    "        \n",
    "        assign_vertex_colors(obj, colors)\n",
    "        create_vertex_color_material(obj, material_name=f\"VertexColorMaterial_{obj.name}\")\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class VertexShaderRefreshOperator(Operator):\n",
    "    \"\"\"Refresh vertex colors for a selected mesh. Colors mesh vertices according to \n",
    "    3D image intensity.\"\"\"\n",
    "    bl_idname = \"scene.refresh_vertex_shader\"\n",
    "    bl_label = \"Refresh Vertex Shader\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        obj = context.active_object\n",
    "        interpolator_dict = getattr(context.scene, \"tissue_cartography_interpolators\")\n",
    "        if not obj or obj.type != 'MESH':\n",
    "            self.report({'ERROR'}, \"No mesh object selected!\")\n",
    "            return {'CANCELLED'}\n",
    "        if interpolator_dict is None or obj.name not in interpolator_dict:\n",
    "            self.report({'ERROR'}, f\"Vertex shader not initialized.\")\n",
    "            return {'CANCELLED'}\n",
    "        if context.scene.tissue_cartography_vertex_shader_channel >= len(interpolator_dict[obj.name]):\n",
    "            self.report({'ERROR'}, f\"Channel {context.scene.tissue_cartography_vertex_shader_channel} is out of bounds for the data array.\")\n",
    "        box_inv = mathutils.Matrix(get_numpy_attribute(obj, \"box_world_inv_vertex_shader\"))\n",
    "        positions = np.array([box_inv@obj.matrix_world@(v.co + context.scene.tissue_cartography_vertex_shader_offset*v.normal)\n",
    "                              for v in obj.data.vertices])\n",
    "        intensities = interpolator_dict[obj.name][context.scene.tissue_cartography_vertex_shader_channel](positions)\n",
    "        colors = np.stack(3*[intensities,], axis=1)\n",
    "        assign_vertex_colors(obj, colors)\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class AlignOperator(Operator):\n",
    "    \"\"\"Align active and selected meshes by rotation, translation, and scaling.\"\"\"\n",
    "    bl_idname = \"scene.align\"\n",
    "    bl_label = \"Align Selected To Active Mesh\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        \n",
    "        if context.scene.tissue_cartography_align_type == \"selected\":\n",
    "            target_mesh = context.active_object\n",
    "            for source_mesh in [x for x in context.selected_objects if not x==target_mesh]:\n",
    "                self.report({'INFO'}, f\"Aligning: {source_mesh.name} to {target_mesh.name}\")\n",
    "                if target_mesh.type != 'MESH'  or source_mesh.type != 'MESH':\n",
    "                    self.report({'ERROR'}, \"Selected object(s) is not a mesh.\")\n",
    "                    return {'CANCELLED'}\n",
    "                # Get the 3D coordinates from the meshes\n",
    "                target = np.array([target_mesh.matrix_world@v.co for v in target_mesh.data.vertices])\n",
    "                source = np.array([source_mesh.matrix_world@v.co for v in source_mesh.data.vertices])\n",
    "                trafo_matrix = combined_alignment(source, target,\n",
    "                                                  pre_align=context.scene.tissue_cartography_prealign,\n",
    "                                                  shear=context.scene.tissue_cartography_prealign_shear,\n",
    "                                                  iterations=context.scene.tissue_cartography_align_iter)\n",
    "                source_mesh.matrix_world = mathutils.Matrix(trafo_matrix)@ source_mesh.matrix_world\n",
    "        elif context.scene.tissue_cartography_align_type == \"active\":\n",
    "            source_mesh = context.active_object\n",
    "            for target_mesh in [x for x in context.selected_objects if not x==source_mesh]:\n",
    "                self.report({'INFO'}, f\"Aligning: {source_mesh.name} to {target_mesh.name}\")\n",
    "                if target_mesh.type != 'MESH'  or source_mesh.type != 'MESH':\n",
    "                    self.report({'ERROR'}, \"Selected object(s) is not a mesh.\")\n",
    "                    return {'CANCELLED'}\n",
    "                # Get the 3D coordinates from the meshes and compute alignment\n",
    "                target = np.array([target_mesh.matrix_world@v.co for v in target_mesh.data.vertices])\n",
    "                source = np.array([source_mesh.matrix_world@v.co for v in source_mesh.data.vertices])\n",
    "                trafo_matrix = combined_alignment(source, target,\n",
    "                                                  pre_align=context.scene.tissue_cartography_prealign,\n",
    "                                                  shear=context.scene.tissue_cartography_prealign_shear,\n",
    "                                                  iterations=context.scene.tissue_cartography_align_iter)\n",
    "                # copy source mesh\n",
    "                source_mesh_copied = source_mesh.copy()\n",
    "                source_mesh_copied.data = source_mesh.data.copy()\n",
    "                bpy.context.collection.objects.link(source_mesh_copied)\n",
    "                source_mesh_copied.name = f\"{target_mesh.name}_aligned\" \n",
    "                source_mesh_copied.matrix_world = mathutils.Matrix(trafo_matrix)@ source_mesh.matrix_world\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class ShrinkwrapOperator(Operator):\n",
    "    \"\"\"Copy and shrink-wrap active mesh to selected meshes.\"\"\"\n",
    "    bl_idname = \"scene.shrinkwrap\"\n",
    "    bl_label = \"Shrink-Wrap Active to Selected\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        mode = context.scene.tissue_cartography_shrinkwarp_iterative\n",
    "        source_mesh = context.active_object\n",
    "        targets = sorted([x for x in context.selected_objects if not x==source_mesh], key=lambda x: x.name)\n",
    "        if mode == \"backward\":\n",
    "            targets = targets[::-1]\n",
    "        for target_mesh in targets:\n",
    "            self.report({'INFO'}, f\"Aligning: {source_mesh.name} to {target_mesh.name}\")\n",
    "            if target_mesh.type != 'MESH'  or source_mesh.type != 'MESH':\n",
    "                self.report({'ERROR'}, \"Selected object(s) is not a mesh.\")\n",
    "                return {'CANCELLED'}\n",
    "            # rigid alignment\n",
    "            target = np.array([target_mesh.matrix_world@v.co for v in target_mesh.data.vertices])\n",
    "            source = np.array([source_mesh.matrix_world@v.co for v in source_mesh.data.vertices])\n",
    "            trafo_matrix = combined_alignment(source, target,\n",
    "                                              pre_align=context.scene.tissue_cartography_prealign,\n",
    "                                              shear=context.scene.tissue_cartography_prealign_shear,\n",
    "                                              iterations=context.scene.tissue_cartography_align_iter)\n",
    "            # copy source mesh\n",
    "            source_mesh_copied = source_mesh.copy()\n",
    "            source_mesh_copied.data = source_mesh.data.copy()\n",
    "            bpy.context.collection.objects.link(source_mesh_copied)\n",
    "            source_mesh_copied.matrix_world = mathutils.Matrix(trafo_matrix)@ source_mesh.matrix_world\n",
    "            source_mesh_copied.name = f\"{target_mesh.name}_wrapped\" \n",
    "            # shrink-wrap\n",
    "            shrinkwrap_and_smooth(source_mesh_copied, target_mesh,\n",
    "                                  corrective_smooth_iter=context.scene.tissue_cartography_shrinkwarp_smooth)\n",
    "            # data transfer modifier to copy UV map from wrapped to target\n",
    "            data_transfer = target_mesh.modifiers.new(name=\"DataTransfer\", type='DATA_TRANSFER')\n",
    "            data_transfer.object = source_mesh_copied\n",
    "            data_transfer.use_loop_data = True\n",
    "            data_transfer.data_types_loops = {'UV'}\n",
    "            data_transfer.loop_mapping = 'POLYINTERP_NEAREST'\n",
    "            # apply\n",
    "            original_active_obj = bpy.context.view_layer.objects.active\n",
    "            bpy.context.view_layer.objects.active = target_mesh\n",
    "            bpy.ops.object.datalayout_transfer(modifier=\"DataTransfer\")\n",
    "            bpy.ops.object.modifier_apply(modifier=\"DataTransfer\")\n",
    "            bpy.context.view_layer.objects.active = original_active_obj\n",
    "                                  \n",
    "            if mode in [\"forward\", \"backward\"]:\n",
    "                source_mesh = source_mesh_copied\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class HelpPopupOperator(Operator):\n",
    "    \"\"\"Open help window.\"\"\"\n",
    "    bl_idname = \"scene.help_popup\"\n",
    "    bl_label = \"Tissue Cartography Help\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        url = \"https://nikolas-claussen.github.io/blender-tissue-cartography/Tutorials/03_blender_addon_tutorial.html\"\n",
    "        bpy.ops.wm.url_open(url=url)\n",
    "        return {'FINISHED'}\n",
    "        \n",
    "        \n",
    "class TissueCartographyPanel(Panel):\n",
    "    \"\"\"Class defining layout of user interface (buttons, inputs, etc.)\"\"\"\n",
    "    bl_label = \"Tissue Cartography\"\n",
    "    bl_idname = \"SCENE_PT_tissue_cartography\"\n",
    "    bl_space_type = 'PROPERTIES'\n",
    "    bl_region_type = 'WINDOW'\n",
    "    bl_context = \"scene\"\n",
    "\n",
    "    def draw(self, context):\n",
    "        layout = self.layout\n",
    "        scene = context.scene\n",
    "\n",
    "        layout.prop(scene, \"tissue_cartography_file\")\n",
    "        row_tiff = layout.row()\n",
    "        row_tiff.prop(scene, \"tissue_cartography_resolution\")\n",
    "        row_tiff.prop(scene, \"tissue_cartography_axis_order\")\n",
    "        layout.operator(\"scene.load_tiff\", text=\"Load .tiff file\")\n",
    "        layout.label(text=f\"Loaded Image Shape: {scene.tissue_cartography_image_shape}. Loaded Image Channels: {scene.tissue_cartography_image_channels}\")\n",
    "        layout.separator()\n",
    "        \n",
    "        layout.prop(scene, \"tissue_cartography_segmentation_file\")\n",
    "        row_segmentation = layout.row()\n",
    "        row_segmentation.prop(scene, \"tissue_cartography_segmentation_resolution\")\n",
    "        row_segmentation.prop(scene, \"tissue_cartography_segmentation_axis_order\")\n",
    "        row_segmentation.prop(scene, \"tissue_cartography_segmentation_sigma\")\n",
    "        layout.operator(\"scene.load_segmentation\", text=\"Get mesh(es) from binary segmentation .tiff file(s)\")\n",
    "        layout.label(text=f\"Loaded Segmentation Shape: {scene.tissue_cartography_segmentation_shape}. Loaded Segmentation Channels: {scene.tissue_cartography_segmentation_channels}\")\n",
    "        layout.separator()\n",
    "        \n",
    "        row_slice = layout.row()\n",
    "        row_slice.prop(scene, \"tissue_cartography_slice_axis\")\n",
    "        row_slice.prop(scene, \"tissue_cartography_slice_position\")\n",
    "        row_slice.prop(scene, \"tissue_cartography_slice_channel\")\n",
    "        layout.operator(\"scene.create_slice_plane\", text=\"Create slice plane\")\n",
    "        layout.separator()\n",
    "        \n",
    "        row_vertex = layout.row()\n",
    "        row_vertex.prop(scene, \"tissue_cartography_vertex_shader_offset\")\n",
    "        row_vertex.prop(scene, \"tissue_cartography_vertex_shader_channel\")\n",
    "        row_vertex2 = layout.row()\n",
    "        row_vertex2.operator(\"scene.initialize_vertex_shader\", text=\"Initialize vertex shading\")\n",
    "        row_vertex2.operator(\"scene.refresh_vertex_shader\", text=\"Refresh vertex shading\")\n",
    "        layout.separator()\n",
    "        \n",
    "        row_projection = layout.row()\n",
    "        row_projection.prop(scene, \"tissue_cartography_offsets\")\n",
    "        row_projection.prop(scene, \"tissue_cartography_projection_resolution\")\n",
    "        row_projection2 = layout.row()\n",
    "        row_projection2.operator(\"scene.create_projection\", text=\"Create Projection\")\n",
    "        row_projection2.operator(\"scene.save_projection\", text=\"Save Projection\")\n",
    "        layout.separator()\n",
    "        \n",
    "        row_batch = layout.row()\n",
    "        row_batch.prop(scene, \"tissue_cartography_batch_directory\")\n",
    "        row_batch.prop(scene, \"tissue_cartography_batch_output_directory\")\n",
    "        row_batch.prop(scene, \"tissue_cartography_batch_create_materials\")\n",
    "        layout.operator(\"scene.batch_projection\", text=\"Batch Process And Save\")\n",
    "        layout.separator()\n",
    "        \n",
    "        row_align = layout.row()\n",
    "        row_align.prop(scene, \"tissue_cartography_prealign\")\n",
    "        row_align.prop(scene, \"tissue_cartography_prealign_shear\")\n",
    "        row_align.prop(scene, \"tissue_cartography_align_type\")\n",
    "        row_align.prop(scene, \"tissue_cartography_align_iter\")\n",
    "        layout.operator(\"scene.align\", text=\"Align Meshes\")\n",
    "        layout.separator()\n",
    "        \n",
    "        row_shrinkwrap = layout.row()\n",
    "        row_shrinkwrap.prop(scene, \"tissue_cartography_shrinkwarp_smooth\")\n",
    "        row_shrinkwrap.prop(scene, \"tissue_cartography_shrinkwarp_iterative\")\n",
    "        layout.operator(\"scene.shrinkwrap\", text=\"Shrinkwrap Meshes (Active To Selected)\")\n",
    "        layout.separator()\n",
    "        \n",
    "        layout.operator(\"scene.help_popup\", text=\"Show help\", icon='HELP')\n",
    "    \n",
    "\n",
    "### Add the add-on to the user interface\n",
    "\n",
    "\n",
    "def register():\n",
    "    \"\"\"Add the add-on to the blender user interface\"\"\"\n",
    "    bpy.utils.register_class(TissueCartographyPanel)\n",
    "    bpy.utils.register_class(LoadTIFFOperator)\n",
    "    bpy.utils.register_class(LoadSegmentationTIFFOperator)\n",
    "    bpy.utils.register_class(CreateProjectionOperator)\n",
    "    bpy.utils.register_class(SaveProjectionOperator)\n",
    "    bpy.utils.register_class(BatchProjectionOperator)\n",
    "    bpy.utils.register_class(SlicePlaneOperator)\n",
    "    bpy.utils.register_class(VertexShaderInitializeOperator)\n",
    "    bpy.utils.register_class(VertexShaderRefreshOperator)\n",
    "    bpy.utils.register_class(AlignOperator)\n",
    "    bpy.utils.register_class(ShrinkwrapOperator)\n",
    "    bpy.utils.register_class(HelpPopupOperator)\n",
    "    \n",
    "    bpy.types.Scene.tissue_cartography_file = StringProperty(\n",
    "        name=\"File Path\",\n",
    "        description=\"Path to the TIFF file\",\n",
    "        subtype='FILE_PATH',\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_resolution = FloatVectorProperty(\n",
    "        name=\"x/y/z Resolution (m)\",\n",
    "        description=\"Resolution in microns along x, y, z axes\",\n",
    "        size=3,\n",
    "        default=(1.0, 1.0, 1.0),\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_axis_order= StringProperty(\n",
    "        name=\"Axis order\",\n",
    "        description=\"Axis order, either xyz + permutations or xyz + permutations (multichannel data). Dynamic data should be loaded as one .tiff per timepoint. If not provided, inferred automatically.\",\n",
    "        default=\"\",\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_image_channels = IntProperty(\n",
    "        name=\"Image Channels\",\n",
    "        description=\"Channels of the loaded image (read-only)\",\n",
    "        default=0,\n",
    "        min=0,\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_image_shape = StringProperty(\n",
    "        name=\"Image Shape\",\n",
    "        description=\"Shape of the loaded image (read-only)\",\n",
    "        default=\"Not loaded\"\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_segmentation_file = StringProperty(\n",
    "        name=\"Segmentation File Path\",\n",
    "        description=\"Path to the segmentation TIFF file. Should have values between 0-1. Selecting a folder instead of a single file will batch-process the full folder.\",\n",
    "        subtype='FILE_PATH',\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_segmentation_resolution = FloatVectorProperty(\n",
    "        name=\"Segmentation x/y/z Resolution (m)\",\n",
    "        description=\"Resolution of segmentation in microns along x, y, z axes\",\n",
    "        size=3,\n",
    "        default=(1.0, 1.0, 1.0),\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_segmentation_axis_order= StringProperty(\n",
    "        name=\"Axis order segmentation\",\n",
    "        description=\"Axis order of segmentation, either xyz + permutations or cxyz + permutations (multichannel data). Different channels for a segmentation mean different labels. Dynamic data should be loaded as one .tiff per timepoint. If not provided, inferred automatically.\",\n",
    "        default=\"\",\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_segmentation_sigma = FloatProperty(\n",
    "        name=\"Smoothing (m)\",\n",
    "        description=\"Smothing kernel for extracting mesh from segmentation, in m\",\n",
    "        default=0,\n",
    "        min=0\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_segmentation_channels = IntProperty(\n",
    "        name=\"Segmentation Channels\",\n",
    "        description=\"Channels of the segmentation (read-only)\",\n",
    "        default=0,\n",
    "        min=0,\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_segmentation_shape = StringProperty(\n",
    "        name=\"Segmentation Shape\",\n",
    "        description=\"Shape of the loaded segmentation (read-only)\",\n",
    "        default=\"Not loaded\"\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_slice_axis = EnumProperty(\n",
    "        name=\"Slice Axis\",\n",
    "        description=\"Choose an axis\",\n",
    "        items=[('x', \"X-Axis\", \"Align to the X axis\"),\n",
    "               ('y', \"Y-Axis\", \"Align to the Y axis\"),\n",
    "               ('z', \"Z-Axis\", \"Align to the Z axis\")],\n",
    "        default='x'\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_slice_position = FloatProperty(\n",
    "        name=\"Slice Position (m)\",\n",
    "        description=\"Position along the selected axis in m\",\n",
    "        default=0\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_slice_channel = IntProperty(\n",
    "        name=\"Slice Channel\",\n",
    "        description=\"Channel for slice plane\",\n",
    "        default=0,\n",
    "        min=0,\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_vertex_shader_offset = FloatProperty(\n",
    "        name=\"Vertex Shader Normal Offset (m)\",\n",
    "        description=\"Normal offse for vertex shading.\",\n",
    "        default=0,\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_vertex_shader_channel = IntProperty(\n",
    "        name=\"Vertex Shader Channel\",\n",
    "        description=\"Channel for vertex shading.\",\n",
    "        default=0,\n",
    "        min=0,\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_offsets = StringProperty(\n",
    "        name=\"Normal Offsets (m)\",\n",
    "        description=\"Comma-separated list of floats for multilayer projection offsets\",\n",
    "        default=\"0\",\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_projection_resolution = IntProperty(\n",
    "        name=\"Projection Format (Pixels)\",\n",
    "        description=\"Resolution for the projection (e.g., 1024 for 1024x1024 pixels)\",\n",
    "        default=1024,\n",
    "        min=1,\n",
    "    )\n",
    "    \n",
    "    bpy.types.Scene.tissue_cartography_batch_directory = StringProperty(\n",
    "        name=\"Batch Process Input Directory\",\n",
    "        description=\"Path to TIFF files directory\",\n",
    "        subtype='DIR_PATH',\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_batch_output_directory = StringProperty(\n",
    "        name=\"Batch Process Output Directory\",\n",
    "        description=\"Path to TIFF files directory\",\n",
    "        subtype='DIR_PATH',\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_batch_create_materials = BoolProperty(\n",
    "        name=\"Create materials\",\n",
    "        description=\"Enable or disable creating materials with projected texture in batch mode. Enabling can result in large .blend files.\",\n",
    "        default=True\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_prealign = BoolProperty(\n",
    "        name=\"Pre-align?\",\n",
    "        description=\"Enable or disable pre-alignment. Do not use if the two meshes are already closely aligned.\",\n",
    "        default=True\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_prealign_shear = BoolProperty(\n",
    "        name=\"Allow shear\",\n",
    "        description=\"Allow shear transformation during alignment.\",\n",
    "        default=True\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_align_type = EnumProperty(\n",
    "        name=\"Align Mode\",\n",
    "        description=\"Choose an axis\",\n",
    "        items=[('selected', \"Selected to Active\", \"Align selected meshes to active mesh.\"),\n",
    "               ('active', \"Active to Selected\", \"Align active mesh to selected meshe (creates copies of active mesh).\")],\n",
    "        default='selected'\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_align_iter = IntProperty(\n",
    "        name=\"Iterations\",\n",
    "        description=\"ICP iterations during alignment.\",\n",
    "        default=100,\n",
    "        min=1,\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_shrinkwarp_smooth = IntProperty(\n",
    "        name=\"Shrinkwrap Corrective Smooth\",\n",
    "        description=\"Corrective smooth iterations during shrink-wrapping.\",\n",
    "        default=10,\n",
    "        min=0,\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_shrinkwarp_iterative = EnumProperty(\n",
    "        name=\"Shrinkwrap Mode\",\n",
    "        description=\"Choose an axis\",\n",
    "        items=[('one-to-all', \"One-To-All\", \"Shrink-wrap active mesh to each selected individually\"),\n",
    "               ('forward', \"Iterative Forward\", \"Shrink-wrap active mesh to selected meshes iteratively, starting with alpha-numerically first\"),\n",
    "               ('backward', \"Iterative Backward\", \"Shrink-wrap active mesh to selected meshes iteratively, starting with alpha-numerically last\")],\n",
    "        default='one-to-all'\n",
    "    )\n",
    "\n",
    "def unregister():\n",
    "    bpy.utils.unregister_class(TissueCartographyPanel)\n",
    "    bpy.utils.unregister_class(LoadTIFFOperator)\n",
    "    bpy.utils.unregister_class(LoadSegmentationTIFFOperator)\n",
    "    bpy.utils.unregister_class(CreateProjectionOperator)\n",
    "    bpy.utils.unregister_class(BatchProjectionOperator)\n",
    "    bpy.utils.unregister_class(SaveProjectionOperator)\n",
    "    bpy.utils.unregister_class(SlicePlaneOperator)\n",
    "    bpy.utils.unregister_class(VertexShaderInitializeOperator)\n",
    "    bpy.utils.unregister_class(VertexShaderRefreshOperator)\n",
    "    bpy.utils.unregister_class(AlignOperator)\n",
    "    bpy.utils.unregister_class(ShrinkwrapOperator)\n",
    "    bpy.utils.unregister_class(HelpPopupOperator)\n",
    "\n",
    "    del bpy.types.Scene.tissue_cartography_file \n",
    "    del bpy.types.Scene.tissue_cartography_resolution\n",
    "    del bpy.types.Scene.tissue_cartography_axis_order\n",
    "    del bpy.types.Scene.tissue_cartography_image_channels\n",
    "    del bpy.types.Scene.tissue_cartography_image_shape\n",
    "    del bpy.types.Scene.tissue_cartography_segmentation_file\n",
    "    del bpy.types.Scene.tissue_cartography_segmentation_resolution\n",
    "    del bpy.types.Scene.tissue_cartography_segmentation_axis_order\n",
    "    del bpy.types.Scene.tissue_cartography_segmentation_sigma\n",
    "    del bpy.types.Scene.tissue_cartography_segmentation_channels\n",
    "    del bpy.types.Scene.tissue_cartography_segmentation_shape\n",
    "    del bpy.types.Scene.tissue_cartography_offsets \n",
    "    del bpy.types.Scene.tissue_cartography_projection_resolution \n",
    "    del bpy.types.Scene.tissue_cartography_slice_axis \n",
    "    del bpy.types.Scene.tissue_cartography_slice_position \n",
    "    del bpy.types.Scene.tissue_cartography_slice_channel \n",
    "    del bpy.types.Scene.tissue_cartography_vertex_shader_offset \n",
    "    del bpy.types.Scene.tissue_cartography_vertex_shader_channel\n",
    "    del bpy.types.Scene.tissue_cartography_prealign \n",
    "    del bpy.types.Scene.tissue_cartography_prealign_shear\n",
    "    del bpy.types.Scene.tissue_cartography_align_iter\n",
    "    del bpy.types.Scene.tissue_cartography_align_type\n",
    "    del bpy.types.Scene.tissue_cartography_batch_directory\n",
    "    del bpy.types.Scene.tissue_cartography_batch_output_directory\n",
    "    del bpy.types.Scene.tissue_cartography_batch_create_materials\n",
    "    del bpy.types.Scene.tissue_cartography_shrinkwarp_smooth\n",
    "    del bpy.types.Scene.tissue_cartography_shrinkwarp_iterative\n",
    "    \n",
    "    if bpy.types.Scene.tissue_cartography_interpolators in globals():\n",
    "        del bpy.types.Scene.tissue_cartography_interpolators\n",
    "\n",
    "### Run the add-on\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    register()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:blender-tissue-cartography] *",
   "language": "python",
   "name": "conda-env-blender-tissue-cartography-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
