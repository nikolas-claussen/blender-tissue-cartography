{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8c94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ea96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from skimage.io import imread, imsave\n",
    "import h5py\n",
    "from typing import Iterable\n",
    "import tifffile\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49966bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import mcubes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5514327",
   "metadata": {},
   "source": [
    "## Basic I/O\n",
    "\n",
    "In this notebook, we define a number of functions for image, mesh, and metadata loading and saving, and show how to use the with the data from the ``basics_example`` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a586f315",
   "metadata": {},
   "source": [
    "## Load and subsample data for segmentation\n",
    "\n",
    "Let's load the dataset. We then enter the relevant metadata - the filename, resolution in microns, and how much we want to subsample for segmentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c7e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def adjust_axis_order(image, channel_axis=None):\n",
    "    \"\"\"\n",
    "    Adjust axis order of image (numpy array) so that the channel axis is axis 0. \n",
    "    \n",
    "    If channel axis is not specified, it is infered as the axis with the smallest number of entries.\n",
    "    If the image contains a single channel, this function adds a singleton dimension.\n",
    "    Axis order is otherwise left unchanged. Image must have 3 axes (single channel volumetric)\n",
    "    or four axes (multichannel volumetric). \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image: np.ndarray with 3 or 4 axes\n",
    "        Input image.\n",
    "    channel_axis: int or None, optional\n",
    "        Channel axis\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    transposed image: np.ndarray with 4 axes\n",
    "        Input image, channel now axis 0.\n",
    "    \"\"\"\n",
    "    assert 2 < len(image.shape) <5 , \"image must have 3 or 4 axes\"\n",
    "    if len(image.shape) == 3:\n",
    "        return image[np.newaxis]\n",
    "    if channel_axis is None:\n",
    "        channel_axis = np.argmin(image.shape)\n",
    "    return np.moveaxis(image, channel_axis, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2346a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_dict = {'filename': 'basics_example/basics_example',\n",
    "                 'resolution_in_microns': (1, 0.36, 0.36), # you can typically get this from the .tif metadata\n",
    "                 'subsampling_factors': (1, 1/3, 1/3),\n",
    "                 'normal_offsets':np.linspace(-2, 2, 5) # normal offsets for map projection, in microns\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fa308e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image shape: (2, 26, 454, 511)\n"
     ]
    }
   ],
   "source": [
    "image = adjust_axis_order(imread(f\"{metadata_dict['filename']}.tif\"))\n",
    "print(\"image shape:\", image.shape) # image shape - spatial axes are in z-x-y order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1981c01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampled image shape: (2, 26, 151, 170)\n"
     ]
    }
   ],
   "source": [
    "subsampled_image = transform.rescale(image, metadata_dict['subsampling_factors'],\n",
    "                                     channel_axis=0, preserve_range=True)\n",
    "print(\"subsampled image shape:\", subsampled_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901857d3",
   "metadata": {},
   "source": [
    "## Create 3d segmentation\n",
    "\n",
    "Now create a 3d segmentation, in this case using ilatik. ilastik works best with input saved as `.h5` data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eb13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def save_h5(filename, image, h5_dataset_name=\"image\"):\n",
    "    \"\"\"Save image (numpy array) as .h5 file (e.g. as input for ilastik).\"\"\"\n",
    "    with h5py.File(filename, \"w\") as f:\n",
    "        f.create_dataset('image', data=image)\n",
    "    return None\n",
    "\n",
    "def load_h5(filename):\n",
    "    \"\"\"Load .h5 file (e.g. ilastik output) into numpy array. Loads alphabetically first entry in .h5.\"\"\"\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        arr = f[sorted(f.keys())[0]][()] \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c33c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now save the subsampled image a .h5 file for input into ilastik for segmentation\n",
    "\n",
    "save_h5(f\"{metadata_dict['filename']}_subsampled.h5\", subsampled_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e77650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmentation shape: (26, 151, 170)\n"
     ]
    }
   ],
   "source": [
    "# after creating an ilastik project, training the model, and exporting the probabilities, we load the segmentation\n",
    "\n",
    "segmentation = load_h5(f\"{metadata_dict['filename']}_subsampled-image_Probabilities.h5\")\n",
    "segmentation = segmentation[0] # select the first channel of the segmentation - it's the probablity a pixel\n",
    "                               # is part of the sample\n",
    "print(\"segmentation shape:\", segmentation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at the segmentation in a cross section\n",
    "\n",
    "plt.imshow(segmentation[:,:,50], vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c012870",
   "metadata": {},
   "source": [
    "## Meshing\n",
    "\n",
    "We convert the segmentation into a triangular mesh using the marching cubes method, and save the mesh. We introduce a couple of functions for mesh io and mesh handling. We save all meshes in as wavefront `.obj` files (see [wikipedia](https://en.wikipedia.org/wiki/Wavefront_.obj_file)). In python, we represent missing entries (such as a vertex which doesn't have a normal by `np.nan`.\n",
    "\n",
    "**Important convention** For sanities sake, we will always store all mesh coordinates in microns. This means rescaling appropriately after calculating the mesh from the 3d segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d84ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def flatten(lst, max_depth=1000, iter_count=0):\n",
    "    \"\"\"\n",
    "    Flatten a list of lists into a list.\n",
    "\n",
    "    Also works with inhomogeneous lists, e.g., [[0,1],2]. The argument\n",
    "    depth determines how \"deep\" to flatten the list, e.g. with max_depth=1:\n",
    "    [[(1,0), (1,0)]] -> [(1,0), (1,0)].\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    lst : list\n",
    "        list-of-lists.\n",
    "    max_depth : int, optional\n",
    "        To what depth to flatten the list.\n",
    "    iter_count : int, optional\n",
    "        Helper argument for recursion depth determination.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    iterator\n",
    "        flattened list.\n",
    "    \"\"\"\n",
    "    for el in lst:\n",
    "        if (isinstance(el, Iterable) and not isinstance(el, (str, bytes))\n",
    "                and iter_count < max_depth):\n",
    "            yield from flatten(el, max_depth=max_depth,\n",
    "                               iter_count=iter_count+1)\n",
    "        else:\n",
    "            yield el\n",
    "            \n",
    "def str_to_int_or_nan(x):\n",
    "    \"\"\"Convert string to int or np.nan if string is empty\"\"\"\n",
    "    if x == '':\n",
    "        return np.nan\n",
    "    return int(x)\n",
    "\n",
    "def int_or_nan_to_str(x):\n",
    "    \"\"\"Convert int/nan to string. np.nan is converted to empty string\"\"\"\n",
    "    if np.isnan(x):\n",
    "        return ''\n",
    "    return str(x)\n",
    "\n",
    "def pad_list(lst, length=3, fill_value=np.nan):\n",
    "    \"\"\"Pad end of list with fill_value if shorter than desired length.\"\"\"\n",
    "    return lst + max([0, (length-len(lst))]) * [fill_value,]\n",
    "\n",
    "def read_obj(filename):\n",
    "    \"\"\"\n",
    "    Return vertices, texture vertices, normals, and faces from an obj file.\n",
    "    \n",
    "    Faces are lists of 3-tuples vertex/texture vertex/normal. If a certain vertex has no texture or normal \n",
    "    associated to it, the entry is np.nan, else it is an index into the vertex, texture, and normal arrays\n",
    "    (note: indices of returned faces start at 0!). See https://en.wikipedia.org/wiki/Wavefront_.obj_file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        filename\n",
    "    Returns\n",
    "    -------\n",
    "    mesh: dict with entries \"vertices\", \"texture_vertices\", \"normals\", and \"faces\"\n",
    "        vertices, texture_vertices, and normals are np.arrays, faces is a list of lists.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    vs = np.array([ln.split()[1:] for ln in lines if ln.startswith(\"v \")]).astype(float)\n",
    "    vts = np.array([ln.split()[1:] for ln in lines if ln.startswith(\"vt \")]).astype(float)\n",
    "    ns = np.array([ln.split()[1:] for ln in lines if ln.startswith(\"vn \")]).astype(float)\n",
    "    fs = [ln.split()[1:] for ln in lines if ln.startswith(\"f \")]\n",
    "    fs = [[pad_list([str_to_int_or_nan(y)-1 for y in x.split(\"/\")], length=3, fill_value=np.nan)\n",
    "           for x in f] for f in fs]\n",
    "    mesh = {\"vertices\": vs, \"texture_vertices\": vts, \"normals\": ns, \"faces\": fs}\n",
    "    return mesh\n",
    "\n",
    "def write_obj(filename, faces, vertices, texture_vertices=None, normals=None, indices_start_at_one=False):\n",
    "    \"\"\"\n",
    "    Write mesh to .obj format\n",
    "    \n",
    "    Can write texture coordinates and normals if included. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        filename to save to\n",
    "    vertices : np.array of shape (..., 3)\n",
    "        vertices\n",
    "    faces : list \n",
    "        Faces. A face can be either a list of vertex indices, or a list of vertex/texture/normal index tuples.\n",
    "        Indices can be np.nan or None to represent missing data.\n",
    "    texture_vertices: np.array of shape (..., 2), optional\n",
    "        Texture vertices\n",
    "    normals: np.array of shape (..., 3), optional\n",
    "         Normals\n",
    "    indices_start_at_one : bool, default True\n",
    "        Whether face indices start at one or at 0.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    faces_include_texture = all([isinstance(v, Iterable) for v in flatten(faces, max_depth=1)])\n",
    "    if not faces_include_texture:\n",
    "        with open(filename, 'w') as f:\n",
    "            for v in vertices:\n",
    "                f.write(\"v {} {} {}\\n\".format(*v))\n",
    "            for fc in faces:\n",
    "                if not indices_start_at_one:\n",
    "                    fc = [v+1 for v in fc]\n",
    "                f.write(\"f {} {} {}\\n\".format(*fc))\n",
    "    if faces_include_texture:\n",
    "        assert all([len(v) ==3 for v in flatten(faces, max_depth=1)]), \"each vertex should contain 3 indices\"\n",
    "        texture_vertices = [] if texture_vertices is None else texture_vertices\n",
    "        normals = [] if normals is None else normals\n",
    "        with open(filename, 'w') as f:\n",
    "            for v in vertices:\n",
    "                f.write(\"v {} {} {}\\n\".format(*v))\n",
    "            for vt in texture_vertices:\n",
    "                f.write(\"vt {} {}\\n\".format(*vt))\n",
    "            for n in normals:\n",
    "                f.write(\"vn {} {} {}\\n\".format(*n))\n",
    "            for fc in faces:\n",
    "                if not indices_start_at_one:\n",
    "                    fc = [[ix+1 for ix in v] for v in fc]\n",
    "                fc = [[int_or_nan_to_str(ix) for ix in v] for v in fc]\n",
    "                f.write(\"f {} {} {}\\n\".format(*[\"{}/{}/{}\".format(*v) for v in fc]))\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574ed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def match_vertex_info(faces, vertices, texture_vertices, normals):\n",
    "    \"\"\"\n",
    "    Match up 3d vertex coordinates / texture coordinates / normals based on face connectivity.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    faces : list\n",
    "        List of faces. Each face is a list of vertex/texture vertex/normal array index triples. Indices start at 0!\n",
    "    vertices : np.array of shape (..., 3)\n",
    "        Vertices\n",
    "    texture_vertices: np.array of shape (..., 2)\n",
    "        Texture vertices\n",
    "    normals: np.array of shape (..., 3)\n",
    "         Normals\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict with entries:\n",
    "        vertices : np.array of shape (n_matched, 3)\n",
    "            Matched vertices\n",
    "        texture_vertices: np.array of shape (n_matched, 2)\n",
    "            Matched texture vertices\n",
    "        normals: np.array of shape (n_matched, 3)\n",
    "            Matched normals\n",
    "\n",
    "    \"\"\"\n",
    "    unique_v_vt_n_pairs = set([tuple(x) for x in flatten([fc for fc in faces\n",
    "                                                      if not np.isnan(list(flatten(fc))).any()], max_depth=1)])\n",
    "\n",
    "    matched_vertices = np.stack([vertices[ix[0]] for ix in unique_v_vt_n_pairs])\n",
    "    matched_texture_vertices = np.stack([texture_vertices[ix[1]] for ix in unique_v_vt_n_pairs])\n",
    "    matched_normals = np.stack([normals[ix[2]] for ix in unique_v_vt_n_pairs])\n",
    "    return {\"vertices\": matched_vertices,\n",
    "            \"texture_vertices\": matched_texture_vertices,\n",
    "            \"normals\": matched_normals}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5541aa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create a 3d mesh of using the marching cubes method\n",
    "\n",
    "level_set = mcubes.smooth(segmentation, method=\"gaussian\") # converts segmentation into level set, with 0=surface\n",
    "vertices, faces = mcubes.marching_cubes(level_set, 0)\n",
    "\n",
    "# EXTREMELY IMPORTANT - we now rescale the vertex coordinates so that they are in microns.\n",
    "vertices_in_microns = vertices * (np.array(metadata_dict['resolution_in_microns'])\n",
    "                                 /np.array(metadata_dict['subsampling_factors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_obj(f\"{metadata_dict['filename']}_mesh_marching_cubes.obj\", faces, vertices_in_microns,\n",
    "          indices_start_at_one=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf752cb2",
   "metadata": {},
   "source": [
    "### Saving the results\n",
    "\n",
    "We can now save the cartographic projections both as `.tif` stack for quantitative analysis, and as `.png`'s for visualization as mesh texture in blender. We will also save the metadata to a `.json` file\n",
    "\n",
    "Annoyingly, we have to normalize our data and convert it to 8-bit to save it as png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce60c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def save_dict_to_json(filename, dictionary):\n",
    "    \"\"\"\n",
    "    Save dictionary to .json file.\n",
    "    \n",
    "    Will automatically convert numpy arrays to lists for saving. If you get an error like \"XXX is not JSON\n",
    "    serializable\", you need to ensure all your dictionary items are things that can be saved to text by json\n",
    "    (strings, numbers, lists).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : str\n",
    "        Filename to save to\n",
    "    dictionary : dict\n",
    "        Dictionary to save\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    serializable_dictionary = {key: val.tolist() if isinstance(val, np.ndarray) else val\n",
    "                               for key, val in dictionary.items()}\n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(serializable_dictionary, f)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823262d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save metadata\n",
    "save_dict_to_json(f\"{metadata_dict['filename']}_metadata.json\", metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70038a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def save_for_imageJ(filename, image, z_axis=None, channel_axis=None):\n",
    "    \"\"\"\n",
    "    Save image as 32bit ImageJ compatible .tif file\n",
    "    \n",
    "    If channel_axis is not provided, it is inferred as the shortest axis.\n",
    "    If z-axis is provided for a 4d array, it will be set as the default z-axis for ImageJ.\n",
    "    \"\"\"\n",
    "    channel_axis = np.argmin(image.shape) if channel_axis is None else channel_axis\n",
    "    if len(image.shape) == 3:\n",
    "        transposed_image = np.moveaxis(image, channel_axis, 0)\n",
    "        tifffile.imwrite(filename, transposed_image.astype(np.float32),\n",
    "                         metadata={'axes': 'CYX'}, imagej=True,)\n",
    "    elif len(image.shape) == 4:\n",
    "        if z_axis is not None:\n",
    "            transposed_image = np.moveaxis(image, (z_axis, channel_axis), (0,1))\n",
    "        else:\n",
    "            transposed_image = np.moveaxis(image, channel_axis, 1)\n",
    "        tifffile.imwrite(filename, transposed_image.astype(np.float32),\n",
    "                         metadata={'axes': 'ZCYX'}, imagej=True,)\n",
    "    return None\n",
    "    \n",
    "def normalize_quantiles_for_png(image, quantiles=(0.01, 0.99)):\n",
    "    \"\"\"\n",
    "    Normalize an image by setting given quantiles to 0 and 255 and converting to 8-bit, for saving as .png\n",
    "    \n",
    "    Also replaces nan by 0.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Image (should be single-channel)\n",
    "    quantiles : tuple\n",
    "        Image quantile to set to 0 and 255.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image_normalized : np.array\n",
    "        Normalized image, datatype np.uint8\n",
    "    \"\"\"\n",
    "    image_normalized = image - np.nanquantile(image, quantiles[0])\n",
    "    image_normalized /= np.nanquantile(image_normalized, quantiles[1])\n",
    "    image_normalized = np.nan_to_num(np.round(np.clip(255*image_normalized, 0, 255)), nan=0)\n",
    "    return image_normalized.astype(np.uint8)\n",
    "    \n",
    "    \n",
    "def save_stack_for_blender(image, directory, normalization=(0.01, 0.99)):\n",
    "    \"\"\"\n",
    "    Save multichannel volumetric image as series of grayscale .png images. Can normalize data if desired.\n",
    "    \n",
    "    This function necessarily converts the image to 8bit. Use a suitable normalization to ensure nothing \n",
    "    is lost.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : 4d np.array\n",
    "        Axis 0 is assumed to be the channel axis, axis 1 is the slicing axes, i.e. images will correspond to\n",
    "        slices along axis 1.\n",
    "    directory : str\n",
    "        Path to save data to. Will create directory if it doesn't exist\n",
    "    normalization : tuple of float, or callable\n",
    "        Whether to normalize the image before saving it. If None, no normalization is performed. If a\n",
    "        tuple is given, it will be interpreted as quantiles to set to 0 and 255, respectively (over the\n",
    "        whole channel, not each slice). If a callable is provided, it will be applied to each channel.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    directory = directory.removesuffix('/')\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    for ic, ch in enumerate(image):\n",
    "        if callable(normalization):\n",
    "            ch_normalized = normalization(ch)\n",
    "        if isinstance(normalization, tuple):\n",
    "            ch_normalized = normalize_quantiles_for_png(ch, quantiles=normalization)\n",
    "        for islc, slc in enumerate(ch_normalized):\n",
    "            slc = np.stack(3*[slc], axis=-1).astype(np.uint8) # necessary for saving as png\n",
    "            imsave(f'{directory}/channel_{ic}_slice_{str(islc).zfill(3)}.png', slc, check_contrast=False)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399116f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape (2, 5, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "# read the data so we can check the saving function\n",
    "projected_data = adjust_axis_order(imread(f\"{metadata_dict['filename']}_projected.tif\"))\n",
    "print(\"Image shape\", projected_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c131da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_for_imageJ(f\"{metadata_dict['filename']}_projected.tif\", projected_data, z_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e2ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_path = f\"{os.getcwd()}/{metadata_dict['filename']}_textures\"\n",
    "save_stack_for_blender(projected_data, texture_path, normalization=(0.01, 0.99))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
