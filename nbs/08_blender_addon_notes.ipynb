{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fff66780-4538-49e7-a1e2-4b1030fad4ec",
   "metadata": {},
   "source": [
    "## Blender add-on notes\n",
    "\n",
    "> Create add-on for blender to do mesh-creation from segmentation and pullbacks from within blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "827788fb-9c2e-4e2b-a2fa-5622bad5d41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from blender_tissue_cartography import io as tcio\n",
    "from blender_tissue_cartography import mesh as tcmesh\n",
    "\n",
    "from blender_tissue_cartography import interpolation as tcinterp\n",
    "from blender_tissue_cartography import rotation as tcrot\n",
    "from blender_tissue_cartography import diffgeo as tcdfg\n",
    "\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "import igl\n",
    "\n",
    "from scipy import interpolate, ndimage, optimize, sparse, spatial\n",
    "from skimage import registration, transform\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e544e92-380e-4dc3-9346-72c7257212b8",
   "metadata": {},
   "source": [
    "### Experiment with the tutorial dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8248f6d-b137-4ff4-bc29-b995ef409b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial_mesh = tcmesh.ObjMesh.read_obj(\"Tutorials/drosophila_example/Drosophila_CAAX-mCherry_mesh_remeshed.obj\")\n",
    "tutorial_data = tcio.imread(\"Tutorials/drosophila_example/Drosophila_CAAX-mCherry.tif\")\n",
    "resolution_array = np.array([1.05, 1.05, 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f43ac9b2-d4a3-4353-9e16-6afa68c4d3c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 7.15691042]),\n",
       " array([191.57263898, 523.00282661, 186.64725986]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tutorial_mesh.vertices.min(axis=0), tutorial_mesh.vertices.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6fc19e4d-297d-4c68-8122-ef68d36cd881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 509, 188)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tutorial_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cc2a6a51-7fe0-4209-81e9-727d4f2bf9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = np.linalg.norm(tutorial_mesh.vertices[tutorial_mesh.faces[:,0]] - tutorial_mesh.vertices[tutorial_mesh.faces[:,1]], axis=1)\n",
    "anti_aliasing_scale = np.median(ls)/2\n",
    "tutorial_data_smoothed = ndimage.gaussian_filter(tutorial_data, anti_aliasing_scale/resolution_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbdf2f48-66f8-4c06-bbee-14baba99adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = [np.arange(ni)/resolution_array[i] for i, ni in enumerate(tutorial_data.shape)]\n",
    "\n",
    "interpolator = interpolate.RegularGridInterpolator((x,y,z), tutorial_data_smoothed, method='linear', bounds_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16511d3f-69ee-4584-9cf0-6c42b9dc233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    baked_data = []\n",
    "    for o in normal_offsets:\n",
    "        baked_layer_data = np.stack([interpolate.interpn((x, y, z), channel,\n",
    "                                     (baked_world_positions+o*baked_normals)/resolution,\n",
    "                                     method=\"linear\", bounds_error=False) for channel in image])\n",
    "        baked_data.append(baked_layer_data)\n",
    "    baked_data = np.stack(baked_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bf032d-444a-4de9-a0c1-f37ba29e0b48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d460d92f-e6bf-497d-88bc-81ff43d5acf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = (3, 10, 40, 40)\n",
    "arr = np.random.normal(size=shape)\n",
    "np.allclose(np.array(arr.tolist()).reshape(shape), arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f5d50dfd-c934-4f77-9797-81a565aa7274",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.normal(size=(1000,1000,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d2c513df-1c87-4c1a-9298-4d6f948fca13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.51 s, sys: 450 ms, total: 6.96 s\n",
      "Wall time: 6.96 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[-3.39334310e-02, -3.25001619e-02, -3.01559763e-02, ...,\n",
       "          3.01606432e-02,  3.84222384e-02,  4.29556282e-02],\n",
       "        [-3.50301492e-02, -3.36526904e-02, -3.14067043e-02, ...,\n",
       "          2.86426603e-02,  3.66980625e-02,  4.11168310e-02],\n",
       "        [-3.69279141e-02, -3.56413538e-02, -3.35532689e-02, ...,\n",
       "          2.59516585e-02,  3.36097662e-02,  3.78064303e-02],\n",
       "        ...,\n",
       "        [-2.20244096e-02, -2.18784777e-02, -2.15578943e-02, ...,\n",
       "         -3.91593486e-02, -4.28806787e-02, -4.48153980e-02],\n",
       "        [-1.89296449e-02, -1.88159862e-02, -1.85722334e-02, ...,\n",
       "         -3.21406552e-02, -3.52243591e-02, -3.68219489e-02],\n",
       "        [-1.72245335e-02, -1.71274879e-02, -1.69230168e-02, ...,\n",
       "         -2.83505424e-02, -3.10802602e-02, -3.24907098e-02]],\n",
       "\n",
       "       [[-3.26145738e-02, -3.13082272e-02, -2.91692788e-02, ...,\n",
       "          2.55707444e-02,  3.33638298e-02,  3.76390111e-02],\n",
       "        [-3.37027537e-02, -3.24474623e-02, -3.03983635e-02, ...,\n",
       "          2.41603056e-02,  3.17499198e-02,  3.59122091e-02],\n",
       "        [-3.55909324e-02, -3.44173149e-02, -3.25099875e-02, ...,\n",
       "          2.16613348e-02,  2.88587373e-02,  3.28022417e-02],\n",
       "        ...,\n",
       "        [-2.06383689e-02, -2.05390227e-02, -2.02998619e-02, ...,\n",
       "         -3.67766975e-02, -4.01598491e-02, -4.19144293e-02],\n",
       "        [-1.76555196e-02, -1.75849090e-02, -1.74155253e-02, ...,\n",
       "         -2.98331412e-02, -3.25737181e-02, -3.39886167e-02],\n",
       "        [-1.60200195e-02, -1.59637030e-02, -1.58290377e-02, ...,\n",
       "         -2.60846115e-02, -2.84681745e-02, -2.96943534e-02]],\n",
       "\n",
       "       [[-2.99852380e-02, -2.88996982e-02, -2.71146002e-02, ...,\n",
       "          1.72493333e-02,  2.41711724e-02,  2.79656463e-02],\n",
       "        [-3.10648221e-02, -3.00214410e-02, -2.83105561e-02, ...,\n",
       "          1.60214613e-02,  2.27450427e-02,  2.64299822e-02],\n",
       "        [-3.29474909e-02, -3.19685995e-02, -3.03694120e-02, ...,\n",
       "          1.38459814e-02,  2.01870871e-02,  2.36596838e-02],\n",
       "        ...,\n",
       "        [-1.81175235e-02, -1.80881527e-02, -1.79725099e-02, ...,\n",
       "         -3.22232578e-02, -3.49865867e-02, -3.64113224e-02],\n",
       "        [-1.53667019e-02, -1.53579057e-02, -1.52960842e-02, ...,\n",
       "         -2.54330830e-02, -2.75479520e-02, -2.86300143e-02],\n",
       "        [-1.38731812e-02, -1.38735166e-02, -1.38364010e-02, ...,\n",
       "         -2.17699705e-02, -2.35240967e-02, -2.44155084e-02]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 4.19104115e-02,  3.83663422e-02,  3.15527433e-02, ...,\n",
       "          6.97919453e-02,  7.60308795e-02,  7.93938094e-02],\n",
       "        [ 4.22808788e-02,  3.88899641e-02,  3.23682455e-02, ...,\n",
       "          6.68616064e-02,  7.32509870e-02,  7.66939406e-02],\n",
       "        [ 4.33002142e-02,  4.01837423e-02,  3.41863232e-02, ...,\n",
       "          6.16735419e-02,  6.83414011e-02,  7.19331758e-02],\n",
       "        ...,\n",
       "        [ 1.52671972e-05, -2.79619620e-03, -7.80591339e-03, ...,\n",
       "         -1.42003604e-02, -1.67039008e-02, -1.82080231e-02],\n",
       "        [ 1.89657089e-03, -1.17308883e-03, -6.66808847e-03, ...,\n",
       "         -1.22017336e-02, -1.48974792e-02, -1.65083541e-02],\n",
       "        [ 2.63027815e-03, -5.65810097e-04, -6.29886634e-03, ...,\n",
       "         -1.09601214e-02, -1.37354634e-02, -1.53910856e-02]],\n",
       "\n",
       "       [[ 4.24044567e-02,  3.86259732e-02,  3.13636314e-02, ...,\n",
       "          7.89628707e-02,  8.59822376e-02,  8.97751052e-02],\n",
       "        [ 4.30221955e-02,  3.94084023e-02,  3.24592274e-02, ...,\n",
       "          7.57031908e-02,  8.28493129e-02,  8.67087451e-02],\n",
       "        [ 4.45438129e-02,  4.12246565e-02,  3.48371266e-02, ...,\n",
       "          6.98933686e-02,  7.72740149e-02,  8.12573504e-02],\n",
       "        ...,\n",
       "        [ 8.39492457e-04, -2.21121462e-03, -7.66945345e-03, ...,\n",
       "         -1.63531859e-02, -1.87428227e-02, -2.01747632e-02],\n",
       "        [ 3.49961965e-03,  1.64958304e-04, -5.82970408e-03, ...,\n",
       "         -1.46047154e-02, -1.72422690e-02, -1.88089325e-02],\n",
       "        [ 4.63957379e-03,  1.16550903e-03, -5.09309570e-03, ...,\n",
       "         -1.35044301e-02, -1.62531933e-02, -1.78805097e-02]],\n",
       "\n",
       "       [[ 4.25729742e-02,  3.86690721e-02,  3.11670935e-02, ...,\n",
       "          8.37290835e-02,  9.11526656e-02,  9.51682612e-02],\n",
       "        [ 4.33185697e-02,  3.95858895e-02,  3.24091157e-02, ...,\n",
       "          8.02927472e-02,  8.78287337e-02,  9.19027905e-02],\n",
       "        [ 4.51016809e-02,  4.16750321e-02,  3.50809422e-02, ...,\n",
       "          7.41492925e-02,  8.18932311e-02,  8.60762139e-02],\n",
       "        ...,\n",
       "        [ 1.18562721e-03, -1.99456412e-03, -7.69562480e-03, ...,\n",
       "         -1.74691769e-02, -1.97897598e-02, -2.11774063e-02],\n",
       "        [ 4.27732090e-03,  7.99323226e-04, -5.46577503e-03, ...,\n",
       "         -1.58522899e-02, -1.84507410e-02, -1.99880576e-02],\n",
       "        [ 5.64290254e-03,  2.01850247e-03, -4.52455675e-03, ...,\n",
       "         -1.48268274e-02, -1.75535722e-02, -1.91600917e-02]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ndimage.gaussian_filter(arr, sigma=(4,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86f6dce7-53d0-4604-ba32-9ef3e0db94b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function scipy.ndimage._filters.gaussian_filter(input, sigma, order=0, output=None, mode='reflect', cval=0.0, truncate=4.0, *, radius=None, axes=None)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3188e4fe-b1fc-4e2d-b0de-849f00dc4f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190, 509, 188)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tutorial_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f139db3-530a-42f3-b38f-baa3ba226bb7",
   "metadata": {},
   "source": [
    "### Notes and To do\n",
    "\n",
    "1. Image normalization for ortho-slices and textures. Maybe add a global variable \"normalized image\"? Normalization slider in materials.\n",
    "\n",
    "2. axis permutation\n",
    "\n",
    "3. marching cubes\n",
    "\n",
    "4. better color options for vertex shading\n",
    "\n",
    "\n",
    "More generally: somehow associate the data (like projections etc) to the mesh, and the image data to the bounding box, instead of having a global variable floating around. This can be done by assigning custom data as\n",
    "\n",
    "```\n",
    "obj[\"data_name\"] = (np.array(...), shape)\n",
    "\n",
    "```\n",
    "Need to reconstruct using `np.array(arr.tolist()).reshape(shape)`.\n",
    "\n",
    "`bpy.context.selected_objects`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e766c-6eed-429b-8181-408f304d3f5e",
   "metadata": {},
   "source": [
    "Idea: selected + active objects. Make sure both bounding box and mesh are selected. Give the bounding box some attribute so I know which of the selected objects is the 3d data and which is the mesh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd0c98-1acc-4dd8-9a6d-ae3a809543d7",
   "metadata": {},
   "source": [
    "## Specs\n",
    "\n",
    "### Inputs\n",
    "\n",
    "1. Path to `.tiff` file\n",
    "2. $x$/$y$/$z$ resolution (can be read out automatically)\n",
    "3. Optional: path to segmentation `.tiff`\n",
    "\n",
    "The user can also import the mesh directly. \n",
    "\n",
    "### Functionality\n",
    "\n",
    "Convention: mesh vertex coordinates always have to be in microns.\n",
    "\n",
    "0. Create bounding box (in microns) in blender that shows outline of volumetric data. Allow loading orthoslices of raw data.\n",
    "\n",
    "1. Upon loading, convert segmentation to mesh using volume to mesh. Options: smoothing scale.\n",
    "\n",
    "Errors: file not found, segmentation and image do not have the same number of pixels. (Q: allow separate x/y/z resolution for segmentation?)\n",
    "\n",
    "2. Upon button click, create multilayer pullback and save to disk as pngs and multi page tiff. Also save normal and 3d coord bake. As well as max projection.\n",
    "\n",
    "**Options**: resolution (pixels), normal layer spacing.\n",
    "\n",
    "**Errors**: file not found, no UV map\n",
    "\n",
    "**Warnings**: UV map has self intersections, UV map out of bounds\n",
    "\n",
    "### Internals\n",
    "\n",
    "1. Meshing (segmentation -> mesh). Load segmentation as .tiff, convert to vdb volume, use blenders volume to mesh node\n",
    "\n",
    "2. Cartographic projection. The mesh used is the currently selected one! Two steps.\n",
    "\n",
    "    a. Bake 3d coordinates and normals to UV. Use `scipy`-interpolation - render bake is difficult to get to work.\n",
    "\n",
    "    b. Bake from volumetric data to UV. Use `scipy`-interpolation as in the pytho package.\n",
    "\n",
    "4. Saving. Always save to fixed path, say extracted_textures in the same path as image. Careful with windows, Linux, etc path handling.\n",
    "\n",
    "5. Create textures/shader from baked data.\n",
    "\n",
    "6. Load orthoslices of raw data\n",
    "\n",
    "7. Optional: Create normal shifted meshes (not visible by default). Shrink/fatten blender button.\n",
    "\n",
    "### Conventions:\n",
    "\n",
    "1. Mesh orientation: $Y$ forward, $Z$ up! (when importing the mesh).\n",
    "\n",
    "### Dependencies:\n",
    "\n",
    "1. Numpy (standard)\n",
    "2. Scipy, if available (interpolation). I can also do interpolation myself \n",
    "3. `tifffile` for reading `.tiff` files (check microscopy nodes source code), and converting to .vdb (for meshing) OR some marching cubes code.\n",
    "\n",
    "\n",
    "TO DO: vertex color based shading! Bounding box!\n",
    "\n",
    "`numpy`, `scipy`, `tifffile` and `skimage` are shipped with Blender's python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3cfe1-ca50-4534-8c33-9ea43c264065",
   "metadata": {},
   "source": [
    "## Ressources\n",
    "\n",
    "Add-on Tutorial: https://docs.blender.org/manual/en/latest/advanced/scripting/addon_tutorial.html\n",
    "\n",
    "MicroscopyNodes source code: https://github.com/oanegros/MicroscopyNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cef6dd-7c42-48ac-a259-f7abede4d721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7531f6bd-9ced-46b6-a389-99b0208f0cf9",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b4b5265-e8f1-4767-930e-76fece7d41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99aa05-26e4-4295-a468-710e582ecdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6702372-866f-4e42-b7d4-6bbc9a167fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33234fd2-17bd-42fc-b6f8-3d3c31656367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c269d1-9b5b-40b6-a788-096b90a1cc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69f4400-ca7c-418c-86ea-7dff39632154",
   "metadata": {},
   "source": [
    "### Add-on code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d858c-1884-4dcb-a040-505cdf25ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "bl_info = {\n",
    "    \"name\": \"Tissue Cartography\",\n",
    "    \"blender\": (3, 0, 0),\n",
    "    \"category\": \"Scene\",\n",
    "}\n",
    "\n",
    "import bpy\n",
    "from bpy.props import StringProperty, FloatVectorProperty, FloatProperty, IntProperty\n",
    "from bpy.types import Operator, Panel\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy import interpolate\n",
    "\n",
    "### Functions for tissue cartography\n",
    "\n",
    "def load_png(image_path):\n",
    "    \"\"\"Load .png into numpy array.\"\"\"\n",
    "    image = bpy.data.images.load(image_path)\n",
    "    width, height = image.size\n",
    "    pixels = np.array(image.pixels[:], dtype=np.float32)\n",
    "    return pixels.reshape((height, width, -1))\n",
    "\n",
    "def get_uv_layout(uv_layout_path, image_resolution):\n",
    "    \"\"\"Get UV layout mask for currently active object and save UV layout to disk\"\"\"\n",
    "    bpy.ops.object.mode_set(mode='EDIT')\n",
    "    bpy.ops.uv.export_layout(filepath=uv_layout_path, size=(image_resolution, image_resolution), opacity=1)\n",
    "    bpy.ops.object.mode_set(mode='OBJECT')\n",
    "    UV_layout = load_png(uv_layout_path)\n",
    "    return (UV_layout.sum(axis=-1) > 0)[::-1]\n",
    "\n",
    "def get_uv_normal_world_per_loop(mesh_obj, filter_unique=False):\n",
    "    \"\"\"\n",
    "    Get UV, normals, and world and normal for each loop (half-edge) as np.array.\n",
    "    \n",
    "    If filter_unique, remove \"duplicate\" loops (for which UV, normals and position\n",
    "    are identical).\n",
    "    \"\"\"\n",
    "    if not mesh_obj:\n",
    "        raise TypeError(\"No object selected\")\n",
    "    if mesh_obj.type != 'MESH':\n",
    "        raise TypeError(\"Selected object is not a mesh\")\n",
    "    world_matrix = mesh_obj.matrix_world\n",
    "    uv_layer = mesh_obj.data.uv_layers.active\n",
    "    if not uv_layer:\n",
    "        raise RuntimeError(\"Mesh does not have an active UV map\")\n",
    "    loop_uvs = np.zeros((len(mesh_obj.data.loops), 2), dtype=np.float32)\n",
    "    loop_normals = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    loop_world_positions = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    for loop in mesh_obj.data.loops:\n",
    "        loop_uvs[loop.index] = uv_layer.data[loop.index].uv\n",
    "        loop_normals[loop.index] = world_matrix.to_3x3() @ mesh_obj.data.vertices[loop.vertex_index].normal\n",
    "        loop_world_positions[loop.index] = world_matrix @ mesh_obj.data.vertices[loop.vertex_index].co\n",
    "    if filter_unique:\n",
    "        unqiue_loops = np.unique(np.hstack([loop_uvs, loop_normals, loop_world_positions]), axis=0)\n",
    "        loop_uvs, loop_normals, loop_world_positions = (unqiue_loops[:,:2], unqiue_loops[:,2:5], unqiue_loops[:,5:])\n",
    "    loop_normals = np.round((loop_normals.T/np.linalg.norm(loop_normals, axis=1)).T, decimals=4)\n",
    "    return loop_uvs, loop_normals, loop_world_positions\n",
    "\n",
    "def bake_per_loop_values_to_uv(loop_uvs, loop_values, image_resolution):\n",
    "    \"\"\"\n",
    "    Bake (interpolate) values (normals or world position) defined per loop into the UV square.\n",
    "    \n",
    "    UV coordinates outside [0,1] are ignored.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    loop_uvs : np.array of shape (n_loops, 2)\n",
    "        UV coordinates of loop.\n",
    "    loop_values : np.array of shape (n_loops, ...)\n",
    "        Input field. Can be an array with any number of axes (e.g. scalar or vector field).\n",
    "    image_resolution : int, default 256\n",
    "        Size of UV grid. Determines resolution of result.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    interpolated : np.array of shape (uv_grid_steps, uv_grid_steps, ...)\n",
    "        Field across [0,1]**2 UV grid, with a uniform step size. UV positions that don't\n",
    "        correspond to any value are set to np.nan.\n",
    "            \n",
    "    \"\"\"\n",
    "    U, V = np.meshgrid(*(2*(np.linspace(0,1, image_resolution),)))\n",
    "    interpolated = interpolate.griddata(loop_uvs, loop_values, (U, V), method='linear')[::-1]\n",
    "    return interpolated\n",
    "    \n",
    "def bake_volumetric_data_to_uv(image, baked_world_positions, resolution, baked_normals, normal_offsets=(0,)):\n",
    "    \"\"\" \n",
    "    Interpolate volumetric image data onto UV coordinate grid.\n",
    "    \n",
    "    Uses baked 3d world positions corresponding to each UV grid point (see bake_per_loop_values_to_UV).\n",
    "    3d coordinates (in microns) are converted into image coordinates via the resolution scaling factor.\n",
    "    The resolution of the bake (number of pixels) is determined by the shape of baked_world_positions.\n",
    "    \n",
    "    normal_offsets moves the 3d positions whose volumetric voxel values will be baked inwards or outwards\n",
    "    along the surface normal. Providing a list of offsets results in a multi-layer pullback\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : 4d np.array\n",
    "        Image, axis 0  is assumed to be the channel axis\n",
    "    baked_world_positions : np.array of shape (image_resolution, image_resolution, uv_grid_steps, 3)\n",
    "        3d world positions baked to UV grid, with uniform step size. UV positions that don't correspond to \n",
    "        any value are set to np.nan.\n",
    "    resolution : np.array of shape (3,)\n",
    "        Resolution in pixels/microns for each of the three spatial axes.\n",
    "    baked_normals : np.array of shape (image_resolution, image_resolution, uv_grid_steps, 3)\n",
    "        3d world normals baked to UV grid, with uniform step size. UV positions that don't correspond to \n",
    "        any value are set to np.nan.\n",
    "    normal_offsets : np.array of shape (n_layers,), default (0,)\n",
    "        Offsets along normal direction, in same units as interpolated_3d_positions (i.e. microns).\n",
    "        0 corresponds to no shift.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    aked_data : np.array of shape (n_channels, n_layers, image_resolution, image_resolution)\n",
    "        Multi-layer 3d volumetric data baked onto UV.\n",
    "    \"\"\"\n",
    "    x, y, z = [np.arange(ni) for ni in image.shape[1:]]\n",
    "    baked_data = []\n",
    "    for o in normal_offsets:\n",
    "        baked_layer_data = np.stack([interpolate.interpn((x, y, z), channel,\n",
    "                                     (baked_world_positions+o*baked_normals)/resolution,\n",
    "                                     method=\"linear\", bounds_error=False) for channel in image])\n",
    "        baked_data.append(baked_layer_data)\n",
    "    baked_data = np.stack(baked_data, axis=1)\n",
    "    return baked_data\n",
    "\n",
    "### Operators defining the user interface of the add-on\n",
    "\n",
    "class LoadTIFFOperator(Operator):\n",
    "    \"\"\"Load .tif file and resolution\"\"\"\n",
    "    bl_idname = \"scene.load_tiff\"\n",
    "    bl_label = \"Load TIFF File\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        file_path = context.scene.tissue_cartography_file\n",
    "        resolution = context.scene.tissue_cartography_resolution\n",
    "\n",
    "        # Load resolution as a NumPy array\n",
    "        resolution_array = np.array(resolution)\n",
    "        self.report({'INFO'}, f\"Resolution loaded: {resolution_array}\")\n",
    "\n",
    "        # Load TIFF file as a NumPy array\n",
    "        if not (file_path.lower().endswith(\".tiff\") or file_path.lower().endswith(\".tif\")):\n",
    "            self.report({'ERROR'}, \"Selected file is not a TIFF\")\n",
    "            return {'CANCELLED'}\n",
    "        try:\n",
    "            data = tifffile.imread(file_path)\n",
    "            if len(data.shape) == 3: # add singleton channel axis to single channel-data \n",
    "                data = data[np.newaxis]\n",
    "            assert len(data.shape) == 4, \"Data must be volumetric!\"\n",
    "            self.report({'INFO'}, f\"TIFF file loaded with shape {data.shape}\")\n",
    "            # Store variables in Blender's global storage\n",
    "            bpy.types.Scene.tissue_cartography_data = data\n",
    "            bpy.types.Scene.tissue_cartography_resolution_array = resolution_array\n",
    "        except Exception as e:\n",
    "            self.report({'ERROR'}, f\"Failed to load TIFF file: {e}\")\n",
    "            return {'CANCELLED'}\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class CreateProjectionOperator(Operator):\n",
    "    \"\"\"\n",
    "    Create a cartographic projection.\n",
    "    \n",
    "    This is done in two steps: first, bake 3d world positions and normals to UV,\n",
    "    then use the baked positions to interpolate the volumetric data\n",
    "    to UV.\n",
    "    \"\"\"\n",
    "    bl_idname = \"scene.create_projection\"\n",
    "    bl_label = \"Create Projection\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        # Validate selected object and UV map\n",
    "        obj = context.active_object\n",
    "        if not obj or obj.type != 'MESH':\n",
    "            self.report({'ERROR'}, \"No mesh object selected!\")\n",
    "            return {'CANCELLED'}\n",
    "        # Ensure the object has a UV map\n",
    "        if not obj.data.uv_layers:\n",
    "            self.report({'ERROR'}, \"The selected mesh does not have a UV map!\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        # Parse offsets into a NumPy array\n",
    "        offsets_str = context.scene.tissue_cartography_offsets\n",
    "        try:\n",
    "            offsets_array = np.array([float(x) for x in offsets_str.split(\",\") if x.strip()])\n",
    "            if offsets_array.size == 0:\n",
    "                offsets_array = np.array([0])\n",
    "            bpy.types.Scene.tissue_cartography_offsets_array = offsets_array\n",
    "            self.report({'INFO'}, f\"Offsets loaded: {offsets_array}\")\n",
    "        except ValueError as e:\n",
    "            self.report({'ERROR'}, f\"Invalid offsets input: {e}\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        # Parse projection resolution\n",
    "        projection_resolution = context.scene.projection_resolution\n",
    "        self.report({'INFO'}, f\"Using projection resolution: {projection_resolution}\")\n",
    "\n",
    "        # texture bake normals and world positions\n",
    "        loop_uvs, loop_normals, loop_world_positions = get_uv_normal_world_per_loop(obj, filter_unique=True)\n",
    "        baked_normals = bake_per_loop_values_to_uv(loop_uvs, loop_normals, image_resolution=projection_resolution)\n",
    "        baked_normals = (baked_normals.T/np.linalg.norm(baked_normals.T, axis=0)).T\n",
    "        baked_world_positions = bake_per_loop_values_to_uv(loop_uvs, loop_world_positions, image_resolution=projection_resolution)\n",
    "\n",
    "        # obtain UV layout and use it to get a mask\n",
    "        uv_layout_path = str(Path(bpy.path.abspath(\"//\")).joinpath('UV_layout.png'))\n",
    "        mask = get_uv_layout(uv_layout_path, projection_resolution)\n",
    "        baked_normals[~mask] = np.nan\n",
    "        baked_world_positions[~mask] = np.nan\n",
    "        \n",
    "        # create a pullback\n",
    "        baked_data = bake_volumetric_data_to_uv(bpy.types.Scene.tissue_cartography_data,\n",
    "                                                baked_world_positions, np.array([1,1,1]), baked_normals,\n",
    "                                                normal_offsets=bpy.types.Scene.tissue_cartography_offsets_array)\n",
    "\n",
    "        # set as global variables and save to disk\n",
    "        bpy.types.Scene.tissue_cartography_baked_normals = baked_normals\n",
    "        bpy.types.Scene.tissue_cartography_baked_world_positions = baked_world_positions\n",
    "        bpy.types.Scene.tissue_cartography_baked_data = baked_data\n",
    "        tifffile.imwrite(Path(bpy.path.abspath(\"//\")).joinpath('BakedNormals.tif'), baked_normals)\n",
    "        tifffile.imwrite(Path(bpy.path.abspath(\"//\")).joinpath('BakedPositions.tif'), baked_world_positions)\n",
    "        tifffile.imwrite(Path(bpy.path.abspath(\"//\")).joinpath('BakedData.tif'), baked_data)\n",
    "        self.report({'INFO'}, \"Projected data saved to: \"+bpy.path.abspath(\"//\"))\n",
    "        \n",
    "        \n",
    "        # [...]\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "class HelpPopupOperator(Operator):\n",
    "    \"\"\"Show help window.\"\"\"\n",
    "    bl_idname = \"scene.help_popup\"\n",
    "    bl_label = \"Tissue Cartography Help\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        return context.window_manager.invoke_popup(self, width=400)\n",
    "\n",
    "    def draw(self, context):\n",
    "        layout = self.layout\n",
    "        col = layout.column()\n",
    "\n",
    "        col.label(text=\"Tissue Cartography Add-On Help\", icon='INFO')\n",
    "        col.label(text=\"1. Load a .tiff file using the 'Load' button.\")\n",
    "        col.label(text=\"   after entering the resolution (x, y, z) in microns.\")\n",
    "        col.label(text=\"2. Select the mesh to use (it should be outlined in orange).\")\n",
    "        col.label(text=\"3. Click 'Create Projection' to bake mesh positions,\")\n",
    "        col.label(text=\"   nesh normals, and volumetric data to UV textures.\")\n",
    "        col.label(text=\"   Define normal offsets to get a multi-layer projection.\")\n",
    "        col.label(text=\"   Data is saved as .tiff files for further processing,\")\n",
    "        col.label(text=\"   and as a material to shade the mesh (see Shading workspace).\")\n",
    "        col.label(text=\"   Projection resolution determines the output texture size.\")\n",
    "        col.separator()\n",
    "        col.label(text=\"4. Troubleshooting and conventions\")\n",
    "        col.label(text=\"   a. The mesh vertex positions must be in micrometers.\")\n",
    "        col.label(text=\"      After creating the mesh (for example by a marching cubes),\")\n",
    "        col.label(text=\"      make sure to convert from pixels to microns!\")\n",
    "        col.label(text=\"   b. When importing a mesh into blender, choose Y=Forward and Z=Up.\")\n",
    "        col.label(text=\"      This ensures the mesh coordinates match the image axes!\")\n",
    "        col.label(text=\"   c. Check the Info Monitor (Scripting window) for messages and errors.\")\n",
    "        \n",
    "class TissueCartographyPanel(Panel):\n",
    "    \"\"\"Class defining layout of user interface (buttons, inputs, etc.)\"\"\"\n",
    "    bl_label = \"Tissue Cartography\"\n",
    "    bl_idname = \"SCENE_PT_tissue_cartography\"\n",
    "    bl_space_type = 'PROPERTIES'\n",
    "    bl_region_type = 'WINDOW'\n",
    "    bl_context = \"scene\"\n",
    "\n",
    "    def draw(self, context):\n",
    "        layout = self.layout\n",
    "        scene = context.scene\n",
    "\n",
    "        layout.prop(scene, \"tissue_cartography_file\")\n",
    "        layout.prop(scene, \"tissue_cartography_resolution\")\n",
    "        layout.operator(\"scene.load_tiff\", text=\"Load\")\n",
    "        layout.prop(scene, \"tissue_cartography_offsets\")\n",
    "        layout.prop(scene, \"projection_resolution\")\n",
    "        layout.operator(\"scene.create_projection\", text=\"Create Projection\")\n",
    "        layout.operator(\"scene.help_popup\", text=\"Help\", icon='HELP')\n",
    "        \n",
    "def register():\n",
    "    \"\"\"Add the add-on to the blender user interface\"\"\"\n",
    "    bpy.utils.register_class(LoadTIFFOperator)\n",
    "    bpy.utils.register_class(CreateProjectionOperator)\n",
    "    bpy.utils.register_class(TissueCartographyPanel)\n",
    "    bpy.utils.register_class(HelpPopupOperator)\n",
    "    \n",
    "    bpy.types.Scene.tissue_cartography_file = StringProperty(\n",
    "        name=\"File Path\",\n",
    "        description=\"Path to the TIFF file\",\n",
    "        subtype='FILE_PATH',\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_resolution = FloatVectorProperty(\n",
    "        name=\"x/y/z Resolution (µm)\",\n",
    "        description=\"Resolution in microns along x, y, z axes\",\n",
    "        size=3,\n",
    "        default=(1.0, 1.0, 1.0),\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_offsets = StringProperty(\n",
    "        name=\"Normal Offsets (µm)\",\n",
    "        description=\"Comma-separated list of floats for multilayer projection offsets\",\n",
    "        default=\"0\",\n",
    "    )\n",
    "    bpy.types.Scene.projection_resolution = IntProperty(\n",
    "        name=\"Projection Resolution\",\n",
    "        description=\"Resolution for the projection (e.g., 1024 for 1024x1024)\",\n",
    "        default=1024,\n",
    "        min=1,\n",
    "    )\n",
    "\n",
    "def unregister():\n",
    "    bpy.utils.unregister_class(LoadTIFFOperator)\n",
    "    bpy.utils.unregister_class(CreateProjectionOperator)\n",
    "    bpy.utils.unregister_class(TissueCartographyPanel)\n",
    "    bpy.utils.unregister_class(HelpPopupOperator)\n",
    "    bpy.utils.unregister_class(OpenHelpWindowOperator)\n",
    "    del bpy.types.Scene.tissue_cartography_file\n",
    "    del bpy.types.Scene.tissue_cartography_resolution_array\n",
    "    del bpy.types.Scene.tissue_cartography_data\n",
    "    del bpy.types.Scene.tissue_cartography_offsets_array\n",
    "    del bpy.types.Scene.tissue_cartography_baked_normals\n",
    "    del bpy.types.Scene.tissue_cartography_baked_world_positions\n",
    "    del bpy.types.Scene.tissue_cartography_baked_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb57fe1-eeca-44e0-a127-a8bddbd166a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2636c1f6-d7f7-4c99-a9e5-aa628d240f19",
   "metadata": {},
   "source": [
    "### baking normal and world position\n",
    "\n",
    "Texture baking the surface normals and vertex positions tunrs out to be more involved than I would like.\n",
    "\n",
    "In particular, it is difficult to guarantee that the coordinates are not distorted or rescaled in a way that I don't understand. Also, it can be slow. Also difficult to get to work as a script, unfortunately. Often I just get black images for reasons I do not understand.\n",
    "\n",
    "I will therefore resort to using (manual) interpolation. Luckily, it appears that `scipy` is available in blender python. We need add one extra step (UV layout mask) though,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd46bf4a-0752-40cb-8d57-22c344ae6f09",
   "metadata": {},
   "source": [
    "### Baking using custom interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2055a3dc-e1e1-46a1-a90f-d3dd0fadf875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bpy\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy import interpolate\n",
    "from pathlib import Path\n",
    "\n",
    "def load_png(image_path):\n",
    "    \"\"\"Load .png into numpy array.\"\"\"\n",
    "    image = bpy.data.images.load(image_path)\n",
    "    width, height = image.size\n",
    "    pixels = np.array(image.pixels[:], dtype=np.float32)\n",
    "    return pixels.reshape((height, width, -1))\n",
    "\n",
    "def get_uv_layout(uv_layout_path, image_resolution):\n",
    "    \"\"\"Get UV layout mask for currently active object and save UV layout to disk\"\"\"\n",
    "    bpy.ops.object.mode_set(mode='EDIT')\n",
    "    bpy.ops.uv.export_layout(filepath=uv_layout_path, size=(image_resolution, image_resolution), opacity=1)\n",
    "    bpy.ops.object.mode_set(mode='OBJECT')\n",
    "    UV_layout = load_png(uv_layout_path)\n",
    "    return (UV_layout.sum(axis=-1) > 0)[::-1]\n",
    "\n",
    "def get_uv_normal_world_per_loop(mesh_obj, filter_unique=False):\n",
    "    \"\"\"\n",
    "    Get UV, normals, and world and normal for each loop (half-edge) as np.array.\n",
    "    \n",
    "    If filter_unique, remove \"duplicate\" loops (for which UV, normals and position\n",
    "    are identical).\n",
    "    \"\"\"\n",
    "    if not mesh_obj:\n",
    "        raise TypeError(\"No object selected\")\n",
    "    if mesh_obj.type != 'MESH':\n",
    "        raise TypeError(\"Selected object is not a mesh\")\n",
    "    world_matrix = mesh_obj.matrix_world\n",
    "    uv_layer = mesh_obj.data.uv_layers.active\n",
    "    if not uv_layer:\n",
    "        raise RuntimeError(\"Mesh does not have an active UV map\")\n",
    "    loop_uvs = np.zeros((len(mesh_obj.data.loops), 2), dtype=np.float32)\n",
    "    loop_normals = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    loop_world_positions = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    for loop in mesh_obj.data.loops:\n",
    "        loop_uvs[loop.index] = uv_layer.data[loop.index].uv\n",
    "        loop_normals[loop.index] = mesh_obj.data.vertices[loop.vertex_index].normal\n",
    "        loop_world_positions[loop.index] = world_matrix @ mesh_obj.data.vertices[loop.vertex_index].co\n",
    "    #loop_normals = np.round((loop_normals.T/np.linalg.norm(loop_normals, axis=1)).T, decimals=4)\n",
    "    if filter_unique:\n",
    "        unqiue_loops = np.unique(np.hstack([loop_uvs, loop_normals, loop_world_positions]), axis=0)\n",
    "        loop_uvs, loop_normals, loop_world_positions = (unqiue_loops[:,:2], unqiue_loops[:,2:5], unqiue_loops[:,5:])\n",
    "    return loop_uvs, loop_normals, loop_world_positions\n",
    "\n",
    "def bake_per_loop_values_to_UV(loop_uvs, loop_values, image_resolution):\n",
    "    \"\"\"\n",
    "    Bake (interpolate) values (normals or world position) defined per loop into the UV square.\n",
    "    \n",
    "    UV coordinates outside [0,1] are ignored.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    loop_uvs : np.array of shape (n_loops, 2)\n",
    "        UV coordinates of loop.\n",
    "    loop_values : np.array of shape (n_loops, ...)\n",
    "        Input field. Can be an array with any number of axes (e.g. scalar or vector field).\n",
    "    image_resolution : int, default 256\n",
    "        Size of UV grid. Determines resolution of result.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    interpolated : np.array of shape (uv_grid_steps, uv_grid_steps, ...)\n",
    "        Field across [0,1]**2 UV grid, with a uniform step size. UV positions that don't\n",
    "        correspond to any value are set to np.nan.\n",
    "            \n",
    "    \"\"\"\n",
    "    U, V = np.meshgrid(*(2*(np.linspace(0,1, image_resolution),)))\n",
    "    interpolated = interpolate.griddata(loop_uvs, loop_values, (U, V), method='linear')[::-1]\n",
    "    return interpolated\n",
    "    \n",
    "image_resolution = 256\n",
    "loop_uvs, loop_normals, loop_world_positions = get_uv_normal_world_per_loop(bpy.context.object, filter_unique=True)\n",
    "baked_normals = bake_per_loop_values_to_UV(loop_uvs, loop_normals, image_resolution=image_resolution)\n",
    "baked_normals = (baked_normals.T/np.linalg.norm(baked_normals.T, axis=0)).T\n",
    "baked_world_positions = bake_per_loop_values_to_UV(loop_uvs, loop_world_positions, image_resolution=image_resolution)\n",
    "\n",
    "# obtain UV layout and use it to get a mask\n",
    "uv_layout_path = str(Path(bpy.path.abspath(\"//\")).joinpath('UV_layout.png'))\n",
    "mask = get_uv_layout(uv_layout_path, image_resolution)\n",
    "baked_normals[~mask] = np.nan\n",
    "baked_world_positions[~mask] = np.nan\n",
    "\n",
    "# set as global variables and save to disk\n",
    "bpy.types.Scene.tissue_cartography_baked_normals = baked_normals\n",
    "bpy.types.Scene.tissue_cartography_baked_world_positions = baked_world_positions \n",
    "tifffile.imwrite(Path(bpy.path.abspath(\"//\")).joinpath('NormalMapBarycentric.tif'), baked_normals)       \n",
    "tifffile.imwrite(Path(bpy.path.abspath(\"//\")).joinpath('PositionMapBarycentric.tif'), baked_world_positions)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d9b770-20d4-4af1-b51c-313fd6c91c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13b2d052-f35b-4add-ad8b-1b9516acf04c",
   "metadata": {},
   "source": [
    "### Baking using render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01573bf-f393-43a3-a371-0388d7808ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Texture baking - here for the normals\n",
    "\n",
    "import bpy\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "\n",
    "obj = bpy.context.object\n",
    "\n",
    "# Check if the object is a mesh\n",
    "if obj.type != 'MESH':\n",
    "    raise TypeError(\"The active object must be a mesh.\")\n",
    "    \n",
    "# Step 1: Create a new, empty material for the currently selected object\n",
    "\n",
    "if \"NormalMap\" in bpy.data.materials:\n",
    "    bpy.data.materials.remove(bpy.data.materials[\"NormalMap\"])\n",
    "material = bpy.data.materials.new(name=\"NormalMap\")\n",
    "material.use_nodes = True  # Enable nodes for the material\n",
    "for node in material.node_tree.nodes:\n",
    "    material.node_tree.nodes.remove(node)\n",
    "# Assign the material to the object\n",
    "obj.data.materials.append(material)\n",
    "obj.active_material = material\n",
    "\n",
    "# Step 2: Create and select an image texture with 512x512 pixels in the new material\n",
    "\n",
    "if \"TextureImage\" in bpy.data.images:\n",
    "    bpy.data.images.remove(bpy.data.images[\"TextureImage\"])\n",
    "image = bpy.data.images.new(name=\"TextureImage\", width=512, height=512)\n",
    "# Create the Image Texture node\n",
    "image_texture_node = material.node_tree.nodes.new(type=\"ShaderNodeTexImage\")\n",
    "image_texture_node.image = image\n",
    "\n",
    "# Step 3: Set the render engine to Cycles and set the bake settings\n",
    "\n",
    "bpy.context.scene.render.engine = 'CYCLES'\n",
    "bpy.context.scene.cycles.bake_type = 'NORMAL'\n",
    "bpy.context.scene.render.bake.normal_space = 'OBJECT'\n",
    "bpy.context.scene.render.bake.normal_r = 'POS_X'\n",
    "bpy.context.scene.render.bake.normal_g = 'POS_Y'\n",
    "bpy.context.scene.render.bake.normal_b = 'POS_Z'\n",
    "bpy.context.scene.render.bake.margin = 1\n",
    "bpy.context.scene.render.bake.use_clear = True\n",
    "\n",
    "# Step 4: Bake the normal map (trigger the bake)\n",
    "    \n",
    "bpy.ops.object.bake()\n",
    "\n",
    "# Step 5: assign pixel values to a numpy array (global variable) and save as .tif file\n",
    "\n",
    "baked_image = bpy.data.images[\"TextureImage\"]  # Access the baked image by name\n",
    "pixels = np.array(baked_image.pixels)  # Get the pixel data as a 1D array\n",
    "# Reshape the 1D array into a 2D array (image width x height x 4 channels)\n",
    "pixels = pixels.reshape((baked_image.size[1], baked_image.size[0], 4))[:,:,:-1]\n",
    "#pixels = (2*pixels - 1) # recale to [-1,1] and normalize \n",
    "#pixels = (pixels.T / np.linalg.norm(pixels.T, axis=0)).T\n",
    "\n",
    "bpy.types.Scene.tissue_cartography_normal_map = pixels\n",
    "tifffile.imwrite(Path(bpy.path.abspath(\"//\")).joinpath('NormalMap.tif'), pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50878a7-879b-4ec6-acc7-365766f17ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Here for the position\n",
    "\n",
    "import bpy\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "# Step 0: Check if the selected object is a mesh\n",
    "\n",
    "obj = bpy.context.object\n",
    "if obj.type != 'MESH':\n",
    "    raise TypeError(\"The active object must be a mesh.\")\n",
    "    \n",
    "# Step 1: Create a new, empty material for the currently selected object\n",
    "\n",
    "if \"PositionMap\" in bpy.data.materials:\n",
    "    bpy.data.materials.remove(bpy.data.materials[\"PositionMap\"])\n",
    "material = bpy.data.materials.new(name=\"PositionMap\")\n",
    "# Set up nodes\n",
    "material.use_nodes = True \n",
    "for node in material.node_tree.nodes:\n",
    "    material.node_tree.nodes.remove(node)\n",
    "# Create nodes\n",
    "geometry_node = material.node_tree.nodes.new(type=\"ShaderNodeNewGeometry\")\n",
    "vector_math_node = material.node_tree.nodes.new(type=\"ShaderNodeVectorMath\")\n",
    "vector_math_node.operation = 'MULTIPLY_ADD'  # Scale and offset\n",
    "emission_node = material.node_tree.nodes.new(type=\"ShaderNodeEmission\")\n",
    "output_node = material.node_tree.nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "# Position the nodes\n",
    "geometry_node.location = (-300, 0)\n",
    "vector_math_node.location = (0, 0)\n",
    "emission_node.location = (300, 0)\n",
    "output_node.location = (600, 0)\n",
    "# Connect nodes\n",
    "material.node_tree.links.new(geometry_node.outputs['Position'], vector_math_node.inputs[0])\n",
    "material.node_tree.links.new(vector_math_node.outputs['Vector'], emission_node.inputs['Color'])\n",
    "material.node_tree.links.new(emission_node.outputs['Emission'], output_node.inputs['Surface'])\n",
    "# Set scaling (adjust these values based on your scene's scale)\n",
    "vector_math_node.inputs[1].default_value = (0.1, 0.1, 0.1)  # Scale\n",
    "vector_math_node.inputs[2].default_value = (0.5, 0.5, 0.5)  # Offset to center in [0, 1]\n",
    "# Assign the material to the object\n",
    "obj.data.materials.append(material)\n",
    "obj.active_material = material\n",
    "\n",
    "# Step 2: Create and select an image texture with 512x512 pixels in the new material\n",
    "\n",
    "if \"TextureImagePositionMap\" in bpy.data.images:\n",
    "    bpy.data.images.remove(bpy.data.images[\"TextureImagePositionMap\"])\n",
    "image = bpy.data.images.new(name=\"TextureImagePositionMap\", width=512, height=512)\n",
    "# Create the Image Texture node\n",
    "image_texture_node = material.node_tree.nodes.new(type=\"ShaderNodeTexImage\")\n",
    "image_texture_node.image = image\n",
    "image_texture_node.location = (-600, -200)\n",
    "\n",
    "# Step 3: Set the render engine to Cycles and set the bake settings\n",
    "\n",
    "bpy.context.scene.render.engine = 'CYCLES'\n",
    "bpy.context.scene.cycles.bake_type = 'EMIT'\n",
    "bpy.context.scene.render.bake.margin = 1\n",
    "bpy.context.scene.render.bake.use_clear = True\n",
    "\n",
    "\n",
    "# Step 4: Bake the normal map (trigger the bake)\n",
    "\n",
    "bpy.context.view_layer.objects.active = obj\n",
    "bpy.ops.object.bake()\n",
    "\n",
    "# Step 5: assign pixel values to a numpy array (global variable) and save as .tif file\n",
    "\n",
    "# Save the image\n",
    "image.filepath_raw = \"//position_map.png\"\n",
    "image.file_format = 'PNG'\n",
    "image.save()\n",
    "\n",
    "baked_image = bpy.data.images[\"TextureImagePositionMap\"]  # Access the baked image by name\n",
    "pixels = np.array(baked_image.pixels)  # Get the pixel data as a 1D array\n",
    "# Reshape the 1D array into a 2D array (image width x height x 4 channels)\n",
    "pixels = pixels.reshape((baked_image.size[1], baked_image.size[0], 4))[:,:,:-1]\n",
    "#pixels = (2*pixels - 1) # recale to [-1,1] and normalize \n",
    "#pixels = (pixels.T / np.linalg.norm(pixels.T, axis=0)).T\n",
    "\n",
    "bpy.types.Scene.tissue_cartography_positon_map = pixels\n",
    "tifffile.imwrite(Path(bpy.path.abspath(\"//\")).joinpath('PositionMap.tif'), pixels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50019bf-9f65-4265-b6ca-d0b1a33b0091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating ortho-slices.\n",
    "\n",
    "import bpy\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "\n",
    "def create_slice_plane(length, width, height, axis='z', position=0.0):\n",
    "    \"\"\"\n",
    "    Creates a 2D plane as a slice of a rectangular box along a specified axis.\n",
    "    The plane lies within the bounds of the box.\n",
    "\n",
    "    Args:\n",
    "        length (float): Length of the box along the X-axis.\n",
    "        width (float): Width of the box along the Y-axis.\n",
    "        height (float): Height of the box along the Z-axis.\n",
    "        axis (str): Axis along which to slice ('x', 'y', or 'z').\n",
    "        position (float): Position along the chosen axis for the slice plane.\n",
    "                          Should be within the range of the box dimensions.\n",
    "    \"\"\"\n",
    "    current_active = bpy.context.active_object\n",
    "    # Validate axis and position\n",
    "    if axis not in {'x', 'y', 'z'}:\n",
    "        raise ValueError(\"Axis must be 'x', 'y', or 'z'.\")\n",
    "    \n",
    "    axis_limits = {'x': length, 'y': width, 'z': height}\n",
    "    if not (0.0 <= position <= axis_limits[axis]):\n",
    "        raise ValueError(f\"Position must be within [0, {axis_limits[axis]}] for axis {axis}.\")\n",
    "\n",
    "    # Create the plane's dimensions based on the slicing axis\n",
    "    if axis == 'x':\n",
    "        plane_size = (width, height)\n",
    "        location = (position, width / 2, height / 2)\n",
    "        rotation = (0, 1.5708, 0)  # Rotate to align with the YZ-plane\n",
    "    elif axis == 'y':\n",
    "        plane_size = (length, height)\n",
    "        location = (length / 2, position, height / 2)\n",
    "        rotation = (1.5708, 0, 0)  # Rotate to align with the XZ-plane\n",
    "    else:  # 'z'\n",
    "        plane_size = (length, width)\n",
    "        location = (length / 2, width / 2, position)\n",
    "        rotation = (0, 0, 0)  # No rotation needed for the XY-plane\n",
    "\n",
    "    # Add a plane\n",
    "    bpy.ops.mesh.primitive_plane_add(size=2, location=(0, 0, 0))\n",
    "    plane = bpy.context.active_object\n",
    "    plane.name = f\"SlicePlane_{axis.upper()}_{position:.2f}\"\n",
    "\n",
    "    # Scale and position the plane\n",
    "    plane.scale = (plane_size[0] / 2, plane_size[1] / 2, 1)\n",
    "    plane.location = location\n",
    "    plane.rotation_euler = rotation\n",
    "\n",
    "    # Apply transformations (scale, location, rotation)\n",
    "    bpy.ops.object.transform_apply(location=True, scale=True, rotation=True)\n",
    "\n",
    "    # Restore the previously active object\n",
    "    if current_active:\n",
    "        bpy.context.view_layer.objects.active = current_active\n",
    "\n",
    "    return plane\n",
    "\n",
    "\n",
    "def create_material_from_array(slice_plane, array, material_name=\"SliceMaterial\"):\n",
    "    \"\"\"\n",
    "    Creates a material for a plane using a 2D numpy array as a texture.\n",
    "\n",
    "    Args:\n",
    "        slice_plane (bpy.types.Object): The plane object to which the material will be applied.\n",
    "        array (numpy.ndarray): 2D array representing grayscale values (0-1), or 3D array representing RGBA values (0-1).\n",
    "        material_name (str): Name of the new material.\n",
    "    \"\"\"\n",
    "    # Validate input array\n",
    "    if not len(array.shape) in [2,3]:\n",
    "        raise ValueError(\"Input array must be 2D.\")\n",
    "    \n",
    "    # Normalize array to range [0, 1] and convert to a flat list\n",
    "    image_height, image_width = array.shape[:2]\n",
    "    pixel_data = np.zeros((image_height, image_width, 4), dtype=np.float32)  # RGBA\n",
    "    if len(array.shape) == 2:\n",
    "        pixel_data[..., 0] =  pixel_data[..., 1] = pixel_data[..., 2] = array\n",
    "        pixel_data[..., 3] = 1.0  # Alpha\n",
    "    else:\n",
    "        pixel_data[...] = array\n",
    "    pixel_data = pixel_data.flatten()\n",
    "\n",
    "    # Create a new image in Blender\n",
    "    image = bpy.data.images.new(name=\"SliceTexture\", width=image_width, height=image_height)\n",
    "    image.pixels = pixel_data.tolist()\n",
    "\n",
    "    # Create a new material\n",
    "    material = bpy.data.materials.new(name=material_name)\n",
    "    material.use_nodes = True\n",
    "    nodes = material.node_tree.nodes\n",
    "    links = material.node_tree.links\n",
    "\n",
    "    # Clear default nodesx\n",
    "    for node in nodes:\n",
    "        nodes.remove(node)\n",
    "\n",
    "    # Add required nodes\n",
    "    texture_node = nodes.new(type=\"ShaderNodeTexImage\")\n",
    "    texture_node.image = image\n",
    "    bsdf_node = nodes.new(type=\"ShaderNodeBsdfPrincipled\")\n",
    "    output_node = nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "\n",
    "    # Arrange nodes\n",
    "    texture_node.location = (-400, 0)\n",
    "    bsdf_node.location = (0, 0)\n",
    "    output_node.location = (400, 0)\n",
    "\n",
    "    # Connect nodes\n",
    "    links.new(texture_node.outputs[\"Color\"], bsdf_node.inputs[\"Base Color\"])\n",
    "    links.new(bsdf_node.outputs[\"BSDF\"], output_node.inputs[\"Surface\"])\n",
    "\n",
    "    # Assign the material to the plane\n",
    "    slice_plane.data.materials.append(material)\n",
    "\n",
    "# Example usage: Create a slice of a box with dimensions 4x5x6 along the Z-axis at position 3\n",
    "\n",
    "length, width, height = (np.array(bpy.context.scene.tissue_cartography_data.shape[1:]) *\n",
    "                         bpy.context.scene.tissue_cartography_resolution_array)\n",
    "\n",
    "slice_plane = create_slice_plane(length, width, height, axis='z', position=50)\n",
    "\n",
    "\n",
    "\n",
    "slice_img = bpy.context.scene.tissue_cartography_data[0,:,:,50] # need to \n",
    "slice_img = slice_img-np.quantile(slice_img, 0.05)\n",
    "slice_img = slice_img/np.quantile(slice_img, 0.95)\n",
    "slice_img = np.clip(slice_img, 0, 1)\n",
    "slice_img = slice_img.T\n",
    "\n",
    "\n",
    "create_material_from_array(slice_plane, slice_img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#create_box_from_cube(190, 509, 188)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb78b27-423e-4d1d-adac-53b9e4e6568c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0638d045-ae0c-4597-bd7b-01407fad659f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32eff18-b57b-4de2-8a31-b6afa23b274c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:blender-tissue-cartography] *",
   "language": "python",
   "name": "conda-env-blender-tissue-cartography-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
