{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6292445f-8b24-43e7-878e-48cf54935695",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp blender_tissue_cartography_addon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff66780-4538-49e7-a1e2-4b1030fad4ec",
   "metadata": {},
   "source": [
    "## Blender add-on\n",
    "\n",
    "> Create add-on for blender to do mesh-creation from segmentation and pullbacks from within blender\n",
    "\n",
    "Note: this module is _not_ for use in normal python, but must be run as an add-on in Blender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f139db3-530a-42f3-b38f-baa3ba226bb7",
   "metadata": {},
   "source": [
    "### Notes and To do\n",
    "\n",
    "1. Image normalization for ortho-slices and textures. Maybe add a global variable \"normalized image\"? Normalization slider in materials.\n",
    "\n",
    "2. axis permutation\n",
    "\n",
    "3. marching cubes\n",
    "\n",
    "4. better color options for vertex shading\n",
    "\n",
    "\n",
    "More generally: somehow associate the data (like projections etc) to the mesh, and the image data to the bounding box, instead of having a global variable floating around. This can be done by assigning custom data as\n",
    "\n",
    "```\n",
    "obj[\"data_name\"] = (np.array(...), shape)\n",
    "\n",
    "```\n",
    "Need to reconstruct using `np.array(arr.tolist()).reshape(shape)`.\n",
    "\n",
    "`bpy.context.selected_objects`.\n",
    "\n",
    "Need to be in Object mode btw.\n",
    "\n",
    "\n",
    "File loading not ideal - often does not work, have to paste full path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1e766c-6eed-429b-8181-408f304d3f5e",
   "metadata": {},
   "source": [
    "Idea: selected + active objects. Make sure both bounding box and mesh are selected. Give the bounding box some attribute so I know which of the selected objects is the 3d data and which is the mesh."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effd0c98-1acc-4dd8-9a6d-ae3a809543d7",
   "metadata": {},
   "source": [
    "## Specs\n",
    "\n",
    "### Inputs\n",
    "\n",
    "1. Path to `.tiff` file\n",
    "2. $x$/$y$/$z$ resolution (can be read out automatically)\n",
    "3. Optional: path to segmentation `.tiff`\n",
    "\n",
    "The user can also import the mesh directly. \n",
    "\n",
    "### Functionality\n",
    "\n",
    "Convention: mesh vertex coordinates always have to be in microns.\n",
    "\n",
    "0. Create bounding box (in microns) in blender that shows outline of volumetric data. Allow loading orthoslices of raw data.\n",
    "\n",
    "1. Upon loading, convert segmentation to mesh using volume to mesh. Options: smoothing scale.\n",
    "\n",
    "Errors: file not found, segmentation and image do not have the same number of pixels. (Q: allow separate x/y/z resolution for segmentation?)\n",
    "\n",
    "2. Upon button click, create multilayer pullback and save to disk as pngs and multi page tiff. Also save normal and 3d coord bake. As well as max projection.\n",
    "\n",
    "**Options**: resolution (pixels), normal layer spacing.\n",
    "\n",
    "**Errors**: file not found, no UV map\n",
    "\n",
    "**Warnings**: UV map has self intersections, UV map out of bounds\n",
    "\n",
    "### Internals\n",
    "\n",
    "1. Meshing (segmentation -> mesh). Load segmentation as .tiff, convert to vdb volume, use blenders volume to mesh node\n",
    "\n",
    "2. Cartographic projection. The mesh used is the currently selected one! Two steps.\n",
    "\n",
    "    a. Bake 3d coordinates and normals to UV. Use `scipy`-interpolation - render bake is difficult to get to work.\n",
    "\n",
    "    b. Bake from volumetric data to UV. Use `scipy`-interpolation as in the pytho package.\n",
    "\n",
    "4. Saving. Always save to fixed path, say extracted_textures in the same path as image. Careful with windows, Linux, etc path handling.\n",
    "\n",
    "5. Create textures/shader from baked data.\n",
    "\n",
    "6. Load orthoslices of raw data\n",
    "\n",
    "7. Optional: Create normal shifted meshes (not visible by default). Shrink/fatten blender button.\n",
    "\n",
    "### Conventions:\n",
    "\n",
    "1. Mesh orientation: $Y$ forward, $Z$ up! (when importing the mesh).\n",
    "\n",
    "### Dependencies:\n",
    "\n",
    "1. Numpy (standard)\n",
    "2. Scipy, if available (interpolation). I can also do interpolation myself \n",
    "3. `tifffile` for reading `.tiff` files (check microscopy nodes source code), and converting to .vdb (for meshing) OR some marching cubes code.\n",
    "\n",
    "\n",
    "TO DO: vertex color based shading! Bounding box!\n",
    "\n",
    "`numpy`, `scipy`, `tifffile` and `skimage` are shipped with Blender's python!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e3cfe1-ca50-4534-8c33-9ea43c264065",
   "metadata": {},
   "source": [
    "## Ressources\n",
    "\n",
    "Add-on Tutorial: https://docs.blender.org/manual/en/latest/advanced/scripting/addon_tutorial.html\n",
    "\n",
    "MicroscopyNodes source code: https://github.com/oanegros/MicroscopyNodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2636c1f6-d7f7-4c99-a9e5-aa628d240f19",
   "metadata": {},
   "source": [
    "### baking normal and world position\n",
    "\n",
    "Texture baking the surface normals and vertex positions tunrs out to be more involved than I would like.\n",
    "\n",
    "In particular, it is difficult to guarantee that the coordinates are not distorted or rescaled in a way that I don't understand. Also, it can be slow. Also difficult to get to work as a script, unfortunately. Often I just get black images for reasons I do not understand.\n",
    "\n",
    "I will therefore resort to using (manual) interpolation. Luckily, it appears that `scipy` is available in blender python. We need add one extra step (UV layout mask) though,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cef6dd-7c42-48ac-a259-f7abede4d721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7531f6bd-9ced-46b6-a389-99b0208f0cf9",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b4b5265-e8f1-4767-930e-76fece7d41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import measure\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe99aa05-26e4-4295-a468-710e582ecdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6702372-866f-4e42-b7d4-6bbc9a167fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33234fd2-17bd-42fc-b6f8-3d3c31656367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c269d1-9b5b-40b6-a788-096b90a1cc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e69f4400-ca7c-418c-86ea-7dff39632154",
   "metadata": {},
   "source": [
    "# Add-on code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2cb886-90be-4c4e-b007-7b1ab82f1b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "bl_info = {\n",
    "    \"name\": \"Tissue Cartography\",\n",
    "    \"blender\": (3, 0, 0),\n",
    "    \"category\": \"Scene\",\n",
    "}\n",
    "\n",
    "import bpy\n",
    "from bpy.props import StringProperty, FloatVectorProperty, FloatProperty, IntProperty, EnumProperty\n",
    "from bpy.types import Operator, Panel\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tifffile\n",
    "from scipy import interpolate, ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c493739-7468-4143-9cff-803df284f4de",
   "metadata": {},
   "source": [
    "### I/O and image handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43130f05-06ab-4e85-bca6-3c2a1a5b1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def load_png(image_path):\n",
    "    \"\"\"Load .png into numpy array.\"\"\"\n",
    "    image = bpy.data.images.load(image_path)\n",
    "    width, height = image.size\n",
    "    pixels = np.array(image.pixels[:], dtype=np.float32)\n",
    "    return pixels.reshape((height, width, -1))\n",
    "\n",
    "\n",
    "def normalize_quantiles(image, quantiles=(0.01, 0.99), channel_axis=None, clip=False,\n",
    "                        data_type=None):\n",
    "    \"\"\"\n",
    "    Normalize a multi-dimensional image by setting given quantiles to 0 and 1.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : np.array\n",
    "        Multi-dimensional image.\n",
    "    quantiles : tuple\n",
    "        Image quantile to set to 0 and 1.\n",
    "    channel_axis : int or None\n",
    "        If None, the image is assumed to have only a single channel.\n",
    "        If int, indicates the position of the channel axis. \n",
    "        Each channel is normalized separately.\n",
    "    clip : bool\n",
    "        Whether to clip image to 0-1. Automatically enabled if converting to int dtype.\n",
    "    data_type : None, np.unit8 or np.uint16\n",
    "        If not None, image is converted to give data type.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    image_normalized : np.array\n",
    "        Normalized image, the same shape as input\n",
    "    \"\"\"\n",
    "    if channel_axis is None:\n",
    "        image_normalized = image - np.nanquantile(image, quantiles[0])\n",
    "        image_normalized /= np.nanquantile(image_normalized, quantiles[1])\n",
    "        image_normalized = np.nan_to_num(image_normalized)\n",
    "    else:\n",
    "        image_normalized = np.moveaxis(image, channel_axis, 0)\n",
    "        image_normalized = np.stack([ch - np.nanquantile(ch, quantiles[0]) for ch in image_normalized])\n",
    "        image_normalized = np.stack([ch / np.nanquantile(ch, quantiles[1]) for ch in image_normalized])\n",
    "        image_normalized = np.moveaxis(np.nan_to_num(image_normalized), 0, channel_axis)\n",
    "    if clip or (data_type is not None):\n",
    "        image_normalized = np.clip(image_normalized, 0, 1)\n",
    "    if data_type is np.uint8:\n",
    "        image_normalized = np.round((2**8-1)*image_normalized).astype(np.uint8)\n",
    "    if data_type is np.uint16:\n",
    "        image_normalized = np.round((2**16-1)*image_normalized).astype(np.uint16)\n",
    "    return image_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b96f1e-4585-4e2b-b641-96d30be555db",
   "metadata": {},
   "source": [
    "### Tissue cartography - projecting 3d images to UV textures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17e7a51-2e5b-4bbc-a946-e0e30137db5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_uv_layout(uv_layout_path, image_resolution):\n",
    "    \"\"\"Get UV layout mask for currently active object and save it to disk\"\"\"\n",
    "    bpy.ops.object.mode_set(mode='EDIT')\n",
    "    bpy.ops.uv.export_layout(filepath=uv_layout_path, size=(image_resolution, image_resolution), opacity=1)\n",
    "    bpy.ops.object.mode_set(mode='OBJECT')\n",
    "    UV_layout = load_png(uv_layout_path)\n",
    "    return (UV_layout.sum(axis=-1) > 0)[::-1]\n",
    "\n",
    "\n",
    "def get_uv_normal_world_per_loop(mesh_obj, filter_unique=False):\n",
    "    \"\"\"\n",
    "    Get UV, normals, and world and normal for each loop (half-edge) as np.array.\n",
    "    \n",
    "    If filter_unique, remove \"duplicate\" loops (for which UV, normals and position\n",
    "    are identical).\n",
    "    \"\"\"\n",
    "    if not mesh_obj:\n",
    "        raise TypeError(\"No object selected\")\n",
    "    if mesh_obj.type != 'MESH':\n",
    "        raise TypeError(\"Selected object is not a mesh\")\n",
    "    world_matrix = mesh_obj.matrix_world\n",
    "    uv_layer = mesh_obj.data.uv_layers.active\n",
    "    if not uv_layer:\n",
    "        raise RuntimeError(\"Mesh does not have an active UV map\")\n",
    "    loop_uvs = np.zeros((len(mesh_obj.data.loops), 2), dtype=np.float32)\n",
    "    loop_normals = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    loop_world_positions = np.zeros((len(mesh_obj.data.loops), 3), dtype=np.float32)\n",
    "    for loop in mesh_obj.data.loops:\n",
    "        loop_uvs[loop.index] = uv_layer.data[loop.index].uv\n",
    "        loop_normals[loop.index] = world_matrix.to_3x3() @ mesh_obj.data.vertices[loop.vertex_index].normal\n",
    "        loop_world_positions[loop.index] = world_matrix @ mesh_obj.data.vertices[loop.vertex_index].co\n",
    "    if filter_unique:\n",
    "        unqiue_loops = np.unique(np.hstack([loop_uvs, loop_normals, loop_world_positions]), axis=0)\n",
    "        loop_uvs, loop_normals, loop_world_positions = (unqiue_loops[:,:2], unqiue_loops[:,2:5], unqiue_loops[:,5:])\n",
    "    loop_normals = np.round((loop_normals.T/np.linalg.norm(loop_normals, axis=1)).T, decimals=4)\n",
    "    return loop_uvs, loop_normals, loop_world_positions\n",
    "\n",
    "\n",
    "def bake_per_loop_values_to_uv(loop_uvs, loop_values, image_resolution):\n",
    "    \"\"\"\n",
    "    Bake (interpolate) values (normals or world position) defined per loop into the UV square.\n",
    "    \n",
    "    UV coordinates outside [0,1] are ignored.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    loop_uvs : np.array of shape (n_loops, 2)\n",
    "        UV coordinates of loop.\n",
    "    loop_values : np.array of shape (n_loops, ...)\n",
    "        Input field. Can be an array with any number of axes (e.g. scalar or vector field).\n",
    "    image_resolution : int, default 256\n",
    "        Size of UV grid. Determines resolution of result.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    \n",
    "    interpolated : np.array of shape (uv_grid_steps, uv_grid_steps, ...)\n",
    "        Field across [0,1]**2 UV grid, with a uniform step size. UV positions that don't\n",
    "        correspond to any value are set to np.nan.\n",
    "            \n",
    "    \"\"\"\n",
    "    U, V = np.meshgrid(*(2*(np.linspace(0,1, image_resolution),)))\n",
    "    interpolated = interpolate.griddata(loop_uvs, loop_values, (U, V), method='linear')[::-1]\n",
    "    return interpolated\n",
    "\n",
    "\n",
    "def bake_volumetric_data_to_uv(image, baked_world_positions, resolution, baked_normals, normal_offsets=(0,)):\n",
    "    \"\"\" \n",
    "    Interpolate volumetric image data onto UV coordinate grid.\n",
    "    \n",
    "    Uses baked 3d world positions corresponding to each UV grid point (see bake_per_loop_values_to_UV).\n",
    "    3d coordinates (in microns) are converted into image coordinates via the resolution scaling factor.\n",
    "    The resolution of the bake (number of pixels) is determined by the shape of baked_world_positions.\n",
    "    \n",
    "    normal_offsets moves the 3d positions whose volumetric voxel values will be baked inwards or outwards\n",
    "    along the surface normal. Providing a list of offsets results in a multi-layer pullback\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    image : 4d np.array\n",
    "        Image, axis 0  is assumed to be the channel axis\n",
    "    baked_world_positions : np.array of shape (image_resolution, image_resolution, uv_grid_steps, 3)\n",
    "        3d world positions baked to UV grid, with uniform step size. UV positions that don't correspond to \n",
    "        any value are set to np.nan.\n",
    "    resolution : np.array of shape (3,)\n",
    "        Resolution in pixels/microns for each of the three spatial axes.\n",
    "    baked_normals : np.array of shape (image_resolution, image_resolution, uv_grid_steps, 3)\n",
    "        3d world normals baked to UV grid, with uniform step size. UV positions that don't correspond to \n",
    "        any value are set to np.nan.\n",
    "    normal_offsets : np.array of shape (n_layers,), default (0,)\n",
    "        Offsets along normal direction, in same units as interpolated_3d_positions (i.e. microns).\n",
    "        0 corresponds to no shift.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    aked_data : np.array of shape (n_channels, n_layers, image_resolution, image_resolution)\n",
    "        Multi-layer 3d volumetric data baked onto UV.\n",
    "    \"\"\"\n",
    "    x, y, z = [np.arange(ni) for ni in image.shape[1:]]\n",
    "    baked_data = []\n",
    "    for o in normal_offsets:\n",
    "        baked_layer_data = np.stack([interpolate.interpn((x, y, z), channel,\n",
    "                                     (baked_world_positions+o*baked_normals)/resolution,\n",
    "                                     method=\"linear\", bounds_error=False) for channel in image])\n",
    "        baked_data.append(baked_layer_data)\n",
    "    baked_data = np.stack(baked_data, axis=1)\n",
    "    return baked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8593cfb3-963e-42d7-a3ca-e0f726f8e307",
   "metadata": {},
   "source": [
    "### Bounding box and orthoslices for visualizing 3d data in Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58585ac3-85a3-4a63-869d-a6404e7d2134",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_box(length, width, height, name=\"RectangularBox\", hide=True):\n",
    "    \"\"\"\n",
    "    Creates a rectangular box using Blender's default cube.\n",
    "    One corner is positioned at the origin, and the box lies in the positive x/y/z quadrant.\n",
    "\n",
    "    Args:\n",
    "        length (float): Length of the box along the X-axis.\n",
    "        width (float): Width of the box along the Y-axis.\n",
    "        height (float): Height of the box along the Z-axis.\n",
    "    \"\"\"\n",
    "    # Store the current active object\n",
    "    current_active = bpy.context.active_object\n",
    "\n",
    "    bpy.ops.mesh.primitive_cube_add(size=2, location=(0, 0, 0))\n",
    "    obj = bpy.context.active_object\n",
    "    obj.name = name\n",
    "    obj.scale = (length / 2, width / 2, height / 2)\n",
    "    obj.location = (length / 2, width / 2, height / 2)\n",
    "    bpy.ops.object.transform_apply(location=True, scale=True)\n",
    "    obj.hide_set(hide)\n",
    "    # re-select the currently active object\n",
    "    if current_active:\n",
    "        bpy.context.view_layer.objects.active = current_active\n",
    "    return obj\n",
    "\n",
    "\n",
    "def create_slice_plane(length, width, height, axis='z', position=0.0):\n",
    "    \"\"\"\n",
    "    Creates a 2D plane as a slice of a rectangular box along a specified axis.\n",
    "    The plane lies within the bounds of the box.\n",
    "\n",
    "    Args:\n",
    "        length (float): Length of the box along the X-axis.\n",
    "        width (float): Width of the box along the Y-axis.\n",
    "        height (float): Height of the box along the Z-axis.\n",
    "        axis (str): Axis along which to slice ('x', 'y', or 'z').\n",
    "        position (float): Position along the chosen axis for the slice plane.\n",
    "                          Should be within the range of the box dimensions.\n",
    "    \"\"\"\n",
    "    current_active = bpy.context.active_object\n",
    "    # Validate axis and position\n",
    "    if axis not in {'x', 'y', 'z'}:\n",
    "        raise ValueError(\"Axis must be 'x', 'y', or 'z'.\")\n",
    "    \n",
    "    axis_limits = {'x': length, 'y': width, 'z': height}\n",
    "    if not (0.0 <= position <= axis_limits[axis]):\n",
    "        raise ValueError(f\"Position must be within [0, {axis_limits[axis]}] for axis {axis}.\")\n",
    "\n",
    "    # Create the plane's dimensions based on the slicing axis\n",
    "    if axis == 'x':\n",
    "        plane_size = (height, width) #(width, height)\n",
    "        location =  (position, width / 2, height / 2)\n",
    "        rotation = (0, 1.5708, 0)  # Rotate to align with the YZ-plane\n",
    "    elif axis == 'y':\n",
    "        plane_size = (length, height)\n",
    "        location = (length / 2, position, height / 2)\n",
    "        rotation = (1.5708, 0, 0)  # Rotate to align with the XZ-plane\n",
    "    else:  # 'z'\n",
    "        plane_size = (length, width)\n",
    "        location = (length / 2, width / 2, position)\n",
    "        rotation = (0, 0, 0)  # No rotation needed for the XY-plane\n",
    "\n",
    "    # Add a plane\n",
    "    bpy.ops.mesh.primitive_plane_add(size=2, location=(0, 0, 0))\n",
    "    plane = bpy.context.active_object\n",
    "    plane.name = f\"SlicePlane_{axis.upper()}_{position:.2f}\"\n",
    "\n",
    "    # Scale and position the plane\n",
    "    plane.scale = (plane_size[0] / 2, plane_size[1] / 2, 1)\n",
    "    plane.location = location\n",
    "    plane.rotation_euler = rotation\n",
    "\n",
    "    # Apply transformations (scale, location, rotation)\n",
    "    bpy.ops.object.transform_apply(location=True, scale=True, rotation=True)\n",
    "\n",
    "    # Restore the previously active object\n",
    "    if current_active:\n",
    "        bpy.context.view_layer.objects.active = current_active\n",
    "\n",
    "    return plane\n",
    "\n",
    "\n",
    "def get_slice_image(image_3d, resolution, axis='z', position=0.0):\n",
    "    \"\"\"Get slice of 3d image along axis for ortho-slice visualization.\n",
    "    image_3d must be a 4d array (channels, x, y, z). Position in microns.\"\"\"\n",
    "    if axis == 'x':\n",
    "        ind = int(np.round(position / resolution[0]))\n",
    "        slice_img = image_3d[:,ind,:,::-1]\n",
    "    elif axis == 'y':\n",
    "        ind = int(np.round(position / resolution[1]))\n",
    "        slice_img = image_3d[:,:,ind,:].transpose((0,2,1))\n",
    "    elif axis == 'z': \n",
    "        ind = int(np.round(position / resolution[0]))\n",
    "        slice_img = image_3d[:,:,:,ind].transpose((0,2,1))\n",
    "    return slice_img\n",
    "\n",
    "\n",
    "def create_material_from_array(slice_plane, array, material_name=\"SliceMaterial\"):\n",
    "    \"\"\"\n",
    "    Creates a material for a ortho-slice plane using a 2D numpy array as a texture.\n",
    "\n",
    "    Args:\n",
    "        slice_plane (bpy.types.Object): The plane object to which the material will be applied.\n",
    "        array (numpy.ndarray): 2D array representing grayscale values (0-1), or 3D array representing RGBA values (0-1).\n",
    "        material_name (str): Name of the new material.\n",
    "    \"\"\"\n",
    "    # Validate input array\n",
    "    if not len(array.shape) in [2,3]:\n",
    "        raise ValueError(\"Input array must be 2D.\")\n",
    "    \n",
    "    # Normalize array to range [0, 1] and convert to a flat list\n",
    "    image_height, image_width = array.shape[:2]\n",
    "    pixel_data = np.zeros((image_height, image_width, 4), dtype=np.float32)  # RGBA\n",
    "    if len(array.shape) == 2:\n",
    "        pixel_data[..., 0] =  pixel_data[..., 1] = pixel_data[..., 2] = array\n",
    "        pixel_data[..., 3] = 1.0  # Alpha\n",
    "    else:\n",
    "        pixel_data[...] = array\n",
    "    pixel_data = pixel_data.flatten()\n",
    "\n",
    "    # Create a new image in Blender\n",
    "    image = bpy.data.images.new(name=\"SliceTexture\", width=image_width, height=image_height)\n",
    "    image.pixels = pixel_data.tolist()\n",
    "\n",
    "    # Create a new material\n",
    "    material = bpy.data.materials.new(name=material_name)\n",
    "    material.use_nodes = True\n",
    "    nodes = material.node_tree.nodes\n",
    "    links = material.node_tree.links\n",
    "\n",
    "    # Clear default nodesx\n",
    "    for node in nodes:\n",
    "        nodes.remove(node)\n",
    "\n",
    "    # Add required nodes\n",
    "    texture_node = nodes.new(type=\"ShaderNodeTexImage\")\n",
    "    texture_node.image = image\n",
    "    bsdf_node = nodes.new(type=\"ShaderNodeBsdfPrincipled\")\n",
    "    output_node = nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "\n",
    "    # Arrange nodes\n",
    "    texture_node.location = (-400, 0)\n",
    "    bsdf_node.location = (0, 0)\n",
    "    output_node.location = (400, 0)\n",
    "\n",
    "    # Connect nodes\n",
    "    links.new(texture_node.outputs[\"Color\"], bsdf_node.inputs[\"Base Color\"])\n",
    "    links.new(bsdf_node.outputs[\"BSDF\"], output_node.inputs[\"Surface\"])\n",
    "\n",
    "    # Assign the material to the plane\n",
    "    slice_plane.data.materials.append(material)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecebc356-c56a-46d5-be00-43a4101c43e4",
   "metadata": {},
   "source": [
    "### Shading using cartographic projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf59f9-e830-4667-81d1-2cdcc02cb700",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def create_material_from_multilayer_array(mesh, array, material_name=\"ProjectedMaterial\"):\n",
    "    \"\"\"\n",
    "    Creates a material for a mesh using multi-channel, multi-layer projection.\n",
    "\n",
    "    Args:\n",
    "        obj (bpy.types.Object): The mesh object to which the material will be applied.\n",
    "        array (numpy.ndarray): 4D array of shape (channels, layers, U, V)\n",
    "        material_name (str): Name of the new material.\n",
    "    \"\"\"\n",
    "    # Validate and normalize input array\n",
    "    if not len(array.shape) == 4:\n",
    "        raise ValueError(\"Input array must have 4 axes.\")\n",
    "    array_normalized = normalize_quantiles(array, quantiles=(0.01, 0.99), channel_axis=0,\n",
    "                                           clip=True, data_type=None)\n",
    "    # Create a new image in Blender for each layer and channel\n",
    "    image_height, image_width = array.shape[-2:]\n",
    "    n_channels, n_layers = array.shape[:2]\n",
    "    images = {}\n",
    "    for ic, chanel in enumerate(array_normalized):\n",
    "        for il, layer in enumerate(chanel):\n",
    "            pixel_data = np.zeros((image_height, image_width, 4), dtype=np.float32)\n",
    "            pixel_data[..., 0] =  pixel_data[..., 1] = pixel_data[..., 2] = layer[::-1]\n",
    "            pixel_data[..., 3] = 1.0  # Alpha\n",
    "            pixel_data = pixel_data.flatten()\n",
    "            images[(ic, il)] = bpy.data.images.new(name=f\"Channel_{ic}_Layer_{il}\",\n",
    "                                                   width=image_width, height=image_height)\n",
    "            images[(ic, il)].pixels = pixel_data.tolist()\n",
    "    # Create a new material\n",
    "    material = bpy.data.materials.new(name=material_name)\n",
    "    material.use_nodes = True\n",
    "    nodes = material.node_tree.nodes\n",
    "    links = material.node_tree.links\n",
    "    # Clear default nodesx\n",
    "    for node in nodes:\n",
    "        nodes.remove(node)\n",
    "    # Add required nodes\n",
    "    texture_nodes = {}\n",
    "    for (ic, il), image in images.items():\n",
    "        texture_nodes[(ic, il)] = nodes.new(type=\"ShaderNodeTexImage\")\n",
    "        texture_nodes[(ic, il)].image = image\n",
    "        texture_nodes[(ic, il)].location = (-400, ic*400 + il*300)\n",
    "    \n",
    "    bsdf_node = nodes.new(type=\"ShaderNodeBsdfPrincipled\")\n",
    "    output_node = nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "\n",
    "    # Arrange nodes\n",
    "    bsdf_node.location = (0, 0)\n",
    "    output_node.location = (400, 0)\n",
    "\n",
    "    # Connect nodes\n",
    "    links.new(texture_nodes[(0,0)].outputs[\"Color\"], bsdf_node.inputs[\"Base Color\"])\n",
    "    links.new(bsdf_node.outputs[\"BSDF\"], output_node.inputs[\"Surface\"])\n",
    "\n",
    "    # Assign the material to the mesh\n",
    "    mesh.data.materials.append(material)\n",
    "    mesh.active_material = material\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a014a9c-d0e7-4b79-9e89-150d9f0413ee",
   "metadata": {},
   "source": [
    "### Vertex shading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8eb76b-6580-4fed-b803-7c607d7f5a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def compute_edge_lengths(obj):\n",
    "    \"\"\"\n",
    "    Computes the lengths of all edges in a mesh object as a numpy array.\n",
    "\n",
    "    Args:\n",
    "        obj (bpy.types.Object): The mesh object to compute edge lengths for.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 1D array containing the lengths of all edges in the mesh.\n",
    "    \"\"\"\n",
    "    # Ensure the object is a mesh\n",
    "    if obj.type != 'MESH':\n",
    "        raise ValueError(\"The selected object is not a mesh.\")\n",
    "    # Ensure the mesh is in edit mode for accurate vertex data\n",
    "    bpy.context.view_layer.objects.active = obj\n",
    "    if obj.mode != 'OBJECT':\n",
    "        bpy.ops.object.mode_set(mode='OBJECT')\n",
    "    edge_lengths = []\n",
    "    for edge in obj.data.edges:\n",
    "        v1 = obj.data.vertices[edge.vertices[0]].co\n",
    "        v2 = obj.data.vertices[edge.vertices[1]].co\n",
    "        edge_lengths.append((v1 - v2).length)\n",
    "    return np.array(edge_lengths)\n",
    "\n",
    "\n",
    "def get_image_to_vertex_interpolator(obj, image_3d, resolution_array, quantiles=(0.01, 0.99)):\n",
    "    \"\"\"\n",
    "    Get interpolator that maps vertex position -> image intensity.\n",
    "    \n",
    "    Returns a list of interpolators, one for each channel.\n",
    "    To avoid aliasing, the 3d image is smoothed with\n",
    "    sigma=median edge length /2. The image data is also normalized to\n",
    "    range from 0-1 using the provided quantiles.\n",
    "    \"\"\"\n",
    "    anti_aliasing_scale = np.median(compute_edge_lengths(obj))/2\n",
    "    image_3d_smoothed = np.stack([ndimage.gaussian_filter(ch, anti_aliasing_scale/resolution_array)\n",
    "                                  for ch in image_3d])\n",
    "    image_3d_smoothed = normalize_quantiles(image_3d_smoothed,\n",
    "                                            quantiles=quantiles, clip=True, data_type=None)\n",
    "    x, y, z = [np.arange(ni)*resolution_array[i]\n",
    "               for i, ni in enumerate(image_3d.shape[1:])]\n",
    "    return [interpolate.RegularGridInterpolator((x,y,z), ch, method='linear', bounds_error=False)\n",
    "            for ch in image_3d_smoothed]\n",
    "\n",
    "\n",
    "def assign_vertex_colors(obj, colors):\n",
    "    \"\"\"\n",
    "    Assigns an RGB color to each vertex in the given object.\n",
    "    Args:\n",
    "        obj: The mesh object.\n",
    "        colors: A list or dict of (R, G, B) tuples for each vertex.\n",
    "    \"\"\"\n",
    "    if obj.type != 'MESH':\n",
    "        print(\"Object is not a mesh!\")\n",
    "        return\n",
    "    if not obj.data.vertex_colors:\n",
    "        obj.data.vertex_colors.new()\n",
    "    color_layer = obj.data.vertex_colors.active\n",
    "    # Assign colors to each loop (face corner)\n",
    "    for loop in obj.data.loops:    \n",
    "        color_layer.data[loop.index].color = (*colors[loop.vertex_index], 1.0)  # RGBA\n",
    "    return None\n",
    "\n",
    "\n",
    "def create_vertex_color_material(object, material_name=\"VertexColorMaterial\"):\n",
    "    \"\"\"\n",
    "    Creates a material for an object that uses vertex colors.\n",
    "    The R, G, and B channels are processed through separate \"Map Range\" nodes\n",
    "    to edit their brightness, and then combined into a Principled BSDF.\n",
    "\n",
    "    Args:\n",
    "        object (bpy.types.Object): The object to which the material will be applied.\n",
    "        material_name (str): Name of the new material.\n",
    "    \"\"\"\n",
    "    # Ensure the object has a vertex color layer\n",
    "    if not object.data.vertex_colors:\n",
    "        raise ValueError(\"The object has no vertex color layers.\")\n",
    "\n",
    "    # Create a new material\n",
    "    material = bpy.data.materials.new(name=material_name)\n",
    "    material.use_nodes = True\n",
    "    nodes = material.node_tree.nodes\n",
    "    links = material.node_tree.links\n",
    "\n",
    "    # Clear default nodes\n",
    "    for node in nodes:\n",
    "        nodes.remove(node)\n",
    "\n",
    "    # Add nodes\n",
    "    vertex_color_node = nodes.new(type=\"ShaderNodeVertexColor\")\n",
    "    vertex_color_node.layer_name = object.data.vertex_colors[0].name\n",
    "    vertex_color_node.location = (-1000, 0)\n",
    "\n",
    "    separate_color_node = nodes.new(type=\"ShaderNodeSeparateRGB\")\n",
    "    separate_color_node.location = (-800, 0)\n",
    "\n",
    "    map_range_r = nodes.new(type=\"ShaderNodeMapRange\")\n",
    "    map_range_r.label = \"Map Range R\"\n",
    "    map_range_r.location = (-600, 300)\n",
    "\n",
    "    map_range_g = nodes.new(type=\"ShaderNodeMapRange\")\n",
    "    map_range_g.label = \"Map Range G\"\n",
    "    map_range_g.location = (-600, 0)\n",
    "\n",
    "    map_range_b = nodes.new(type=\"ShaderNodeMapRange\")\n",
    "    map_range_b.label = \"Map Range B\"\n",
    "    map_range_b.location = (-600, -300)\n",
    "\n",
    "    combine_rgb = nodes.new(type=\"ShaderNodeCombineRGB\")\n",
    "    combine_rgb.location = (-200, 0)\n",
    "\n",
    "    bsdf_node = nodes.new(type=\"ShaderNodeBsdfPrincipled\")\n",
    "    bsdf_node.location = (000, 0)\n",
    "\n",
    "    output_node = nodes.new(type=\"ShaderNodeOutputMaterial\")\n",
    "    output_node.location = (400, 0)\n",
    "\n",
    "    # Connect nodes\n",
    "    links.new(vertex_color_node.outputs[\"Color\"], separate_color_node.inputs[\"Image\"])\n",
    "    links.new(separate_color_node.outputs[\"R\"], map_range_r.inputs[\"Value\"])\n",
    "    links.new(separate_color_node.outputs[\"G\"], map_range_g.inputs[\"Value\"])\n",
    "    links.new(separate_color_node.outputs[\"B\"], map_range_b.inputs[\"Value\"])\n",
    "\n",
    "    links.new(map_range_r.outputs[\"Result\"], combine_rgb.inputs[\"R\"])\n",
    "    links.new(map_range_g.outputs[\"Result\"], combine_rgb.inputs[\"G\"])\n",
    "    links.new(map_range_b.outputs[\"Result\"], combine_rgb.inputs[\"B\"])\n",
    "\n",
    "    links.new(combine_rgb.outputs[\"Image\"], bsdf_node.inputs[\"Base Color\"])\n",
    "    links.new(bsdf_node.outputs[\"BSDF\"], output_node.inputs[\"Surface\"])\n",
    "\n",
    "    # Set default map range values for each channel\n",
    "    for map_range_node in [map_range_r, map_range_g, map_range_b]:\n",
    "        map_range_node.inputs[\"From Min\"].default_value = 0.0\n",
    "        map_range_node.inputs[\"From Max\"].default_value = 1.0\n",
    "        map_range_node.inputs[\"To Min\"].default_value = 0.0\n",
    "        map_range_node.inputs[\"To Max\"].default_value = 1.0\n",
    "\n",
    "    # Assign the material to the object\n",
    "    if object.data.materials:\n",
    "        object.data.materials[0] = material\n",
    "    else:\n",
    "        object.data.materials.append(material)\n",
    "    object.active_material = material\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf7fe8-9b20-4ed3-bc7d-f484bde0db09",
   "metadata": {},
   "source": [
    "### Operators defining add-on user interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d858c-1884-4dcb-a040-505cdf25ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class LoadTIFFOperator(Operator):\n",
    "    \"\"\"Load .tif file and resolution. Also creates a bounding box object.\"\"\"\n",
    "    bl_idname = \"scene.load_tiff\"\n",
    "    bl_label = \"Load TIFF File\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        file_path = context.scene.tissue_cartography_file\n",
    "        resolution = context.scene.tissue_cartography_resolution\n",
    "\n",
    "        # Load resolution as a NumPy array\n",
    "        resolution_array = np.array(resolution)\n",
    "        self.report({'INFO'}, f\"Resolution loaded: {resolution_array}\")\n",
    "\n",
    "        # Load TIFF file as a NumPy array\n",
    "        if not (file_path.lower().endswith(\".tiff\") or file_path.lower().endswith(\".tif\")):\n",
    "            self.report({'ERROR'}, \"Selected file is not a TIFF\")\n",
    "            return {'CANCELLED'}\n",
    "        try:\n",
    "            data = tifffile.imread(file_path)\n",
    "            if len(data.shape) == 3: # add singleton channel axis to single channel-data \n",
    "                data = data[np.newaxis]\n",
    "            assert len(data.shape) == 4, \"Data must be volumetric!\"\n",
    "            self.report({'INFO'}, f\"TIFF file loaded with shape {data.shape}\")\n",
    "            # Store variables in Blender's global storage\n",
    "            bpy.types.Scene.tissue_cartography_data = data\n",
    "            bpy.types.Scene.tissue_cartography_resolution_array = resolution_array\n",
    "            # create a bounding box mesh to represent the data\n",
    "            box = create_box(*(np.array(data.shape[1:])*resolution_array),\n",
    "                             name=f\"{Path(file_path).name}_BoundingBox\",\n",
    "                             hide=False)\n",
    "            box.display_type = 'WIRE'\n",
    "            # attach the data to the box\n",
    "            box[\"resolution\"] = resolution_array.tolist()\n",
    "            box[\"3D_data\"] = (data.tolist(), data.shape) # data will be converted to list, so need to save its shape\n",
    "            \n",
    "        except Exception as e:\n",
    "            self.report({'ERROR'}, f\"Failed to load TIFF file: {e}\")\n",
    "            return {'CANCELLED'}\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class CreateProjectionOperator(Operator):\n",
    "    \"\"\"\n",
    "    Create a cartographic projection.\n",
    "    \n",
    "    This is done in two steps: first, bake 3d world positions and normals to UV,\n",
    "    then use the baked positions to interpolate the volumetric data\n",
    "    to UV.\n",
    "    \"\"\"\n",
    "    bl_idname = \"scene.create_projection\"\n",
    "    bl_label = \"Create Projection\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        # Validate selected object and UV map\n",
    "        obj = context.active_object\n",
    "        if not obj or obj.type != 'MESH':\n",
    "            self.report({'ERROR'}, \"No mesh object selected!\")\n",
    "            return {'CANCELLED'}\n",
    "        # Ensure the object has a UV map\n",
    "        if not obj.data.uv_layers:\n",
    "            self.report({'ERROR'}, \"The selected mesh does not have a UV map!\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        # Parse offsets into a NumPy array\n",
    "        offsets_str = context.scene.tissue_cartography_offsets\n",
    "        try:\n",
    "            offsets_array = np.array([float(x) for x in offsets_str.split(\",\") if x.strip()])\n",
    "            if offsets_array.size == 0:\n",
    "                offsets_array = np.array([0])\n",
    "            self.report({'INFO'}, f\"Offsets loaded: {offsets_array}\")\n",
    "        except ValueError as e:\n",
    "            self.report({'ERROR'}, f\"Invalid offsets input: {e}\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        # Parse projection resolution\n",
    "        projection_resolution = context.scene.projection_resolution\n",
    "        self.report({'INFO'}, f\"Using projection resolution: {projection_resolution}\")\n",
    "\n",
    "        # texture bake normals and world positions\n",
    "        loop_uvs, loop_normals, loop_world_positions = get_uv_normal_world_per_loop(obj, filter_unique=True)\n",
    "        \n",
    "        baked_normals = bake_per_loop_values_to_uv(loop_uvs, loop_normals, \n",
    "                                                   image_resolution=projection_resolution)\n",
    "        baked_normals = (baked_normals.T/np.linalg.norm(baked_normals.T, axis=0)).T\n",
    "        baked_world_positions = bake_per_loop_values_to_uv(loop_uvs, loop_world_positions,\n",
    "                                                           image_resolution=projection_resolution)\n",
    "        # obtain UV layout and use it to get a mask\n",
    "        uv_layout_path = str(Path(bpy.path.abspath(\"//\")).joinpath(f'{obj.name}_UV_layout.png'))\n",
    "        mask = get_uv_layout(uv_layout_path, projection_resolution)\n",
    "        baked_normals[~mask] = np.nan\n",
    "        baked_world_positions[~mask] = np.nan\n",
    "        \n",
    "        # create a pullback\n",
    "        baked_data = bake_volumetric_data_to_uv(context.scene.tissue_cartography_data,\n",
    "                                                baked_world_positions, \n",
    "                                                context.scene.tissue_cartography_resolution_array,\n",
    "                                                baked_normals, normal_offsets=offsets_array)\n",
    "        print(obj.name)\n",
    "        print(\"all nans?\", np.mean(np.isnan(baked_data)))\n",
    "        # set results as attributes of the mesh\n",
    "        obj[\"baked_data\"] = (baked_data.tolist(), baked_data.shape)\n",
    "        obj[\"baked_normals\"] = (baked_normals.tolist(), baked_normals.shape)\n",
    "        obj[\"baked_world_positions\"] = (baked_world_positions.tolist(), baked_world_positions.shape)\n",
    "\n",
    "        # create texture\n",
    "        create_material_from_multilayer_array(obj, baked_data, material_name=\"ProjectedMaterial\")\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class SaveProjectionOperator(bpy.types.Operator):\n",
    "    \"\"\"Save cartographic projection to disk\"\"\"\n",
    "    bl_idname = \"scene.save_projection\"\n",
    "    bl_label = \"Save Projection\"\n",
    "    \n",
    "    filepath: bpy.props.StringProperty(subtype=\"FILE_PATH\")\n",
    "    \n",
    "    def invoke(self, context, event):\n",
    "        # Open file browser to choose the save location\n",
    "        context.window_manager.fileselect_add(self)\n",
    "        return {'RUNNING_MODAL'}\n",
    "    \n",
    "    def execute(self, context):\n",
    "        obj = context.active_object\n",
    "        if not obj or \"baked_data\" not in obj:\n",
    "            self.report({'ERROR'}, \"No baked data found on the active object!\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        # Get the baked data\n",
    "        baked_data = np.array(obj[\"baked_data\"][0]).reshape(obj[\"baked_data\"][1])\n",
    "        baked_normals = np.array(obj[\"baked_normals\"][0]).reshape(obj[\"baked_normals\"][1])\n",
    "        baked_world_positions = np.array(obj[\"baked_world_positions\"][0]).reshape(obj[\"baked_world_positions\"][1])\n",
    "        print(self.filepath)\n",
    "        # Save the data to the chosen filepath\n",
    "        try:\n",
    "            tifffile.imwrite(self.filepath + \"_BakedNormals.tif\", baked_normals)\n",
    "            tifffile.imwrite(self.filepath + \"_BakedPositions.tif\", baked_world_positions)\n",
    "            tifffile.imwrite(self.filepath + \"_BakedData.tif\", baked_data.astype(np.float32),\n",
    "                             metadata={'axes': 'ZCYX'}, imagej=True)\n",
    "            self.report({'INFO'}, f\"Cartographic projection saved to {self.filepath}\")\n",
    "        except Exception as e:\n",
    "            self.report({'ERROR'}, f\"Failed to save data: {str(e)}\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class SlicePlaneOperator(bpy.types.Operator):\n",
    "    \"\"\"Create a slice plane along the selected axis with texture from 3D data\"\"\"\n",
    "    bl_idname = \"scene.create_slice_plane\"\n",
    "    bl_label = \"Create Slice Plane\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        # Get the 3D data array from the scene\n",
    "        data = getattr(context.scene, \"tissue_cartography_data\", None)\n",
    "        resolution = getattr(context.scene, \"tissue_cartography_resolution_array\", None)\n",
    "        if data is None or resolution is None:\n",
    "            self.report({'ERROR'}, \"3D data array not found in the scene.\")\n",
    "            return {'CANCELLED'}\n",
    "        if not isinstance(data, np.ndarray) or data.ndim != 4:\n",
    "            self.report({'ERROR'}, \"Invalid 3D data array.\")\n",
    "            return {'CANCELLED'}\n",
    "        if context.scene.slice_channel >= data.shape[0]:\n",
    "            self.report({'ERROR'}, f\"Channel {context.scene.slice_channel} is out of bounds for the data array.\")\n",
    "            return {'CANCELLED'}\n",
    "\n",
    "        length, width, height = (np.array(data.shape[1:]) * resolution)\n",
    "        slice_plane = create_slice_plane(length, width, height, axis=context.scene.slice_axis,\n",
    "                                         position=context.scene.slice_position)\n",
    "        slice_img = get_slice_image(data, resolution, axis=context.scene.slice_axis,\n",
    "                                    position=context.scene.slice_position)\n",
    "        slice_img = normalize_quantiles(slice_img, quantiles=(0.01, 0.99),\n",
    "                                         channel_axis=0, clip=True, data_type=None)     \n",
    "        create_material_from_array(slice_plane, slice_img[context.scene.slice_channel],\n",
    "                                   material_name=f\"SliceMaterial_{context.scene.slice_axis}_{context.scene.slice_position}\")  \n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class VertexShaderInitializeOperator(bpy.types.Operator):\n",
    "    \"\"\"Initialize vertex shader for a selected mesh. Colors mesh vertices according to \n",
    "    3D image intensity.\"\"\"\n",
    "    bl_idname = \"scene.initialize_vertex_shader\"\n",
    "    bl_label = \"Initialize Vertex Shader\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        # create global dict to hold interpolator objects\n",
    "        if not hasattr(bpy.types.Scene, \"tissue_cartography_interpolators\"):\n",
    "            bpy.types.Scene.tissue_cartography_interpolators = dict()\n",
    "        # Get the 3D data array from the scene\n",
    "        data = getattr(context.scene, \"tissue_cartography_data\", None)\n",
    "        resolution = getattr(context.scene, \"tissue_cartography_resolution_array\", None)\n",
    "        obj = context.active_object\n",
    "        if data is None or resolution is None:\n",
    "            self.report({'ERROR'}, \"3D data array not found in the scene.\")\n",
    "            return {'CANCELLED'}\n",
    "        if not isinstance(data, np.ndarray) or data.ndim != 4:\n",
    "            self.report({'ERROR'}, \"Invalid 3D data array.\")\n",
    "            return {'CANCELLED'}\n",
    "        if not obj or obj.type != 'MESH':\n",
    "            self.report({'ERROR'}, \"No mesh object selected!\")\n",
    "            return {'CANCELLED'}\n",
    "        if context.scene.vertex_channel >= data.shape[0]:\n",
    "            self.report({'ERROR'}, f\"Channel {context.scene.vertex_channel} is out of bounds for the data array.\")\n",
    "            return {'CANCELLED'}\n",
    "        \n",
    "        bpy.types.Scene.tissue_cartography_interpolators[obj.name] = get_image_to_vertex_interpolator(obj, data, resolution)\n",
    "        positions = np.array([v.co + context.scene.vertex_offset*v.normal for v in obj.data.vertices])\n",
    "        intensities = bpy.types.Scene.tissue_cartography_interpolators[obj.name][context.scene.vertex_channel](positions)\n",
    "        colors = np.stack(3*[intensities,], axis=1)\n",
    "        \n",
    "        assign_vertex_colors(obj, colors)\n",
    "        create_vertex_color_material(obj)\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class VertexShaderRefreshOperator(bpy.types.Operator):\n",
    "    \"\"\"Refresh vertex colors for a selected mesh. Colors mesh vertices according to \n",
    "    3D image intensity.\"\"\"\n",
    "    bl_idname = \"scene.refresh_vertex_shader\"\n",
    "    bl_label = \"Refresh Vertex Shader\"\n",
    "    bl_options = {'REGISTER', 'UNDO'}\n",
    "\n",
    "    def execute(self, context):\n",
    "        # Get the 3D data array from the scene\n",
    "        data = getattr(context.scene, \"tissue_cartography_data\", None)\n",
    "        resolution = getattr(context.scene, \"tissue_cartography_resolution_array\", None)\n",
    "        obj = context.active_object\n",
    "        interpolator_dict = getattr(context.scene, \"tissue_cartography_interpolators\")\n",
    "        if data is None or resolution is None:\n",
    "            self.report({'ERROR'}, \"3D data array not found in the scene.\")\n",
    "            return {'CANCELLED'}\n",
    "        if not isinstance(data, np.ndarray) or data.ndim != 4:\n",
    "            self.report({'ERROR'}, \"Invalid 3D data array.\")\n",
    "            return {'CANCELLED'}\n",
    "        if not obj or obj.type != 'MESH':\n",
    "            self.report({'ERROR'}, \"No mesh object selected!\")\n",
    "            return {'CANCELLED'}\n",
    "        if context.scene.vertex_channel >= data.shape[0]:\n",
    "            self.report({'ERROR'}, f\"Channel {context.scene.vertex_channel} is out of bounds for the data array.\")\n",
    "        if interpolator_dict is None or obj.name not in interpolator_dict:\n",
    "            self.report({'ERROR'}, f\"Vertex shader not initialized.\")\n",
    "            return {'CANCELLED'}\n",
    "       \n",
    "        positions = np.array([v.co + context.scene.vertex_offset*v.normal for v in obj.data.vertices])\n",
    "        intensities = interpolator_dict[obj.name][context.scene.vertex_channel](positions)\n",
    "        colors = np.stack(3*[intensities,], axis=1)\n",
    "        assign_vertex_colors(obj, colors)\n",
    "\n",
    "        return {'FINISHED'}\n",
    "\n",
    "\n",
    "class HelpPopupOperator(Operator):\n",
    "    \"\"\"Show help window.\"\"\"\n",
    "    bl_idname = \"scene.help_popup\"\n",
    "    bl_label = \"Tissue Cartography Help\"\n",
    "\n",
    "    def execute(self, context):\n",
    "        return context.window_manager.invoke_popup(self, width=400)\n",
    "\n",
    "    def draw(self, context):\n",
    "        layout = self.layout\n",
    "        col = layout.column()\n",
    "\n",
    "        col.label(text=\"Tissue Cartography Add-On Help\", icon='INFO')\n",
    "        col.label(text=\"1. Load a .tiff file using the 'Load' button.\")\n",
    "        col.label(text=\"   after entering the resolution (x, y, z) in microns.\")\n",
    "        col.label(text=\"2. Select the mesh to use (it should be outlined in orange).\")\n",
    "        col.label(text=\"3. Click 'Create Projection' to bake mesh positions,\")\n",
    "        col.label(text=\"   nesh normals, and volumetric data to UV textures.\")\n",
    "        col.label(text=\"   Define normal offsets to get a multi-layer projection.\")\n",
    "        col.label(text=\"   Data is saved as .tiff files for further processing,\")\n",
    "        col.label(text=\"   and as a material to shade the mesh (see Shading workspace).\")\n",
    "        col.label(text=\"   Projection resolution determines the output texture size.\")\n",
    "        col.separator()\n",
    "        col.label(text=\"4. Troubleshooting and conventions\")\n",
    "        col.label(text=\"   a. The mesh vertex positions must be in micrometers.\")\n",
    "        col.label(text=\"      After creating the mesh (for example by a marching cubes),\")\n",
    "        col.label(text=\"      make sure to convert from pixels to microns!\")\n",
    "        col.label(text=\"   b. When importing a mesh into blender, choose Y=Forward and Z=Up.\")\n",
    "        col.label(text=\"      This ensures the mesh coordinates match the image axes!\")\n",
    "        col.label(text=\"   c. Check the Info Monitor (Scripting window) for messages and errors.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85efe225-f82e-4e7c-8f6b-dbc02773f846",
   "metadata": {},
   "source": [
    "### Define layout and set up add-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3d7f75-8a9b-4d9f-9d7c-f1cf8973764b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class TissueCartographyPanel(Panel):\n",
    "    \"\"\"Class defining layout of user interface (buttons, inputs, etc.)\"\"\"\n",
    "    bl_label = \"Tissue Cartography\"\n",
    "    bl_idname = \"SCENE_PT_tissue_cartography\"\n",
    "    bl_space_type = 'PROPERTIES'\n",
    "    bl_region_type = 'WINDOW'\n",
    "    bl_context = \"scene\"\n",
    "\n",
    "    def draw(self, context):\n",
    "        layout = self.layout\n",
    "        scene = context.scene\n",
    "\n",
    "        layout.prop(scene, \"tissue_cartography_file\")\n",
    "        layout.prop(scene, \"tissue_cartography_resolution\")\n",
    "        layout.operator(\"scene.load_tiff\", text=\"Load .tiff file\")\n",
    "        layout.separator()\n",
    "        layout.prop(scene, \"tissue_cartography_offsets\")\n",
    "        layout.prop(scene, \"projection_resolution\")\n",
    "        layout.operator(\"scene.create_projection\", text=\"Create Projection\")\n",
    "        layout.operator(\"scene.save_projection\", text=\"Save Projection\")\n",
    "        layout.separator()\n",
    "        layout.prop(scene, \"slice_axis\")\n",
    "        layout.prop(scene, \"slice_position\")\n",
    "        layout.prop(scene, \"slice_channel\")\n",
    "        layout.operator(\"scene.create_slice_plane\", text=\"Create slice plane\")\n",
    "        layout.separator()\n",
    "        layout.prop(scene, \"vertex_offset\")\n",
    "        layout.prop(scene, \"vertex_channel\")\n",
    "        layout.operator(\"scene.initialize_vertex_shader\", text=\"Initialize vertex shading\")\n",
    "        layout.operator(\"scene.refresh_vertex_shader\", text=\"Refresh vertex shading\")\n",
    "        layout.separator()\n",
    "        layout.operator(\"scene.help_popup\", text=\"Show help\", icon='HELP')\n",
    "        \n",
    "\n",
    "def register():\n",
    "    \"\"\"Add the add-on to the blender user interface\"\"\"\n",
    "    bpy.utils.register_class(TissueCartographyPanel)\n",
    "    bpy.utils.register_class(LoadTIFFOperator)\n",
    "    bpy.utils.register_class(CreateProjectionOperator)\n",
    "    bpy.utils.register_class(SaveProjectionOperator)\n",
    "    bpy.utils.register_class(SlicePlaneOperator)\n",
    "    bpy.utils.register_class(VertexShaderInitializeOperator)\n",
    "    bpy.utils.register_class(VertexShaderRefreshOperator)\n",
    "    bpy.utils.register_class(HelpPopupOperator)\n",
    "    \n",
    "    bpy.types.Scene.tissue_cartography_file = StringProperty(\n",
    "        name=\"File Path\",\n",
    "        description=\"Path to the TIFF file\",\n",
    "        subtype='FILE_PATH',\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_resolution = FloatVectorProperty(\n",
    "        name=\"x/y/z Resolution (µm)\",\n",
    "        description=\"Resolution in microns along x, y, z axes\",\n",
    "        size=3,\n",
    "        default=(1.0, 1.0, 1.0),\n",
    "    )\n",
    "    bpy.types.Scene.tissue_cartography_offsets = StringProperty(\n",
    "        name=\"Normal Offsets (µm)\",\n",
    "        description=\"Comma-separated list of floats for multilayer projection offsets\",\n",
    "        default=\"0\",\n",
    "    )\n",
    "    bpy.types.Scene.projection_resolution = IntProperty(\n",
    "        name=\"Projection Resolution\",\n",
    "        description=\"Resolution for the projection (e.g., 1024 for 1024x1024)\",\n",
    "        default=1024,\n",
    "        min=1,\n",
    "    )\n",
    "    bpy.types.Scene.slice_axis = EnumProperty(\n",
    "        name=\"Slice Axis\",\n",
    "        description=\"Choose an axis\",\n",
    "        items=[('x', \"X-Axis\", \"Align to the X axis\"),\n",
    "               ('y', \"Y-Axis\", \"Align to the Y axis\"),\n",
    "               ('z', \"Z-Axis\", \"Align to the Z axis\")],\n",
    "        default='x'\n",
    "    )\n",
    "    bpy.types.Scene.slice_position = FloatProperty(\n",
    "        name=\"Slice Position (µm)\",\n",
    "        description=\"Position along the selected axis in µm\",\n",
    "        default=0\n",
    "    )\n",
    "    bpy.types.Scene.slice_channel = IntProperty(\n",
    "        name=\"Slice Channel\",\n",
    "        description=\"Channel to use for slice. plane\",\n",
    "        default=0,\n",
    "        min=0,\n",
    "    )\n",
    "    bpy.types.Scene.vertex_offset = FloatProperty(\n",
    "        name=\"Vertex Normal Offset (µm)\",\n",
    "        description=\"Normal offset to use for vertex shading.\",\n",
    "        default=0,\n",
    "        min=0,\n",
    "    )\n",
    "    bpy.types.Scene.vertex_channel = IntProperty(\n",
    "        name=\"Vertex Channel\",\n",
    "        description=\"Channel to use for vertex shading.\",\n",
    "        default=0,\n",
    "        min=0,\n",
    "    )\n",
    "\n",
    "\n",
    "def unregister():\n",
    "    bpy.utils.unregister_class(TissueCartographyPanel)\n",
    "    bpy.utils.unregister_class(LoadTIFFOperator)\n",
    "    bpy.utils.unregister_class(CreateProjectionOperator)\n",
    "    bpy.utils.unregister_class(SaveProjectionOperator)\n",
    "    bpy.utils.unregister_class(SlicePlaneOperator)\n",
    "    bpy.utils.unregister_class(VertexShaderInitializeOperator)\n",
    "    bpy.utils.unregister_class(VertexShaderRefreshOperator)\n",
    "    bpy.utils.unregister_class(HelpPopupOperator)\n",
    "    del bpy.types.Scene.tissue_cartography_resolution_array\n",
    "    del bpy.types.Scene.tissue_cartography_data\n",
    "    del bpy.types.Scene.tissue_cartography_interpolators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eb725f-8ca9-4626-a782-c17259205c9c",
   "metadata": {},
   "source": [
    "### Run the add-on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb57fe1-eeca-44e0-a127-a8bddbd166a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    register()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:blender-tissue-cartography] *",
   "language": "python",
   "name": "conda-env-blender-tissue-cartography-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
