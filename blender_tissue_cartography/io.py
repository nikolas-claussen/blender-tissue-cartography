# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_io.ipynb.

# %% auto 0
__all__ = ['adjust_axis_order', 'write_h5', 'read_h5', 'flatten', 'pad_list', 'unique', 'index_else_nan', 'ObjMesh',
           'save_dict_to_json', 'save_for_imageJ', 'normalize_quantiles_for_png', 'save_stack_for_blender']

# %% ../nbs/01_io.ipynb 1
import numpy as np
from skimage import transform
from skimage.io import imread, imsave
import h5py
from typing import Iterable
import tifffile
import json
import os
from copy import deepcopy

# %% ../nbs/01_io.ipynb 5
def adjust_axis_order(image, channel_axis=None):
    """
    Adjust axis order of image (numpy array) so that the channel axis is axis 0. 
    
    If channel axis is not specified, it is infered as the axis with the smallest number of entries.
    If the image contains a single channel, this function adds a singleton dimension.
    Axis order is otherwise left unchanged. Image must have 3 axes (single channel volumetric)
    or four axes (multichannel volumetric). 
    
    Parameters
    ----------
    image: np.ndarray with 3 or 4 axes
        Input image.
    channel_axis: int or None, optional
        Channel axis
    
    Returns
    -------
    transposed image: np.ndarray with 4 axes
        Input image, channel now axis 0.
    """
    assert 2 < len(image.shape) <5 , "image must have 3 or 4 axes"
    if len(image.shape) == 3:
        return image[np.newaxis]
    if channel_axis is None:
        channel_axis = np.argmin(image.shape)
    return np.moveaxis(image, channel_axis, 0)

# %% ../nbs/01_io.ipynb 10
def write_h5(filename, image, h5_dataset_name="image"):
    """Write image (numpy array) as .h5 file (e.g. as input for ilastik)."""
    with h5py.File(filename, "w") as f:
        f.create_dataset('image', data=image)
    return None

def read_h5(filename):
    """Read .h5 file (e.g. ilastik output) into numpy array. Loads alphabetically first entry in .h5."""
    with h5py.File(filename, "r") as f:
        arr = f[sorted(f.keys())[0]][()] 
    return arr

# %% ../nbs/01_io.ipynb 15
def flatten(lst, max_depth=1000, iter_count=0):
    """
    Flatten a list of lists into a list.

    Also works with inhomogeneous lists, e.g., [[0,1],2]. The argument
    depth determines how "deep" to flatten the list, e.g. with max_depth=1:
    [[(1,0), (1,0)]] -> [(1,0), (1,0)].

    Parameters
    ----------
    lst : list
        list-of-lists.
    max_depth : int, optional
        To what depth to flatten the list.
    iter_count : int, optional
        Helper argument for recursion depth determination.
    
    Returns
    -------
    iterator
        flattened list.
    """
    for el in lst:
        if (isinstance(el, Iterable) and not isinstance(el, (str, bytes))
                and iter_count < max_depth):
            yield from flatten(el, max_depth=max_depth,
                               iter_count=iter_count+1)
        else:
            yield el
            
def pad_list(lst, length=3, fill_value=np.nan):
    """Pad end of list with fill_value if shorter than desired length."""
    return lst + max([0, (length-len(lst))]) * [fill_value,]

def unique(sequence):
    """Create list of unique entries in sequence while preserving order"""
    seen = set()
    return [x for x in sequence if not (x in seen or seen.add(x))]

def index_else_nan(arr, ind, target_shape=None):
    """Return arr[ind] if not np.isnan(ind), else np.nan*np.ones(arr.shape[1:])"""
    if np.isnan(ind):
        target_shape = (arr.shape[1:] if len(arr.shape) > 1 else (1,)) if target_shape is None else target_shape
        return np.nan*np.ones(target_shape)
    return arr[ind]

# %% ../nbs/01_io.ipynb 16
class ObjMesh:
    """
    Simple class for reading, holding, transforming, and saving 3d polygonal meshes in the .obj format.
    See https://en.wikipedia.org/wiki/Wavefront_.obj_file.
    Attributes
        - vertices = [(x_0, y_0, z_0), ... ]
        - texture_vertices = [(u_0, v_0), ...] or None
        - normals = [(nx_0, ny_0, nz_0), ...] or None
        - faces = [f0, ...]
        - only_vertices = bool. 
    vertices, texture_vertices, normals are np.arrays, faces is a list of lists.
    Each face is either a list of vertex indices (if only_vertices is True), or, if the mesh
    has texture and normal information, a list of vertex/texture/normal index triples.
    Missing data is represented by np.nan. Faces can be any length (triangles, quads, ...).
    Indices start at 0!
    
    The method match_vertex_info can be used to match up vertices, texture vertices and
    normals based on the face connectivity. This sets the following attributes:
        - matched_vertices
        - matched_texture_vertices
        - matched_normals
    as np.array's with correspondong rows. 

    The property tris gets all triangles as a numpy array.
    """
    
    def __init__(self, vertices, faces, texture_vertices=None, normals=None, name=None):
        self.vertices, self.faces = (vertices, faces)
        self.texture_vertices, self.normals = (texture_vertices, normals)
        self.name = None
        self.only_vertices = texture_vertices is None and normals is None


    @staticmethod
    def read_obj(filename):
        """
        Return vertices, texture vertices, normals, and faces from an obj file.

        Faces are lists of 3-tuples vertex/texture vertex/normal. If a certain vertex has no texture or normal 
        associated to it, the entry is np.nan, else it is an index into the vertex, texture, and normal arrays
        (note: indices of returned faces start at 0!). See https://en.wikipedia.org/wiki/Wavefront_.obj_file.
        
        Intended for .obj files containing a single object only.

        Parameters
        ----------
        filename : str
            filename
        Returns
        -------
        mesh: ObjMesh
        """
        def _str_to_int_or_nan(x):
            """Convert string to int or np.nan if string is empty"""
            if x == '':
                return np.nan
            return int(x)
        with open(filename, 'r') as f:
            lines = f.readlines()
        names = [ln.split()[1:] for ln in lines if ln.startswith("o ")]
        name = None if len(names) == 0 else names[0]
        vs = np.array([ln.split()[1:] for ln in lines if ln.startswith("v ")]).astype(float)
        vts = np.array([ln.split()[1:] for ln in lines if ln.startswith("vt ")]).astype(float)
        ns = np.array([ln.split()[1:] for ln in lines if ln.startswith("vn ")]).astype(float)
        fs = [ln.split()[1:] for ln in lines if ln.startswith("f ")]
        fs = [[pad_list([_str_to_int_or_nan(y)-1 for y in x.split("/")], length=3, fill_value=np.nan)
               for x in f] for f in fs]
        if vts.shape == (0,) and ns.shape == (0,):
            fs = [[v[0] for v in f] for f in fs]
            mesh = ObjMesh(vs, fs, texture_vertices=None, normals=None, name=name)
        else:
            mesh = ObjMesh(vs, fs, texture_vertices=vts, normals=ns, name=name)
        return mesh
    
    def write_obj(self, filename,):
        """
        Write mesh to .obj format

        Can write texture coordinates and normals if included. 

        Parameters
        ----------
        filename : str
            filename to save to

        Returns
        -------
        None

        """
        def _int_or_nan_to_str(x):
            """Convert int/nan to string. np.nan is converted to empty string"""
            if np.isnan(x):
                return ''
            return str(x)
        namelines = ["o {}\n".format(*self.name)] if self.name is not None else []
        if self.only_vertices:
            vlines = ["v {} {} {}\n".format(*v) for v in self.vertices]
            flines = ["f {} {} {}\n".format(*[int(v+1) for v in fc]) for fc in self.faces]
            with open(filename, 'w') as f:
                f.writelines(namelines)
                f.writelines(vlines)
                f.writelines(flines)
        else:
            assert all([len(v)==3 for v in flatten(self.faces, max_depth=1)]), "each vertex must have 3 indices"
            texture_vertices = [] if self.texture_vertices is None else self.texture_vertices
            normals = [] if self.normals is None else self.normals
            vlines = ["v {} {} {}\n".format(*v) for v in self.vertices]
            vtlines = ["vt {} {}\n".format(*vt) for vt in texture_vertices]
            nlines = ["vn {} {} {}\n".format(*n) for n in normals]
            flines = ["f {} {} {}\n".format(*["{}/{}/{}".format(*[_int_or_nan_to_str(ix+1) for ix in v])
                                              for v in fc]) for fc in self.faces]
            with open(filename, 'w') as f:
                f.writelines(namelines)
                f.writelines(vlines)
                f.writelines(vtlines)
                f.writelines(nlines)
                f.writelines(flines)
        return None
 
    def match_vertex_info(self, use_vertex_normals=True, require_texture_normals=True):
        """
        Match up 3d vertex coordinates / texture coordinates / normals based on face connectivity.
        
        Sets attributes matched_vertices, matched_texture_vertices, matched_normals.
        The resulting arrays will _not_ match the face indices, since there can be more texture vertices
        than vertices, and will have a shape given by the number of unique vertex/texture vertex/normal
        pairs (note: this is much lower than the number of faces, which is numerically favorable)
        
        Parameters
        ----------
        use_vertex_normals : bool, default True
            Use vertex normals for normal info instead of face normals. Will result in arrays
            of size O(n_vertices). Else, you get an arra of size O(n_triangles).
        require_texture_normals : bool, default True
            If True, discard vertices for which texture or normal info does not exist. 
            If False, attributes that do not exist for a given vertex are set to np.nan.
            
        Returns
        -------
        None
        """
        assert not self.only_vertices, """Method requires texture or normal information"""
        if not use_vertex_normals:
            unique_v_vt_n_pairs = unique([tuple(x) for x in flatten(self.faces, max_depth=1)])
            matched_vertices = np.array([index_else_nan(self.normals, pair[0], target_shape=(3,))
                                         for pair in unique_v_vt_n_pairs])
            matched_texture_vertices = np.array([index_else_nan(self.texture_vertices, pair[1], target_shape=(2,))
                                                 for pair in unique_v_vt_n_pairs])
            matched_normals = np.array([index_else_nan(self.normals, pair[2], target_shape=(3,))
                                        for pair in unique_v_vt_n_pairs])
        else:
            unique_v_vt_pairs = unique([tuple(x[:2]) for x in flatten(self.faces, max_depth=1)])
            matched_vertices = np.array([index_else_nan(self.normals, pair[0], target_shape=(3,))
                                         for pair in unique_v_vt_pairs])
            matched_texture_vertices = np.array([index_else_nan(self.texture_vertices, pair[1], target_shape=(2,))
                                                 for pair in unique_v_vt_pairs])
            normals = self.vertex_normals
            matched_normals = np.array([index_else_nan(normals, pair[0], target_shape=(3,))
                                        for pair in unique_v_vt_pairs])


        if require_texture_normals:
            mask = ~np.isnan(matched_texture_vertices).any(axis=1) & ~np.isnan(matched_normals).any(axis=1)
            matched_vertices = matched_vertices[mask,:]
            matched_texture_vertices = matched_texture_vertices[mask,:]
            matched_normals = matched_normals[mask,:]            
        self.matched_vertices = matched_vertices
        self.matched_texture_vertices = matched_texture_vertices
        self.matched_normals = matched_normals
        return None
        
    @property
    def tris(self):
        """Get all triangles in mesh as a numpy array. Entries are vertex indices."""
        if self.only_vertices:
            return np.array([fc for fc in self.faces if len(fc)==3])
        else:
            return np.array([[v[0] for v in fc] for fc in self.faces if len(fc)==3])
        return None
    
    @property
    def texture_tris(self):
        """Get all texture triangles in mesh as a numpy array. Entries are texture_vertex indices."""
        if self.only_vertices:
            return np.array([np.nan for fc in self.faces if len(fc)==3])
        else:
            return np.array([[v[1] for v in fc] for fc in self.faces if len(fc)==3])
        return None
    
    @property
    def vertex_normals(self):
        """Get array of vertex normals. If multiple normals per vertex are stored, the last one is returned"""
        if self.only_vertices:
            return np.nan*np.ones_like(self.vertices)
        v_n_pairs = {v: np.nan for v in range(self.vertices.shape[0])}
        for v, _, n in flatten(self.faces, max_depth=1):
            v_n_pairs[v] = n
        return np.array([index_else_nan(self.normals, v_n_pairs[key], target_shape=(3,))
                         for key in range(self.vertices.shape[0])])

    @property
    def vertex_textures(self):
        """Get array of vertex texture coordinates. If multiple textures per vertex are stored,
        the last one is returned"""
        if self.only_vertices:
            return np.nan*np.ones_like(self.vertices)
        v_vt_pairs = {v: np.nan for v in range(self.vertices.shape[0])}
        for v, vt, _ in flatten(self.faces, max_depth=1):
            v_vt_pairs[v] = vt
        return np.array([index_else_nan(self.texture_vertices, v_vt_pairs[key], target_shape=(2,))
                         for key in range(self.vertices.shape[0])])

    
    def apply_affine_to_mesh(self, trafo, update_matched_data=True):
        """
        Apply affine transformation to mesh.
        
        Rotate/shear and translate vertices, rotate/shear and renormalize normals,
        flip faces if transformation determinant is -1.

        Parameters
        ----------
        trafo : np.array of shape (4,4) or (3,3)
            Transformation matrix. If (4,4), it is interpreted as affine transformation.
        update_matched_data : bool, default True
            Update matched data

        Returns
        -------
        newmesh : ObjMesh
            Transformed mesh.

        """
        assert trafo.shape==(3,3) or trafo.shape==(4,4), "Transformation matrix must be 3*3 or 4*4"
        if trafo.shape == (3,3):
            trafo_matrix, trafo_translate = (trafo, np.zeros(3))
        elif trafo.shape == (4,4):
            trafo_matrix, trafo_translate = (trafo[:3,:3], trafo[:3,-1])
        newmesh = deepcopy(self)
        newmesh.vertices = self.vertices@trafo_matrix.T + trafo_translate
        if self.normals is not None:
            normals_transformed = self.normals@trafo_matrix.T
            newmesh.normals = (normals_transformed.T / np.linalg.norm(normals_transformed, axis=-1)).T
        if np.linalg.det(trafo_matrix) < 0:
            newmesh.faces = [fc[::-1] for fc in self.faces]
        if update_matched_data and not self.only_vertices:
            newmesh.match_vertex_info()
        return newmesh

# %% ../nbs/01_io.ipynb 35
def save_dict_to_json(filename, dictionary):
    """
    Save dictionary to .json file.
    
    Will automatically convert numpy arrays to lists for saving. If you get an error like "XXX is not JSON
    serializable", you need to ensure all your dictionary items are things that can be saved to text by json
    (strings, numbers, lists).
    
    Parameters
    ----------
    filename : str
        Filename to save to
    dictionary : dict
        Dictionary to save
    
    Returns
    -------
    None
    """
    serializable_dictionary = {key: val.tolist() if isinstance(val, np.ndarray) else val
                               for key, val in dictionary.items()}
    with open(filename, "w") as f:
        json.dump(serializable_dictionary, f)
    return None

# %% ../nbs/01_io.ipynb 37
def save_for_imageJ(filename, image, z_axis=None, channel_axis=None):
    """
    Save image as 32bit ImageJ compatible .tif file
    
    If channel_axis is not provided, it is inferred as the shortest axis.
    If z-axis is provided for a 4d array, it will be set as the default z-axis for ImageJ.
    """
    channel_axis = np.argmin(image.shape) if channel_axis is None else channel_axis
    if len(image.shape) == 3:
        transposed_image = np.moveaxis(image, channel_axis, 0)
        tifffile.imwrite(filename, transposed_image.astype(np.float32),
                         metadata={'axes': 'CYX'}, imagej=True,)
    elif len(image.shape) == 4:
        if z_axis is not None:
            transposed_image = np.moveaxis(image, (z_axis, channel_axis), (0,1))
        else:
            transposed_image = np.moveaxis(image, channel_axis, 1)
        tifffile.imwrite(filename, transposed_image.astype(np.float32),
                         metadata={'axes': 'ZCYX'}, imagej=True,)
    return None
    
def normalize_quantiles_for_png(image, quantiles=(0.01, 0.99)):
    """
    Normalize an image by setting given quantiles to 0 and 255 and converting to 8-bit, for saving as .png
    
    Also replaces nan by 0.
    
    Parameters
    ----------
    image : np.array
        Image (should be single-channel)
    quantiles : tuple
        Image quantile to set to 0 and 255.
    
    Returns
    -------
    image_normalized : np.array
        Normalized image, datatype np.uint8
    """
    image_normalized = image - np.nanquantile(image, quantiles[0])
    image_normalized /= np.nanquantile(image_normalized, quantiles[1])
    image_normalized = np.nan_to_num(np.round(np.clip(255*image_normalized, 0, 255)), nan=0)
    return image_normalized.astype(np.uint8)
    
    
def save_stack_for_blender(image, directory, normalization=(0.01, 0.99)):
    """
    Save multichannel volumetric image as series of grayscale .png images. Can normalize data if desired.
    
    This function necessarily converts the image to 8bit. Use a suitable normalization to ensure nothing 
    is lost.
    
    Parameters
    ----------
    image : 4d np.array
        Axis 0 is assumed to be the channel axis, axis 1 is the slicing axes, i.e. images will correspond to
        slices along axis 1.
    directory : str
        Path to save data to. Will create directory if it doesn't exist
    normalization : tuple of float, or callable
        Whether to normalize the image before saving it. If None, no normalization is performed. If a
        tuple is given, it will be interpreted as quantiles to set to 0 and 255, respectively (over the
        whole channel, not each slice). If a callable is provided, it will be applied to each channel.
        
    Returns
    -------
    None
    
    """
    directory = directory.removesuffix('/')
    if not os.path.exists(directory):
        os.makedirs(directory)
    for ic, ch in enumerate(image):
        if callable(normalization):
            ch_normalized = normalization(ch)
        if isinstance(normalization, tuple):
            ch_normalized = normalize_quantiles_for_png(ch, quantiles=normalization)
        for islc, slc in enumerate(ch_normalized):
            slc = np.stack(3*[slc], axis=-1).astype(np.uint8) # necessary for saving as png
            imsave(f'{directory}/channel_{ic}_slice_{str(islc).zfill(3)}.png', slc, check_contrast=False)
    return None
