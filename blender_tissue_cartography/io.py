# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_io.ipynb.

# %% auto 0
__all__ = ['adjust_axis_order', 'save_h5', 'load_h5', 'flatten', 'str_to_int_or_nan', 'int_or_nan_to_str', 'pad_list', 'read_obj',
           'write_obj', 'match_vertex_info', 'save_dict_to_json', 'save_for_imageJ', 'normalize_quantiles_for_png',
           'save_stack_for_blender']

# %% ../nbs/01_io.ipynb 1
import numpy as np
from skimage import transform
from skimage.io import imread, imsave
import h5py
from typing import Iterable
import tifffile
import json
import os

# %% ../nbs/01_io.ipynb 5
def adjust_axis_order(image, channel_axis=None):
    """
    Adjust axis order of image (numpy array) so that the channel axis is axis 0. 
    
    If channel axis is not specified, it is infered as the axis with the smallest number of entries.
    If the image contains a single channel, this function adds a singleton dimension.
    Axis order is otherwise left unchanged. Image must have 3 axes (single channel volumetric)
    or four axes (multichannel volumetric). 
    
    Parameters
    ----------
    image: np.ndarray with 3 or 4 axes
        Input image.
    channel_axis: int or None, optional
        Channel axis
    
    Returns
    -------
    transposed image: np.ndarray with 4 axes
        Input image, channel now axis 0.
    """
    assert 2 < len(image.shape) <5 , "image must have 3 or 4 axes"
    if len(image.shape) == 3:
        return image[np.newaxis]
    if channel_axis is None:
        channel_axis = np.argmin(image.shape)
    return np.moveaxis(image, channel_axis, 0)

# %% ../nbs/01_io.ipynb 10
def save_h5(filename, image, h5_dataset_name="image"):
    """Save image (numpy array) as .h5 file (e.g. as input for ilastik)."""
    with h5py.File(filename, "w") as f:
        f.create_dataset('image', data=image)
    return None

def load_h5(filename):
    """Load .h5 file (e.g. ilastik output) into numpy array. Loads alphabetically first entry in .h5."""
    with h5py.File(filename, "r") as f:
        arr = f[sorted(f.keys())[0]][()] 
    return arr

# %% ../nbs/01_io.ipynb 15
def flatten(lst, max_depth=1000, iter_count=0):
    """
    Flatten a list of lists into a list.

    Also works with inhomogeneous lists, e.g., [[0,1],2]. The argument
    depth determines how "deep" to flatten the list, e.g. with max_depth=1:
    [[(1,0), (1,0)]] -> [(1,0), (1,0)].

    Parameters
    ----------
    lst : list
        list-of-lists.
    max_depth : int, optional
        To what depth to flatten the list.
    iter_count : int, optional
        Helper argument for recursion depth determination.
    
    Returns
    -------
    iterator
        flattened list.
    """
    for el in lst:
        if (isinstance(el, Iterable) and not isinstance(el, (str, bytes))
                and iter_count < max_depth):
            yield from flatten(el, max_depth=max_depth,
                               iter_count=iter_count+1)
        else:
            yield el
            
def str_to_int_or_nan(x):
    """Convert string to int or np.nan if string is empty"""
    if x == '':
        return np.nan
    return int(x)

def int_or_nan_to_str(x):
    """Convert int/nan to string. np.nan is converted to empty string"""
    if np.isnan(x):
        return ''
    return str(x)

def pad_list(lst, length=3, fill_value=np.nan):
    """Pad end of list with fill_value if shorter than desired length."""
    return lst + max([0, (length-len(lst))]) * [fill_value,]

def read_obj(filename):
    """
    Return vertices, texture vertices, normals, and faces from an obj file.
    
    Faces are lists of 3-tuples vertex/texture vertex/normal. If a certain vertex has no texture or normal 
    associated to it, the entry is np.nan, else it is an index into the vertex, texture, and normal arrays
    (note: indices of returned faces start at 0!). See https://en.wikipedia.org/wiki/Wavefront_.obj_file.

    Parameters
    ----------
    filename : str
        filename
    Returns
    -------
    mesh: dict with entries "vertices", "texture_vertices", "normals", and "faces"
        vertices, texture_vertices, and normals are np.arrays, faces is a list of lists.
    """

    
    with open(filename, 'r') as f:
        lines = f.readlines()
    vs = np.array([ln.split()[1:] for ln in lines if ln.startswith("v ")]).astype(float)
    vts = np.array([ln.split()[1:] for ln in lines if ln.startswith("vt ")]).astype(float)
    ns = np.array([ln.split()[1:] for ln in lines if ln.startswith("vn ")]).astype(float)
    fs = [ln.split()[1:] for ln in lines if ln.startswith("f ")]
    fs = [[pad_list([str_to_int_or_nan(y)-1 for y in x.split("/")], length=3, fill_value=np.nan)
           for x in f] for f in fs]
    mesh = {"vertices": vs, "texture_vertices": vts, "normals": ns, "faces": fs}
    return mesh

def write_obj(filename, faces, vertices, texture_vertices=None, normals=None, indices_start_at_one=False):
    """
    Write mesh to .obj format
    
    Can write texture coordinates and normals if included. 
    
    Parameters
    ----------
    filename : str
        filename to save to
    vertices : np.array of shape (..., 3)
        vertices
    faces : list 
        Faces. A face can be either a list of vertex indices, or a list of vertex/texture/normal index tuples.
        Indices can be np.nan or None to represent missing data.
    texture_vertices: np.array of shape (..., 2), optional
        Texture vertices
    normals: np.array of shape (..., 3), optional
         Normals
    indices_start_at_one : bool, default True
        Whether face indices start at one or at 0.
    
    Returns
    -------
    None
    
    """
    faces_include_texture = all([isinstance(v, Iterable) for v in flatten(faces, max_depth=1)])
    if not faces_include_texture:
        with open(filename, 'w') as f:
            for v in vertices:
                f.write("v {} {} {}\n".format(*v))
            for fc in faces:
                if not indices_start_at_one:
                    fc = [v+1 for v in fc]
                f.write("f {} {} {}\n".format(*fc))
    if faces_include_texture:
        assert all([len(v) ==3 for v in flatten(faces, max_depth=1)]), "each vertex should contain 3 indices"
        texture_vertices = [] if texture_vertices is None else texture_vertices
        normals = [] if normals is None else normals
        with open(filename, 'w') as f:
            for v in vertices:
                f.write("v {} {} {}\n".format(*v))
            for vt in texture_vertices:
                f.write("vt {} {}\n".format(*vt))
            for n in normals:
                f.write("vn {} {} {}\n".format(*n))
            for fc in faces:
                if not indices_start_at_one:
                    fc = [[ix+1 for ix in v] for v in fc]
                fc = [[int_or_nan_to_str(ix) for ix in v] for v in fc]
                f.write("f {} {} {}\n".format(*["{}/{}/{}".format(*v) for v in fc]))
    return None


# %% ../nbs/01_io.ipynb 16
def match_vertex_info(faces, vertices, texture_vertices, normals):
    """
    Match up 3d vertex coordinates / texture coordinates / normals based on face connectivity.
    
    Parameters
    ----------
    faces : list
        List of faces. Each face is a list of vertex/texture vertex/normal array index triples. Indices start at 0!
    vertices : np.array of shape (..., 3)
        Vertices
    texture_vertices: np.array of shape (..., 2)
        Texture vertices
    normals: np.array of shape (..., 3)
         Normals
    
    Returns
    -------
    dict with entries:
        vertices : np.array of shape (n_matched, 3)
            Matched vertices
        texture_vertices: np.array of shape (n_matched, 2)
            Matched texture vertices
        normals: np.array of shape (n_matched, 3)
            Matched normals

    """
    unique_v_vt_n_pairs = set([tuple(x) for x in flatten([fc for fc in faces
                                                      if not np.isnan(list(flatten(fc))).any()], max_depth=1)])

    matched_vertices = np.stack([vertices[ix[0]] for ix in unique_v_vt_n_pairs])
    matched_texture_vertices = np.stack([texture_vertices[ix[1]] for ix in unique_v_vt_n_pairs])
    matched_normals = np.stack([normals[ix[2]] for ix in unique_v_vt_n_pairs])
    return {"vertices": matched_vertices,
            "texture_vertices": matched_texture_vertices,
            "normals": matched_normals}

# %% ../nbs/01_io.ipynb 20
def save_dict_to_json(filename, dictionary):
    """
    Save dictionary to .json file.
    
    Will automatically convert numpy arrays to lists for saving. If you get an error like "XXX is not JSON
    serializable", you need to ensure all your dictionary items are things that can be saved to text by json
    (strings, numbers, lists).
    
    Parameters
    ----------
    filename : str
        Filename to save to
    dictionary : dict
        Dictionary to save
    
    Returns
    -------
    None
    """
    serializable_dictionary = {key: val.tolist() if isinstance(val, np.ndarray) else val
                               for key, val in dictionary.items()}
    with open(filename, "w") as f:
        json.dump(serializable_dictionary, f)
    return None

# %% ../nbs/01_io.ipynb 22
def save_for_imageJ(filename, image, z_axis=None, channel_axis=None):
    """
    Save image as 32bit ImageJ compatible .tif file
    
    If channel_axis is not provided, it is inferred as the shortest axis.
    If z-axis is provided for a 4d array, it will be set as the default z-axis for ImageJ.
    """
    channel_axis = np.argmin(image.shape) if channel_axis is None else channel_axis
    if len(image.shape) == 3:
        transposed_image = np.moveaxis(image, channel_axis, 0)
        tifffile.imwrite(filename, transposed_image.astype(np.float32),
                         metadata={'axes': 'CYX'}, imagej=True,)
    elif len(image.shape) == 4:
        if z_axis is not None:
            transposed_image = np.moveaxis(image, (z_axis, channel_axis), (0,1))
        else:
            transposed_image = np.moveaxis(image, channel_axis, 1)
        tifffile.imwrite(filename, transposed_image.astype(np.float32),
                         metadata={'axes': 'ZCYX'}, imagej=True,)
    return None
    
def normalize_quantiles_for_png(image, quantiles=(0.01, 0.99)):
    """
    Normalize an image by setting given quantiles to 0 and 255 and converting to 8-bit, for saving as .png
    
    Also replaces nan by 0.
    
    Parameters
    ----------
    image : np.array
        Image (should be single-channel)
    quantiles : tuple
        Image quantile to set to 0 and 255.
    
    Returns
    -------
    image_normalized : np.array
        Normalized image, datatype np.uint8
    """
    image_normalized = image - np.nanquantile(image, quantiles[0])
    image_normalized /= np.nanquantile(image_normalized, quantiles[1])
    image_normalized = np.nan_to_num(np.round(np.clip(255*image_normalized, 0, 255)), nan=0)
    return image_normalized.astype(np.uint8)
    
    
def save_stack_for_blender(image, directory, normalization=(0.01, 0.99)):
    """
    Save multichannel volumetric image as series of grayscale .png images. Can normalize data if desired.
    
    This function necessarily converts the image to 8bit. Use a suitable normalization to ensure nothing 
    is lost.
    
    Parameters
    ----------
    image : 4d np.array
        Axis 0 is assumed to be the channel axis, axis 1 is the slicing axes, i.e. images will correspond to
        slices along axis 1.
    directory : str
        Path to save data to. Will create directory if it doesn't exist
    normalization : tuple of float, or callable
        Whether to normalize the image before saving it. If None, no normalization is performed. If a
        tuple is given, it will be interpreted as quantiles to set to 0 and 255, respectively (over the
        whole channel, not each slice). If a callable is provided, it will be applied to each channel.
        
    Returns
    -------
    None
    
    """
    directory = directory.removesuffix('/')
    if not os.path.exists(directory):
        os.makedirs(directory)
    for ic, ch in enumerate(image):
        if callable(normalization):
            ch_normalized = normalization(ch)
        if isinstance(normalization, tuple):
            ch_normalized = normalize_quantiles_for_png(ch, quantiles=normalization)
        for islc, slc in enumerate(ch_normalized):
            slc = np.stack(3*[slc], axis=-1).astype(np.uint8) # necessary for saving as png
            imsave(f'{directory}/channel_{ic}_slice_{str(islc).zfill(3)}.png', slc, check_contrast=False)
    return None
